{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1407,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0021321961620469083,
      "grad_norm": 131.21485900878906,
      "learning_rate": 4.651162790697675e-07,
      "loss": 7.8807,
      "step": 1
    },
    {
      "epoch": 0.0042643923240938165,
      "grad_norm": 136.63601684570312,
      "learning_rate": 9.30232558139535e-07,
      "loss": 7.6535,
      "step": 2
    },
    {
      "epoch": 0.006396588486140725,
      "grad_norm": 139.9501495361328,
      "learning_rate": 1.3953488372093025e-06,
      "loss": 5.0866,
      "step": 3
    },
    {
      "epoch": 0.008528784648187633,
      "grad_norm": 81.506103515625,
      "learning_rate": 1.86046511627907e-06,
      "loss": 4.3285,
      "step": 4
    },
    {
      "epoch": 0.010660980810234541,
      "grad_norm": 35.25471496582031,
      "learning_rate": 2.3255813953488376e-06,
      "loss": 4.0094,
      "step": 5
    },
    {
      "epoch": 0.01279317697228145,
      "grad_norm": 45.32255554199219,
      "learning_rate": 2.790697674418605e-06,
      "loss": 3.4639,
      "step": 6
    },
    {
      "epoch": 0.014925373134328358,
      "grad_norm": 90.38739013671875,
      "learning_rate": 3.2558139534883724e-06,
      "loss": 3.9947,
      "step": 7
    },
    {
      "epoch": 0.017057569296375266,
      "grad_norm": 81.82947540283203,
      "learning_rate": 3.72093023255814e-06,
      "loss": 2.9861,
      "step": 8
    },
    {
      "epoch": 0.019189765458422176,
      "grad_norm": 44.98365020751953,
      "learning_rate": 4.186046511627907e-06,
      "loss": 2.8807,
      "step": 9
    },
    {
      "epoch": 0.021321961620469083,
      "grad_norm": 113.10209655761719,
      "learning_rate": 4.651162790697675e-06,
      "loss": 3.2824,
      "step": 10
    },
    {
      "epoch": 0.023454157782515993,
      "grad_norm": 36.615806579589844,
      "learning_rate": 5.116279069767442e-06,
      "loss": 2.5987,
      "step": 11
    },
    {
      "epoch": 0.0255863539445629,
      "grad_norm": 49.37934494018555,
      "learning_rate": 5.58139534883721e-06,
      "loss": 2.5368,
      "step": 12
    },
    {
      "epoch": 0.02771855010660981,
      "grad_norm": 38.72647476196289,
      "learning_rate": 6.046511627906977e-06,
      "loss": 2.4376,
      "step": 13
    },
    {
      "epoch": 0.029850746268656716,
      "grad_norm": 41.03298568725586,
      "learning_rate": 6.511627906976745e-06,
      "loss": 2.394,
      "step": 14
    },
    {
      "epoch": 0.031982942430703626,
      "grad_norm": 35.58973693847656,
      "learning_rate": 6.976744186046513e-06,
      "loss": 2.2008,
      "step": 15
    },
    {
      "epoch": 0.03411513859275053,
      "grad_norm": 38.74470138549805,
      "learning_rate": 7.44186046511628e-06,
      "loss": 2.2476,
      "step": 16
    },
    {
      "epoch": 0.03624733475479744,
      "grad_norm": 38.07345199584961,
      "learning_rate": 7.906976744186048e-06,
      "loss": 2.1181,
      "step": 17
    },
    {
      "epoch": 0.03837953091684435,
      "grad_norm": 34.29568862915039,
      "learning_rate": 8.372093023255815e-06,
      "loss": 2.0059,
      "step": 18
    },
    {
      "epoch": 0.04051172707889126,
      "grad_norm": 35.75888442993164,
      "learning_rate": 8.837209302325582e-06,
      "loss": 1.9629,
      "step": 19
    },
    {
      "epoch": 0.042643923240938165,
      "grad_norm": 39.25952911376953,
      "learning_rate": 9.30232558139535e-06,
      "loss": 2.0593,
      "step": 20
    },
    {
      "epoch": 0.04477611940298507,
      "grad_norm": 38.633941650390625,
      "learning_rate": 9.767441860465117e-06,
      "loss": 2.034,
      "step": 21
    },
    {
      "epoch": 0.046908315565031986,
      "grad_norm": 35.36851501464844,
      "learning_rate": 1.0232558139534884e-05,
      "loss": 1.9196,
      "step": 22
    },
    {
      "epoch": 0.04904051172707889,
      "grad_norm": 39.029537200927734,
      "learning_rate": 1.0697674418604651e-05,
      "loss": 1.9519,
      "step": 23
    },
    {
      "epoch": 0.0511727078891258,
      "grad_norm": 35.589698791503906,
      "learning_rate": 1.116279069767442e-05,
      "loss": 1.8417,
      "step": 24
    },
    {
      "epoch": 0.053304904051172705,
      "grad_norm": 34.60423278808594,
      "learning_rate": 1.1627906976744187e-05,
      "loss": 1.782,
      "step": 25
    },
    {
      "epoch": 0.05543710021321962,
      "grad_norm": 36.344932556152344,
      "learning_rate": 1.2093023255813954e-05,
      "loss": 1.7362,
      "step": 26
    },
    {
      "epoch": 0.057569296375266525,
      "grad_norm": 38.6636962890625,
      "learning_rate": 1.2558139534883723e-05,
      "loss": 1.7765,
      "step": 27
    },
    {
      "epoch": 0.05970149253731343,
      "grad_norm": 32.3853874206543,
      "learning_rate": 1.302325581395349e-05,
      "loss": 1.5796,
      "step": 28
    },
    {
      "epoch": 0.06183368869936034,
      "grad_norm": 35.12067413330078,
      "learning_rate": 1.3488372093023257e-05,
      "loss": 1.5811,
      "step": 29
    },
    {
      "epoch": 0.06396588486140725,
      "grad_norm": 32.84918975830078,
      "learning_rate": 1.3953488372093025e-05,
      "loss": 1.4898,
      "step": 30
    },
    {
      "epoch": 0.06609808102345416,
      "grad_norm": 34.29348373413086,
      "learning_rate": 1.441860465116279e-05,
      "loss": 1.4864,
      "step": 31
    },
    {
      "epoch": 0.06823027718550106,
      "grad_norm": 36.052452087402344,
      "learning_rate": 1.488372093023256e-05,
      "loss": 1.4432,
      "step": 32
    },
    {
      "epoch": 0.07036247334754797,
      "grad_norm": 32.38676452636719,
      "learning_rate": 1.5348837209302328e-05,
      "loss": 1.3238,
      "step": 33
    },
    {
      "epoch": 0.07249466950959488,
      "grad_norm": 32.92742156982422,
      "learning_rate": 1.5813953488372095e-05,
      "loss": 1.2903,
      "step": 34
    },
    {
      "epoch": 0.07462686567164178,
      "grad_norm": 32.200618743896484,
      "learning_rate": 1.6279069767441862e-05,
      "loss": 1.2189,
      "step": 35
    },
    {
      "epoch": 0.0767590618336887,
      "grad_norm": 30.911319732666016,
      "learning_rate": 1.674418604651163e-05,
      "loss": 1.1683,
      "step": 36
    },
    {
      "epoch": 0.07889125799573561,
      "grad_norm": 31.70611000061035,
      "learning_rate": 1.7209302325581396e-05,
      "loss": 1.1322,
      "step": 37
    },
    {
      "epoch": 0.08102345415778252,
      "grad_norm": 28.541385650634766,
      "learning_rate": 1.7674418604651163e-05,
      "loss": 1.0269,
      "step": 38
    },
    {
      "epoch": 0.08315565031982942,
      "grad_norm": 25.2576847076416,
      "learning_rate": 1.813953488372093e-05,
      "loss": 0.9866,
      "step": 39
    },
    {
      "epoch": 0.08528784648187633,
      "grad_norm": 22.764301300048828,
      "learning_rate": 1.86046511627907e-05,
      "loss": 0.9445,
      "step": 40
    },
    {
      "epoch": 0.08742004264392324,
      "grad_norm": 22.68866539001465,
      "learning_rate": 1.9069767441860468e-05,
      "loss": 0.8719,
      "step": 41
    },
    {
      "epoch": 0.08955223880597014,
      "grad_norm": 19.025362014770508,
      "learning_rate": 1.9534883720930235e-05,
      "loss": 0.8058,
      "step": 42
    },
    {
      "epoch": 0.09168443496801706,
      "grad_norm": 18.470260620117188,
      "learning_rate": 2e-05,
      "loss": 0.7162,
      "step": 43
    },
    {
      "epoch": 0.09381663113006397,
      "grad_norm": 14.655425071716309,
      "learning_rate": 1.99999734758902e-05,
      "loss": 0.7295,
      "step": 44
    },
    {
      "epoch": 0.09594882729211088,
      "grad_norm": 11.394603729248047,
      "learning_rate": 1.99998939037015e-05,
      "loss": 0.6717,
      "step": 45
    },
    {
      "epoch": 0.09808102345415778,
      "grad_norm": 10.50560474395752,
      "learning_rate": 1.9999761283856016e-05,
      "loss": 0.6117,
      "step": 46
    },
    {
      "epoch": 0.10021321961620469,
      "grad_norm": 8.748003959655762,
      "learning_rate": 1.9999575617057277e-05,
      "loss": 0.5857,
      "step": 47
    },
    {
      "epoch": 0.1023454157782516,
      "grad_norm": 6.637113571166992,
      "learning_rate": 1.9999336904290208e-05,
      "loss": 0.5813,
      "step": 48
    },
    {
      "epoch": 0.1044776119402985,
      "grad_norm": 5.365267753601074,
      "learning_rate": 1.999904514682114e-05,
      "loss": 0.5658,
      "step": 49
    },
    {
      "epoch": 0.10660980810234541,
      "grad_norm": 3.8899459838867188,
      "learning_rate": 1.9998700346197797e-05,
      "loss": 0.5521,
      "step": 50
    },
    {
      "epoch": 0.10874200426439233,
      "grad_norm": 3.2472126483917236,
      "learning_rate": 1.9998302504249278e-05,
      "loss": 0.5391,
      "step": 51
    },
    {
      "epoch": 0.11087420042643924,
      "grad_norm": 2.6163809299468994,
      "learning_rate": 1.999785162308607e-05,
      "loss": 0.4896,
      "step": 52
    },
    {
      "epoch": 0.11300639658848614,
      "grad_norm": 1.9549809694290161,
      "learning_rate": 1.9997347705100015e-05,
      "loss": 0.5015,
      "step": 53
    },
    {
      "epoch": 0.11513859275053305,
      "grad_norm": 1.579596996307373,
      "learning_rate": 1.9996790752964305e-05,
      "loss": 0.4747,
      "step": 54
    },
    {
      "epoch": 0.11727078891257996,
      "grad_norm": 1.1847225427627563,
      "learning_rate": 1.999618076963348e-05,
      "loss": 0.4872,
      "step": 55
    },
    {
      "epoch": 0.11940298507462686,
      "grad_norm": 0.9594101905822754,
      "learning_rate": 1.9995517758343385e-05,
      "loss": 0.4764,
      "step": 56
    },
    {
      "epoch": 0.12153518123667377,
      "grad_norm": 0.76308274269104,
      "learning_rate": 1.999480172261118e-05,
      "loss": 0.4656,
      "step": 57
    },
    {
      "epoch": 0.12366737739872068,
      "grad_norm": 0.5690674185752869,
      "learning_rate": 1.999403266623531e-05,
      "loss": 0.5061,
      "step": 58
    },
    {
      "epoch": 0.1257995735607676,
      "grad_norm": 0.5343296527862549,
      "learning_rate": 1.9993210593295474e-05,
      "loss": 0.4213,
      "step": 59
    },
    {
      "epoch": 0.1279317697228145,
      "grad_norm": 0.45124873518943787,
      "learning_rate": 1.999233550815263e-05,
      "loss": 0.4614,
      "step": 60
    },
    {
      "epoch": 0.1300639658848614,
      "grad_norm": 0.3799026310443878,
      "learning_rate": 1.9991407415448948e-05,
      "loss": 0.4258,
      "step": 61
    },
    {
      "epoch": 0.13219616204690832,
      "grad_norm": 0.3704446852207184,
      "learning_rate": 1.9990426320107793e-05,
      "loss": 0.4098,
      "step": 62
    },
    {
      "epoch": 0.13432835820895522,
      "grad_norm": 0.31446149945259094,
      "learning_rate": 1.99893922273337e-05,
      "loss": 0.4535,
      "step": 63
    },
    {
      "epoch": 0.13646055437100213,
      "grad_norm": 0.31685709953308105,
      "learning_rate": 1.998830514261235e-05,
      "loss": 0.4654,
      "step": 64
    },
    {
      "epoch": 0.13859275053304904,
      "grad_norm": 0.2947236895561218,
      "learning_rate": 1.998716507171053e-05,
      "loss": 0.4573,
      "step": 65
    },
    {
      "epoch": 0.14072494669509594,
      "grad_norm": 0.29864493012428284,
      "learning_rate": 1.9985972020676116e-05,
      "loss": 0.4493,
      "step": 66
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 0.294145792722702,
      "learning_rate": 1.9984725995838032e-05,
      "loss": 0.4614,
      "step": 67
    },
    {
      "epoch": 0.14498933901918976,
      "grad_norm": 0.27030205726623535,
      "learning_rate": 1.9983427003806213e-05,
      "loss": 0.4324,
      "step": 68
    },
    {
      "epoch": 0.14712153518123666,
      "grad_norm": 0.28586962819099426,
      "learning_rate": 1.9982075051471588e-05,
      "loss": 0.445,
      "step": 69
    },
    {
      "epoch": 0.14925373134328357,
      "grad_norm": 0.27818435430526733,
      "learning_rate": 1.998067014600602e-05,
      "loss": 0.4507,
      "step": 70
    },
    {
      "epoch": 0.1513859275053305,
      "grad_norm": 0.2681903839111328,
      "learning_rate": 1.997921229486228e-05,
      "loss": 0.4278,
      "step": 71
    },
    {
      "epoch": 0.1535181236673774,
      "grad_norm": 0.2649684548377991,
      "learning_rate": 1.997770150577401e-05,
      "loss": 0.453,
      "step": 72
    },
    {
      "epoch": 0.15565031982942432,
      "grad_norm": 0.2772769331932068,
      "learning_rate": 1.9976137786755682e-05,
      "loss": 0.432,
      "step": 73
    },
    {
      "epoch": 0.15778251599147122,
      "grad_norm": 0.2591695785522461,
      "learning_rate": 1.9974521146102535e-05,
      "loss": 0.4541,
      "step": 74
    },
    {
      "epoch": 0.15991471215351813,
      "grad_norm": 0.2626112997531891,
      "learning_rate": 1.9972851592390573e-05,
      "loss": 0.4422,
      "step": 75
    },
    {
      "epoch": 0.16204690831556504,
      "grad_norm": 0.25730934739112854,
      "learning_rate": 1.9971129134476474e-05,
      "loss": 0.4477,
      "step": 76
    },
    {
      "epoch": 0.16417910447761194,
      "grad_norm": 0.25376155972480774,
      "learning_rate": 1.9969353781497575e-05,
      "loss": 0.4046,
      "step": 77
    },
    {
      "epoch": 0.16631130063965885,
      "grad_norm": 0.2609823942184448,
      "learning_rate": 1.9967525542871805e-05,
      "loss": 0.4462,
      "step": 78
    },
    {
      "epoch": 0.16844349680170576,
      "grad_norm": 0.24912501871585846,
      "learning_rate": 1.996564442829764e-05,
      "loss": 0.4214,
      "step": 79
    },
    {
      "epoch": 0.17057569296375266,
      "grad_norm": 0.25144603848457336,
      "learning_rate": 1.9963710447754065e-05,
      "loss": 0.3984,
      "step": 80
    },
    {
      "epoch": 0.17270788912579957,
      "grad_norm": 0.26654765009880066,
      "learning_rate": 1.99617236115005e-05,
      "loss": 0.443,
      "step": 81
    },
    {
      "epoch": 0.17484008528784648,
      "grad_norm": 0.26035812497138977,
      "learning_rate": 1.995968393007676e-05,
      "loss": 0.45,
      "step": 82
    },
    {
      "epoch": 0.17697228144989338,
      "grad_norm": 0.2404470294713974,
      "learning_rate": 1.9957591414302983e-05,
      "loss": 0.4262,
      "step": 83
    },
    {
      "epoch": 0.1791044776119403,
      "grad_norm": 0.26304617524147034,
      "learning_rate": 1.99554460752796e-05,
      "loss": 0.4602,
      "step": 84
    },
    {
      "epoch": 0.1812366737739872,
      "grad_norm": 0.26044321060180664,
      "learning_rate": 1.9953247924387255e-05,
      "loss": 0.4275,
      "step": 85
    },
    {
      "epoch": 0.18336886993603413,
      "grad_norm": 0.24924053251743317,
      "learning_rate": 1.9950996973286737e-05,
      "loss": 0.4459,
      "step": 86
    },
    {
      "epoch": 0.18550106609808104,
      "grad_norm": 0.25075456500053406,
      "learning_rate": 1.994869323391895e-05,
      "loss": 0.4174,
      "step": 87
    },
    {
      "epoch": 0.18763326226012794,
      "grad_norm": 0.2527909278869629,
      "learning_rate": 1.9946336718504823e-05,
      "loss": 0.4328,
      "step": 88
    },
    {
      "epoch": 0.18976545842217485,
      "grad_norm": 0.2574516534805298,
      "learning_rate": 1.9943927439545242e-05,
      "loss": 0.4579,
      "step": 89
    },
    {
      "epoch": 0.19189765458422176,
      "grad_norm": 0.26544156670570374,
      "learning_rate": 1.9941465409821008e-05,
      "loss": 0.4777,
      "step": 90
    },
    {
      "epoch": 0.19402985074626866,
      "grad_norm": 0.2686915397644043,
      "learning_rate": 1.993895064239275e-05,
      "loss": 0.3716,
      "step": 91
    },
    {
      "epoch": 0.19616204690831557,
      "grad_norm": 0.2614673674106598,
      "learning_rate": 1.9936383150600857e-05,
      "loss": 0.4386,
      "step": 92
    },
    {
      "epoch": 0.19829424307036247,
      "grad_norm": 0.2485521137714386,
      "learning_rate": 1.9933762948065423e-05,
      "loss": 0.4071,
      "step": 93
    },
    {
      "epoch": 0.20042643923240938,
      "grad_norm": 0.2640252113342285,
      "learning_rate": 1.9931090048686152e-05,
      "loss": 0.4314,
      "step": 94
    },
    {
      "epoch": 0.2025586353944563,
      "grad_norm": 0.24777109920978546,
      "learning_rate": 1.99283644666423e-05,
      "loss": 0.4124,
      "step": 95
    },
    {
      "epoch": 0.2046908315565032,
      "grad_norm": 0.23599018156528473,
      "learning_rate": 1.9925586216392597e-05,
      "loss": 0.4221,
      "step": 96
    },
    {
      "epoch": 0.2068230277185501,
      "grad_norm": 0.2616764307022095,
      "learning_rate": 1.9922755312675157e-05,
      "loss": 0.4311,
      "step": 97
    },
    {
      "epoch": 0.208955223880597,
      "grad_norm": 0.2570851445198059,
      "learning_rate": 1.991987177050743e-05,
      "loss": 0.41,
      "step": 98
    },
    {
      "epoch": 0.21108742004264391,
      "grad_norm": 0.249265655875206,
      "learning_rate": 1.9916935605186092e-05,
      "loss": 0.4089,
      "step": 99
    },
    {
      "epoch": 0.21321961620469082,
      "grad_norm": 0.2436961829662323,
      "learning_rate": 1.9913946832286976e-05,
      "loss": 0.4017,
      "step": 100
    },
    {
      "epoch": 0.21535181236673773,
      "grad_norm": 0.24480605125427246,
      "learning_rate": 1.9910905467664986e-05,
      "loss": 0.416,
      "step": 101
    },
    {
      "epoch": 0.21748400852878466,
      "grad_norm": 0.24884916841983795,
      "learning_rate": 1.990781152745403e-05,
      "loss": 0.4329,
      "step": 102
    },
    {
      "epoch": 0.21961620469083157,
      "grad_norm": 0.24858634173870087,
      "learning_rate": 1.9904665028066898e-05,
      "loss": 0.4326,
      "step": 103
    },
    {
      "epoch": 0.22174840085287847,
      "grad_norm": 0.2357385754585266,
      "learning_rate": 1.9901465986195216e-05,
      "loss": 0.39,
      "step": 104
    },
    {
      "epoch": 0.22388059701492538,
      "grad_norm": 0.26147767901420593,
      "learning_rate": 1.989821441880933e-05,
      "loss": 0.4478,
      "step": 105
    },
    {
      "epoch": 0.2260127931769723,
      "grad_norm": 0.24829845130443573,
      "learning_rate": 1.9894910343158223e-05,
      "loss": 0.4091,
      "step": 106
    },
    {
      "epoch": 0.2281449893390192,
      "grad_norm": 0.25650495290756226,
      "learning_rate": 1.989155377676944e-05,
      "loss": 0.4497,
      "step": 107
    },
    {
      "epoch": 0.2302771855010661,
      "grad_norm": 0.24211230874061584,
      "learning_rate": 1.988814473744895e-05,
      "loss": 0.4144,
      "step": 108
    },
    {
      "epoch": 0.232409381663113,
      "grad_norm": 0.2755013108253479,
      "learning_rate": 1.9884683243281117e-05,
      "loss": 0.4213,
      "step": 109
    },
    {
      "epoch": 0.2345415778251599,
      "grad_norm": 0.24887137115001678,
      "learning_rate": 1.9881169312628538e-05,
      "loss": 0.4154,
      "step": 110
    },
    {
      "epoch": 0.23667377398720682,
      "grad_norm": 0.26873546838760376,
      "learning_rate": 1.9877602964131996e-05,
      "loss": 0.4416,
      "step": 111
    },
    {
      "epoch": 0.23880597014925373,
      "grad_norm": 0.24886871874332428,
      "learning_rate": 1.9873984216710336e-05,
      "loss": 0.4318,
      "step": 112
    },
    {
      "epoch": 0.24093816631130063,
      "grad_norm": 0.23374877870082855,
      "learning_rate": 1.9870313089560365e-05,
      "loss": 0.3823,
      "step": 113
    },
    {
      "epoch": 0.24307036247334754,
      "grad_norm": 0.25990989804267883,
      "learning_rate": 1.986658960215676e-05,
      "loss": 0.3995,
      "step": 114
    },
    {
      "epoch": 0.24520255863539445,
      "grad_norm": 0.2538311183452606,
      "learning_rate": 1.986281377425196e-05,
      "loss": 0.4153,
      "step": 115
    },
    {
      "epoch": 0.24733475479744135,
      "grad_norm": 0.27877363562583923,
      "learning_rate": 1.9858985625876056e-05,
      "loss": 0.4138,
      "step": 116
    },
    {
      "epoch": 0.24946695095948826,
      "grad_norm": 0.26093608140945435,
      "learning_rate": 1.98551051773367e-05,
      "loss": 0.4113,
      "step": 117
    },
    {
      "epoch": 0.2515991471215352,
      "grad_norm": 0.2540494203567505,
      "learning_rate": 1.9851172449218978e-05,
      "loss": 0.4187,
      "step": 118
    },
    {
      "epoch": 0.2537313432835821,
      "grad_norm": 0.2522899806499481,
      "learning_rate": 1.984718746238531e-05,
      "loss": 0.4096,
      "step": 119
    },
    {
      "epoch": 0.255863539445629,
      "grad_norm": 0.2474694699048996,
      "learning_rate": 1.9843150237975343e-05,
      "loss": 0.4139,
      "step": 120
    },
    {
      "epoch": 0.2579957356076759,
      "grad_norm": 0.24110227823257446,
      "learning_rate": 1.9839060797405834e-05,
      "loss": 0.3986,
      "step": 121
    },
    {
      "epoch": 0.2601279317697228,
      "grad_norm": 0.24558144807815552,
      "learning_rate": 1.9834919162370538e-05,
      "loss": 0.3798,
      "step": 122
    },
    {
      "epoch": 0.2622601279317697,
      "grad_norm": 0.24035534262657166,
      "learning_rate": 1.983072535484009e-05,
      "loss": 0.3947,
      "step": 123
    },
    {
      "epoch": 0.26439232409381663,
      "grad_norm": 0.24366366863250732,
      "learning_rate": 1.9826479397061893e-05,
      "loss": 0.4014,
      "step": 124
    },
    {
      "epoch": 0.26652452025586354,
      "grad_norm": 0.23440906405448914,
      "learning_rate": 1.9822181311559995e-05,
      "loss": 0.369,
      "step": 125
    },
    {
      "epoch": 0.26865671641791045,
      "grad_norm": 0.256561279296875,
      "learning_rate": 1.981783112113498e-05,
      "loss": 0.3931,
      "step": 126
    },
    {
      "epoch": 0.27078891257995735,
      "grad_norm": 0.2545720338821411,
      "learning_rate": 1.9813428848863828e-05,
      "loss": 0.4172,
      "step": 127
    },
    {
      "epoch": 0.27292110874200426,
      "grad_norm": 0.2357325553894043,
      "learning_rate": 1.9808974518099813e-05,
      "loss": 0.3757,
      "step": 128
    },
    {
      "epoch": 0.27505330490405117,
      "grad_norm": 0.24853190779685974,
      "learning_rate": 1.9804468152472364e-05,
      "loss": 0.4055,
      "step": 129
    },
    {
      "epoch": 0.2771855010660981,
      "grad_norm": 0.25481805205345154,
      "learning_rate": 1.9799909775886948e-05,
      "loss": 0.4114,
      "step": 130
    },
    {
      "epoch": 0.279317697228145,
      "grad_norm": 0.26429474353790283,
      "learning_rate": 1.9795299412524948e-05,
      "loss": 0.4498,
      "step": 131
    },
    {
      "epoch": 0.2814498933901919,
      "grad_norm": 0.23735523223876953,
      "learning_rate": 1.979063708684351e-05,
      "loss": 0.4013,
      "step": 132
    },
    {
      "epoch": 0.2835820895522388,
      "grad_norm": 0.29319894313812256,
      "learning_rate": 1.978592282357545e-05,
      "loss": 0.4199,
      "step": 133
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.23747026920318604,
      "learning_rate": 1.9781156647729092e-05,
      "loss": 0.3744,
      "step": 134
    },
    {
      "epoch": 0.2878464818763326,
      "grad_norm": 0.2366279661655426,
      "learning_rate": 1.9776338584588153e-05,
      "loss": 0.3503,
      "step": 135
    },
    {
      "epoch": 0.2899786780383795,
      "grad_norm": 0.3119730055332184,
      "learning_rate": 1.9771468659711595e-05,
      "loss": 0.4073,
      "step": 136
    },
    {
      "epoch": 0.2921108742004264,
      "grad_norm": 0.264453649520874,
      "learning_rate": 1.976654689893351e-05,
      "loss": 0.4027,
      "step": 137
    },
    {
      "epoch": 0.2942430703624733,
      "grad_norm": 0.24872872233390808,
      "learning_rate": 1.9761573328362954e-05,
      "loss": 0.3971,
      "step": 138
    },
    {
      "epoch": 0.29637526652452023,
      "grad_norm": 0.2745459973812103,
      "learning_rate": 1.975654797438384e-05,
      "loss": 0.4184,
      "step": 139
    },
    {
      "epoch": 0.29850746268656714,
      "grad_norm": 0.2831178605556488,
      "learning_rate": 1.9751470863654773e-05,
      "loss": 0.4049,
      "step": 140
    },
    {
      "epoch": 0.3006396588486141,
      "grad_norm": 0.25548288226127625,
      "learning_rate": 1.974634202310892e-05,
      "loss": 0.3872,
      "step": 141
    },
    {
      "epoch": 0.302771855010661,
      "grad_norm": 0.2790493071079254,
      "learning_rate": 1.9741161479953872e-05,
      "loss": 0.4084,
      "step": 142
    },
    {
      "epoch": 0.3049040511727079,
      "grad_norm": 0.2786419987678528,
      "learning_rate": 1.9735929261671484e-05,
      "loss": 0.4041,
      "step": 143
    },
    {
      "epoch": 0.3070362473347548,
      "grad_norm": 0.24856948852539062,
      "learning_rate": 1.9730645396017746e-05,
      "loss": 0.3949,
      "step": 144
    },
    {
      "epoch": 0.3091684434968017,
      "grad_norm": 0.2579636871814728,
      "learning_rate": 1.9725309911022617e-05,
      "loss": 0.4003,
      "step": 145
    },
    {
      "epoch": 0.31130063965884863,
      "grad_norm": 0.30625444650650024,
      "learning_rate": 1.9719922834989905e-05,
      "loss": 0.3884,
      "step": 146
    },
    {
      "epoch": 0.31343283582089554,
      "grad_norm": 0.2491229921579361,
      "learning_rate": 1.9714484196497087e-05,
      "loss": 0.3904,
      "step": 147
    },
    {
      "epoch": 0.31556503198294245,
      "grad_norm": 0.24527886509895325,
      "learning_rate": 1.9708994024395163e-05,
      "loss": 0.3792,
      "step": 148
    },
    {
      "epoch": 0.31769722814498935,
      "grad_norm": 0.2960670292377472,
      "learning_rate": 1.9703452347808527e-05,
      "loss": 0.3681,
      "step": 149
    },
    {
      "epoch": 0.31982942430703626,
      "grad_norm": 0.26091012358665466,
      "learning_rate": 1.9697859196134786e-05,
      "loss": 0.3736,
      "step": 150
    },
    {
      "epoch": 0.32196162046908317,
      "grad_norm": 0.2602207660675049,
      "learning_rate": 1.969221459904461e-05,
      "loss": 0.3938,
      "step": 151
    },
    {
      "epoch": 0.32409381663113007,
      "grad_norm": 0.2525958716869354,
      "learning_rate": 1.9686518586481585e-05,
      "loss": 0.3978,
      "step": 152
    },
    {
      "epoch": 0.326226012793177,
      "grad_norm": 0.2542193531990051,
      "learning_rate": 1.9680771188662044e-05,
      "loss": 0.3777,
      "step": 153
    },
    {
      "epoch": 0.3283582089552239,
      "grad_norm": 0.2691692113876343,
      "learning_rate": 1.9674972436074907e-05,
      "loss": 0.3927,
      "step": 154
    },
    {
      "epoch": 0.3304904051172708,
      "grad_norm": 0.26398754119873047,
      "learning_rate": 1.9669122359481526e-05,
      "loss": 0.3864,
      "step": 155
    },
    {
      "epoch": 0.3326226012793177,
      "grad_norm": 0.24671801924705505,
      "learning_rate": 1.9663220989915513e-05,
      "loss": 0.3501,
      "step": 156
    },
    {
      "epoch": 0.3347547974413646,
      "grad_norm": 0.25479355454444885,
      "learning_rate": 1.9657268358682584e-05,
      "loss": 0.3843,
      "step": 157
    },
    {
      "epoch": 0.3368869936034115,
      "grad_norm": 0.2571786642074585,
      "learning_rate": 1.965126449736039e-05,
      "loss": 0.3942,
      "step": 158
    },
    {
      "epoch": 0.3390191897654584,
      "grad_norm": 0.2532227337360382,
      "learning_rate": 1.964520943779834e-05,
      "loss": 0.3727,
      "step": 159
    },
    {
      "epoch": 0.3411513859275053,
      "grad_norm": 0.2600748836994171,
      "learning_rate": 1.9639103212117458e-05,
      "loss": 0.378,
      "step": 160
    },
    {
      "epoch": 0.34328358208955223,
      "grad_norm": 0.2465021312236786,
      "learning_rate": 1.9632945852710175e-05,
      "loss": 0.3836,
      "step": 161
    },
    {
      "epoch": 0.34541577825159914,
      "grad_norm": 0.25942713022232056,
      "learning_rate": 1.962673739224019e-05,
      "loss": 0.3859,
      "step": 162
    },
    {
      "epoch": 0.34754797441364604,
      "grad_norm": 0.2885582745075226,
      "learning_rate": 1.9620477863642277e-05,
      "loss": 0.4033,
      "step": 163
    },
    {
      "epoch": 0.34968017057569295,
      "grad_norm": 0.2530713379383087,
      "learning_rate": 1.9614167300122126e-05,
      "loss": 0.3973,
      "step": 164
    },
    {
      "epoch": 0.35181236673773986,
      "grad_norm": 0.2494288831949234,
      "learning_rate": 1.960780573515615e-05,
      "loss": 0.3514,
      "step": 165
    },
    {
      "epoch": 0.35394456289978676,
      "grad_norm": 0.2463092803955078,
      "learning_rate": 1.9601393202491316e-05,
      "loss": 0.3693,
      "step": 166
    },
    {
      "epoch": 0.35607675906183367,
      "grad_norm": 0.2337418645620346,
      "learning_rate": 1.9594929736144978e-05,
      "loss": 0.3566,
      "step": 167
    },
    {
      "epoch": 0.3582089552238806,
      "grad_norm": 0.25344276428222656,
      "learning_rate": 1.958841537040466e-05,
      "loss": 0.374,
      "step": 168
    },
    {
      "epoch": 0.3603411513859275,
      "grad_norm": 0.27227234840393066,
      "learning_rate": 1.9581850139827924e-05,
      "loss": 0.3936,
      "step": 169
    },
    {
      "epoch": 0.3624733475479744,
      "grad_norm": 0.27064722776412964,
      "learning_rate": 1.9575234079242143e-05,
      "loss": 0.362,
      "step": 170
    },
    {
      "epoch": 0.3646055437100213,
      "grad_norm": 0.25571441650390625,
      "learning_rate": 1.956856722374434e-05,
      "loss": 0.3705,
      "step": 171
    },
    {
      "epoch": 0.36673773987206826,
      "grad_norm": 0.2628113925457001,
      "learning_rate": 1.9561849608701e-05,
      "loss": 0.3485,
      "step": 172
    },
    {
      "epoch": 0.36886993603411516,
      "grad_norm": 0.2578686773777008,
      "learning_rate": 1.9555081269747877e-05,
      "loss": 0.3718,
      "step": 173
    },
    {
      "epoch": 0.37100213219616207,
      "grad_norm": 0.2601796090602875,
      "learning_rate": 1.9548262242789797e-05,
      "loss": 0.3686,
      "step": 174
    },
    {
      "epoch": 0.373134328358209,
      "grad_norm": 0.3198471665382385,
      "learning_rate": 1.954139256400049e-05,
      "loss": 0.387,
      "step": 175
    },
    {
      "epoch": 0.3752665245202559,
      "grad_norm": 0.2489587664604187,
      "learning_rate": 1.9534472269822377e-05,
      "loss": 0.3642,
      "step": 176
    },
    {
      "epoch": 0.3773987206823028,
      "grad_norm": 0.25361308455467224,
      "learning_rate": 1.9527501396966383e-05,
      "loss": 0.39,
      "step": 177
    },
    {
      "epoch": 0.3795309168443497,
      "grad_norm": 0.277118980884552,
      "learning_rate": 1.9520479982411756e-05,
      "loss": 0.3932,
      "step": 178
    },
    {
      "epoch": 0.3816631130063966,
      "grad_norm": 0.25245848298072815,
      "learning_rate": 1.9513408063405838e-05,
      "loss": 0.3853,
      "step": 179
    },
    {
      "epoch": 0.3837953091684435,
      "grad_norm": 0.25179702043533325,
      "learning_rate": 1.9506285677463913e-05,
      "loss": 0.3743,
      "step": 180
    },
    {
      "epoch": 0.3859275053304904,
      "grad_norm": 0.2634812593460083,
      "learning_rate": 1.949911286236896e-05,
      "loss": 0.3712,
      "step": 181
    },
    {
      "epoch": 0.3880597014925373,
      "grad_norm": 0.2464388757944107,
      "learning_rate": 1.9491889656171493e-05,
      "loss": 0.3388,
      "step": 182
    },
    {
      "epoch": 0.39019189765458423,
      "grad_norm": 0.2677946388721466,
      "learning_rate": 1.948461609718933e-05,
      "loss": 0.3664,
      "step": 183
    },
    {
      "epoch": 0.39232409381663114,
      "grad_norm": 0.3251895606517792,
      "learning_rate": 1.947729222400741e-05,
      "loss": 0.3565,
      "step": 184
    },
    {
      "epoch": 0.39445628997867804,
      "grad_norm": 0.2506219744682312,
      "learning_rate": 1.9469918075477575e-05,
      "loss": 0.3325,
      "step": 185
    },
    {
      "epoch": 0.39658848614072495,
      "grad_norm": 0.2552160322666168,
      "learning_rate": 1.9462493690718373e-05,
      "loss": 0.3525,
      "step": 186
    },
    {
      "epoch": 0.39872068230277186,
      "grad_norm": 0.2731989920139313,
      "learning_rate": 1.9455019109114833e-05,
      "loss": 0.3489,
      "step": 187
    },
    {
      "epoch": 0.40085287846481876,
      "grad_norm": 0.2601653039455414,
      "learning_rate": 1.944749437031829e-05,
      "loss": 0.3648,
      "step": 188
    },
    {
      "epoch": 0.40298507462686567,
      "grad_norm": 0.26022928953170776,
      "learning_rate": 1.9439919514246146e-05,
      "loss": 0.3674,
      "step": 189
    },
    {
      "epoch": 0.4051172707889126,
      "grad_norm": 0.25961220264434814,
      "learning_rate": 1.943229458108165e-05,
      "loss": 0.3496,
      "step": 190
    },
    {
      "epoch": 0.4072494669509595,
      "grad_norm": 0.23998413980007172,
      "learning_rate": 1.9424619611273726e-05,
      "loss": 0.3393,
      "step": 191
    },
    {
      "epoch": 0.4093816631130064,
      "grad_norm": 0.25406593084335327,
      "learning_rate": 1.9416894645536722e-05,
      "loss": 0.3785,
      "step": 192
    },
    {
      "epoch": 0.4115138592750533,
      "grad_norm": 0.2699589729309082,
      "learning_rate": 1.9409119724850202e-05,
      "loss": 0.3711,
      "step": 193
    },
    {
      "epoch": 0.4136460554371002,
      "grad_norm": 0.2605101466178894,
      "learning_rate": 1.940129489045874e-05,
      "loss": 0.3577,
      "step": 194
    },
    {
      "epoch": 0.4157782515991471,
      "grad_norm": 0.24771268665790558,
      "learning_rate": 1.9393420183871684e-05,
      "loss": 0.3448,
      "step": 195
    },
    {
      "epoch": 0.417910447761194,
      "grad_norm": 0.2559705078601837,
      "learning_rate": 1.9385495646862954e-05,
      "loss": 0.3511,
      "step": 196
    },
    {
      "epoch": 0.4200426439232409,
      "grad_norm": 0.25951454043388367,
      "learning_rate": 1.9377521321470806e-05,
      "loss": 0.3499,
      "step": 197
    },
    {
      "epoch": 0.42217484008528783,
      "grad_norm": 0.27584514021873474,
      "learning_rate": 1.936949724999762e-05,
      "loss": 0.357,
      "step": 198
    },
    {
      "epoch": 0.42430703624733473,
      "grad_norm": 0.25427520275115967,
      "learning_rate": 1.9361423475009663e-05,
      "loss": 0.3609,
      "step": 199
    },
    {
      "epoch": 0.42643923240938164,
      "grad_norm": 0.25705263018608093,
      "learning_rate": 1.9353300039336874e-05,
      "loss": 0.3617,
      "step": 200
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 0.2544158697128296,
      "learning_rate": 1.9345126986072636e-05,
      "loss": 0.3286,
      "step": 201
    },
    {
      "epoch": 0.43070362473347545,
      "grad_norm": 0.25426429510116577,
      "learning_rate": 1.9336904358573538e-05,
      "loss": 0.3152,
      "step": 202
    },
    {
      "epoch": 0.43283582089552236,
      "grad_norm": 0.24564635753631592,
      "learning_rate": 1.9328632200459157e-05,
      "loss": 0.3542,
      "step": 203
    },
    {
      "epoch": 0.4349680170575693,
      "grad_norm": 0.26883381605148315,
      "learning_rate": 1.932031055561182e-05,
      "loss": 0.3432,
      "step": 204
    },
    {
      "epoch": 0.43710021321961623,
      "grad_norm": 0.2710798382759094,
      "learning_rate": 1.9311939468176368e-05,
      "loss": 0.3455,
      "step": 205
    },
    {
      "epoch": 0.43923240938166314,
      "grad_norm": 0.25286975502967834,
      "learning_rate": 1.930351898255993e-05,
      "loss": 0.3492,
      "step": 206
    },
    {
      "epoch": 0.44136460554371004,
      "grad_norm": 0.2688445448875427,
      "learning_rate": 1.9295049143431685e-05,
      "loss": 0.3582,
      "step": 207
    },
    {
      "epoch": 0.44349680170575695,
      "grad_norm": 0.27447569370269775,
      "learning_rate": 1.9286529995722624e-05,
      "loss": 0.3765,
      "step": 208
    },
    {
      "epoch": 0.44562899786780386,
      "grad_norm": 0.25451022386550903,
      "learning_rate": 1.9277961584625302e-05,
      "loss": 0.349,
      "step": 209
    },
    {
      "epoch": 0.44776119402985076,
      "grad_norm": 0.2788371443748474,
      "learning_rate": 1.926934395559362e-05,
      "loss": 0.3679,
      "step": 210
    },
    {
      "epoch": 0.44989339019189767,
      "grad_norm": 0.2575949728488922,
      "learning_rate": 1.9260677154342563e-05,
      "loss": 0.3324,
      "step": 211
    },
    {
      "epoch": 0.4520255863539446,
      "grad_norm": 0.30261996388435364,
      "learning_rate": 1.925196122684797e-05,
      "loss": 0.3822,
      "step": 212
    },
    {
      "epoch": 0.4541577825159915,
      "grad_norm": 0.254303902387619,
      "learning_rate": 1.9243196219346285e-05,
      "loss": 0.3303,
      "step": 213
    },
    {
      "epoch": 0.4562899786780384,
      "grad_norm": 0.262223482131958,
      "learning_rate": 1.923438217833431e-05,
      "loss": 0.35,
      "step": 214
    },
    {
      "epoch": 0.4584221748400853,
      "grad_norm": 0.2742505371570587,
      "learning_rate": 1.9225519150568966e-05,
      "loss": 0.3609,
      "step": 215
    },
    {
      "epoch": 0.4605543710021322,
      "grad_norm": 0.2455277442932129,
      "learning_rate": 1.9216607183067033e-05,
      "loss": 0.3542,
      "step": 216
    },
    {
      "epoch": 0.4626865671641791,
      "grad_norm": 0.26327061653137207,
      "learning_rate": 1.9207646323104917e-05,
      "loss": 0.3464,
      "step": 217
    },
    {
      "epoch": 0.464818763326226,
      "grad_norm": 0.2505815029144287,
      "learning_rate": 1.9198636618218382e-05,
      "loss": 0.3172,
      "step": 218
    },
    {
      "epoch": 0.4669509594882729,
      "grad_norm": 0.26254621148109436,
      "learning_rate": 1.918957811620231e-05,
      "loss": 0.3442,
      "step": 219
    },
    {
      "epoch": 0.4690831556503198,
      "grad_norm": 0.258059561252594,
      "learning_rate": 1.9180470865110438e-05,
      "loss": 0.3587,
      "step": 220
    },
    {
      "epoch": 0.47121535181236673,
      "grad_norm": 0.2625110447406769,
      "learning_rate": 1.9171314913255114e-05,
      "loss": 0.3479,
      "step": 221
    },
    {
      "epoch": 0.47334754797441364,
      "grad_norm": 0.25870445370674133,
      "learning_rate": 1.9162110309207034e-05,
      "loss": 0.3204,
      "step": 222
    },
    {
      "epoch": 0.47547974413646055,
      "grad_norm": 0.27490776777267456,
      "learning_rate": 1.915285710179498e-05,
      "loss": 0.3545,
      "step": 223
    },
    {
      "epoch": 0.47761194029850745,
      "grad_norm": 0.2577129602432251,
      "learning_rate": 1.9143555340105573e-05,
      "loss": 0.3203,
      "step": 224
    },
    {
      "epoch": 0.47974413646055436,
      "grad_norm": 0.3095560073852539,
      "learning_rate": 1.9134205073483003e-05,
      "loss": 0.3401,
      "step": 225
    },
    {
      "epoch": 0.48187633262260127,
      "grad_norm": 0.2752231955528259,
      "learning_rate": 1.9124806351528766e-05,
      "loss": 0.3604,
      "step": 226
    },
    {
      "epoch": 0.4840085287846482,
      "grad_norm": 0.2619611322879791,
      "learning_rate": 1.9115359224101416e-05,
      "loss": 0.3298,
      "step": 227
    },
    {
      "epoch": 0.4861407249466951,
      "grad_norm": 0.29869234561920166,
      "learning_rate": 1.910586374131627e-05,
      "loss": 0.3319,
      "step": 228
    },
    {
      "epoch": 0.488272921108742,
      "grad_norm": 0.26134297251701355,
      "learning_rate": 1.9096319953545186e-05,
      "loss": 0.3368,
      "step": 229
    },
    {
      "epoch": 0.4904051172707889,
      "grad_norm": 0.2740339934825897,
      "learning_rate": 1.908672791141625e-05,
      "loss": 0.3633,
      "step": 230
    },
    {
      "epoch": 0.4925373134328358,
      "grad_norm": 0.2742077708244324,
      "learning_rate": 1.9077087665813547e-05,
      "loss": 0.3564,
      "step": 231
    },
    {
      "epoch": 0.4946695095948827,
      "grad_norm": 0.3028295636177063,
      "learning_rate": 1.906739926787685e-05,
      "loss": 0.318,
      "step": 232
    },
    {
      "epoch": 0.4968017057569296,
      "grad_norm": 0.26541098952293396,
      "learning_rate": 1.9057662769001397e-05,
      "loss": 0.349,
      "step": 233
    },
    {
      "epoch": 0.4989339019189765,
      "grad_norm": 0.2782990038394928,
      "learning_rate": 1.9047878220837577e-05,
      "loss": 0.341,
      "step": 234
    },
    {
      "epoch": 0.5010660980810234,
      "grad_norm": 0.3131334185600281,
      "learning_rate": 1.9038045675290674e-05,
      "loss": 0.3374,
      "step": 235
    },
    {
      "epoch": 0.5031982942430704,
      "grad_norm": 0.32440224289894104,
      "learning_rate": 1.9028165184520598e-05,
      "loss": 0.3386,
      "step": 236
    },
    {
      "epoch": 0.5053304904051172,
      "grad_norm": 0.2783079743385315,
      "learning_rate": 1.9018236800941584e-05,
      "loss": 0.3356,
      "step": 237
    },
    {
      "epoch": 0.5074626865671642,
      "grad_norm": 0.2877621650695801,
      "learning_rate": 1.9008260577221945e-05,
      "loss": 0.3372,
      "step": 238
    },
    {
      "epoch": 0.509594882729211,
      "grad_norm": 0.2922506034374237,
      "learning_rate": 1.8998236566283774e-05,
      "loss": 0.3137,
      "step": 239
    },
    {
      "epoch": 0.511727078891258,
      "grad_norm": 0.27668625116348267,
      "learning_rate": 1.8988164821302662e-05,
      "loss": 0.3394,
      "step": 240
    },
    {
      "epoch": 0.5138592750533049,
      "grad_norm": 0.28183960914611816,
      "learning_rate": 1.897804539570742e-05,
      "loss": 0.3361,
      "step": 241
    },
    {
      "epoch": 0.5159914712153518,
      "grad_norm": 0.3169099688529968,
      "learning_rate": 1.89678783431798e-05,
      "loss": 0.348,
      "step": 242
    },
    {
      "epoch": 0.5181236673773987,
      "grad_norm": 0.29081133008003235,
      "learning_rate": 1.895766371765421e-05,
      "loss": 0.3587,
      "step": 243
    },
    {
      "epoch": 0.5202558635394456,
      "grad_norm": 0.261508971452713,
      "learning_rate": 1.8947401573317412e-05,
      "loss": 0.3203,
      "step": 244
    },
    {
      "epoch": 0.5223880597014925,
      "grad_norm": 0.3099935054779053,
      "learning_rate": 1.8937091964608263e-05,
      "loss": 0.316,
      "step": 245
    },
    {
      "epoch": 0.5245202558635395,
      "grad_norm": 0.286878377199173,
      "learning_rate": 1.8926734946217394e-05,
      "loss": 0.3341,
      "step": 246
    },
    {
      "epoch": 0.5266524520255863,
      "grad_norm": 0.2669479548931122,
      "learning_rate": 1.8916330573086953e-05,
      "loss": 0.339,
      "step": 247
    },
    {
      "epoch": 0.5287846481876333,
      "grad_norm": 0.2887333929538727,
      "learning_rate": 1.8905878900410278e-05,
      "loss": 0.3407,
      "step": 248
    },
    {
      "epoch": 0.5309168443496801,
      "grad_norm": 0.347171813249588,
      "learning_rate": 1.8895379983631638e-05,
      "loss": 0.3435,
      "step": 249
    },
    {
      "epoch": 0.5330490405117271,
      "grad_norm": 0.26600581407546997,
      "learning_rate": 1.8884833878445912e-05,
      "loss": 0.3105,
      "step": 250
    },
    {
      "epoch": 0.535181236673774,
      "grad_norm": 0.29781773686408997,
      "learning_rate": 1.8874240640798316e-05,
      "loss": 0.3282,
      "step": 251
    },
    {
      "epoch": 0.5373134328358209,
      "grad_norm": 0.2742546498775482,
      "learning_rate": 1.8863600326884085e-05,
      "loss": 0.3259,
      "step": 252
    },
    {
      "epoch": 0.5394456289978679,
      "grad_norm": 0.26835113763809204,
      "learning_rate": 1.885291299314819e-05,
      "loss": 0.3301,
      "step": 253
    },
    {
      "epoch": 0.5415778251599147,
      "grad_norm": 0.2762032151222229,
      "learning_rate": 1.8842178696285037e-05,
      "loss": 0.3259,
      "step": 254
    },
    {
      "epoch": 0.5437100213219617,
      "grad_norm": 0.30398309230804443,
      "learning_rate": 1.883139749323816e-05,
      "loss": 0.3435,
      "step": 255
    },
    {
      "epoch": 0.5458422174840085,
      "grad_norm": 0.27944865822792053,
      "learning_rate": 1.8820569441199915e-05,
      "loss": 0.3372,
      "step": 256
    },
    {
      "epoch": 0.5479744136460555,
      "grad_norm": 0.2708320617675781,
      "learning_rate": 1.88096945976112e-05,
      "loss": 0.3457,
      "step": 257
    },
    {
      "epoch": 0.5501066098081023,
      "grad_norm": 0.2933814525604248,
      "learning_rate": 1.879877302016112e-05,
      "loss": 0.316,
      "step": 258
    },
    {
      "epoch": 0.5522388059701493,
      "grad_norm": 0.2716354727745056,
      "learning_rate": 1.8787804766786693e-05,
      "loss": 0.333,
      "step": 259
    },
    {
      "epoch": 0.5543710021321961,
      "grad_norm": 0.2760998010635376,
      "learning_rate": 1.8776789895672557e-05,
      "loss": 0.3329,
      "step": 260
    },
    {
      "epoch": 0.5565031982942431,
      "grad_norm": 0.27594494819641113,
      "learning_rate": 1.8765728465250643e-05,
      "loss": 0.2959,
      "step": 261
    },
    {
      "epoch": 0.55863539445629,
      "grad_norm": 0.26369357109069824,
      "learning_rate": 1.8754620534199864e-05,
      "loss": 0.3169,
      "step": 262
    },
    {
      "epoch": 0.5607675906183369,
      "grad_norm": 0.29383692145347595,
      "learning_rate": 1.8743466161445823e-05,
      "loss": 0.3323,
      "step": 263
    },
    {
      "epoch": 0.5628997867803838,
      "grad_norm": 0.2603667974472046,
      "learning_rate": 1.8732265406160478e-05,
      "loss": 0.3027,
      "step": 264
    },
    {
      "epoch": 0.5650319829424307,
      "grad_norm": 0.2740887403488159,
      "learning_rate": 1.872101832776184e-05,
      "loss": 0.2992,
      "step": 265
    },
    {
      "epoch": 0.5671641791044776,
      "grad_norm": 0.277098685503006,
      "learning_rate": 1.8709724985913662e-05,
      "loss": 0.3208,
      "step": 266
    },
    {
      "epoch": 0.5692963752665245,
      "grad_norm": 0.2761559784412384,
      "learning_rate": 1.869838544052511e-05,
      "loss": 0.3117,
      "step": 267
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.273932546377182,
      "learning_rate": 1.868699975175045e-05,
      "loss": 0.2994,
      "step": 268
    },
    {
      "epoch": 0.5735607675906184,
      "grad_norm": 0.29604673385620117,
      "learning_rate": 1.8675567979988742e-05,
      "loss": 0.3352,
      "step": 269
    },
    {
      "epoch": 0.5756929637526652,
      "grad_norm": 0.2657366096973419,
      "learning_rate": 1.8664090185883494e-05,
      "loss": 0.286,
      "step": 270
    },
    {
      "epoch": 0.5778251599147122,
      "grad_norm": 0.2657814621925354,
      "learning_rate": 1.8652566430322355e-05,
      "loss": 0.3065,
      "step": 271
    },
    {
      "epoch": 0.579957356076759,
      "grad_norm": 0.2707808315753937,
      "learning_rate": 1.864099677443681e-05,
      "loss": 0.3139,
      "step": 272
    },
    {
      "epoch": 0.582089552238806,
      "grad_norm": 0.2708495259284973,
      "learning_rate": 1.862938127960181e-05,
      "loss": 0.3038,
      "step": 273
    },
    {
      "epoch": 0.5842217484008528,
      "grad_norm": 0.26454949378967285,
      "learning_rate": 1.8617720007435497e-05,
      "loss": 0.2914,
      "step": 274
    },
    {
      "epoch": 0.5863539445628998,
      "grad_norm": 0.26289162039756775,
      "learning_rate": 1.860601301979884e-05,
      "loss": 0.2903,
      "step": 275
    },
    {
      "epoch": 0.5884861407249466,
      "grad_norm": 0.27449753880500793,
      "learning_rate": 1.8594260378795322e-05,
      "loss": 0.3258,
      "step": 276
    },
    {
      "epoch": 0.5906183368869936,
      "grad_norm": 0.27402463555336,
      "learning_rate": 1.8582462146770613e-05,
      "loss": 0.3077,
      "step": 277
    },
    {
      "epoch": 0.5927505330490405,
      "grad_norm": 0.28515297174453735,
      "learning_rate": 1.8570618386312236e-05,
      "loss": 0.3199,
      "step": 278
    },
    {
      "epoch": 0.5948827292110874,
      "grad_norm": 0.29440656304359436,
      "learning_rate": 1.855872916024923e-05,
      "loss": 0.3011,
      "step": 279
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 0.3081257939338684,
      "learning_rate": 1.8546794531651817e-05,
      "loss": 0.3133,
      "step": 280
    },
    {
      "epoch": 0.5991471215351812,
      "grad_norm": 0.2928609251976013,
      "learning_rate": 1.8534814563831082e-05,
      "loss": 0.3121,
      "step": 281
    },
    {
      "epoch": 0.6012793176972282,
      "grad_norm": 0.2907765209674835,
      "learning_rate": 1.8522789320338623e-05,
      "loss": 0.2978,
      "step": 282
    },
    {
      "epoch": 0.603411513859275,
      "grad_norm": 0.28662970662117004,
      "learning_rate": 1.851071886496621e-05,
      "loss": 0.3173,
      "step": 283
    },
    {
      "epoch": 0.605543710021322,
      "grad_norm": 0.27615198493003845,
      "learning_rate": 1.849860326174547e-05,
      "loss": 0.3167,
      "step": 284
    },
    {
      "epoch": 0.6076759061833689,
      "grad_norm": 0.2873261570930481,
      "learning_rate": 1.848644257494751e-05,
      "loss": 0.3114,
      "step": 285
    },
    {
      "epoch": 0.6098081023454158,
      "grad_norm": 0.3228626847267151,
      "learning_rate": 1.8474236869082616e-05,
      "loss": 0.2931,
      "step": 286
    },
    {
      "epoch": 0.6119402985074627,
      "grad_norm": 0.2675280272960663,
      "learning_rate": 1.846198620889988e-05,
      "loss": 0.2885,
      "step": 287
    },
    {
      "epoch": 0.6140724946695096,
      "grad_norm": 0.2669902443885803,
      "learning_rate": 1.844969065938687e-05,
      "loss": 0.2845,
      "step": 288
    },
    {
      "epoch": 0.6162046908315565,
      "grad_norm": 0.277202844619751,
      "learning_rate": 1.8437350285769296e-05,
      "loss": 0.2808,
      "step": 289
    },
    {
      "epoch": 0.6183368869936035,
      "grad_norm": 0.2857298254966736,
      "learning_rate": 1.8424965153510635e-05,
      "loss": 0.3115,
      "step": 290
    },
    {
      "epoch": 0.6204690831556503,
      "grad_norm": 0.2943260669708252,
      "learning_rate": 1.8412535328311813e-05,
      "loss": 0.3117,
      "step": 291
    },
    {
      "epoch": 0.6226012793176973,
      "grad_norm": 0.2849584221839905,
      "learning_rate": 1.840006087611084e-05,
      "loss": 0.2965,
      "step": 292
    },
    {
      "epoch": 0.6247334754797441,
      "grad_norm": 0.2709091901779175,
      "learning_rate": 1.838754186308246e-05,
      "loss": 0.3023,
      "step": 293
    },
    {
      "epoch": 0.6268656716417911,
      "grad_norm": 0.31160736083984375,
      "learning_rate": 1.8374978355637814e-05,
      "loss": 0.2876,
      "step": 294
    },
    {
      "epoch": 0.6289978678038379,
      "grad_norm": 0.3055921792984009,
      "learning_rate": 1.836237042042407e-05,
      "loss": 0.3281,
      "step": 295
    },
    {
      "epoch": 0.6311300639658849,
      "grad_norm": 0.3102927803993225,
      "learning_rate": 1.8349718124324075e-05,
      "loss": 0.2768,
      "step": 296
    },
    {
      "epoch": 0.6332622601279317,
      "grad_norm": 0.27893924713134766,
      "learning_rate": 1.8337021534456016e-05,
      "loss": 0.2824,
      "step": 297
    },
    {
      "epoch": 0.6353944562899787,
      "grad_norm": 0.30410537123680115,
      "learning_rate": 1.832428071817303e-05,
      "loss": 0.3021,
      "step": 298
    },
    {
      "epoch": 0.6375266524520256,
      "grad_norm": 0.31610608100891113,
      "learning_rate": 1.8311495743062887e-05,
      "loss": 0.2977,
      "step": 299
    },
    {
      "epoch": 0.6396588486140725,
      "grad_norm": 0.2827489674091339,
      "learning_rate": 1.8298666676947605e-05,
      "loss": 0.2892,
      "step": 300
    },
    {
      "epoch": 0.6417910447761194,
      "grad_norm": 0.3012917637825012,
      "learning_rate": 1.8285793587883093e-05,
      "loss": 0.2907,
      "step": 301
    },
    {
      "epoch": 0.6439232409381663,
      "grad_norm": 0.2962357699871063,
      "learning_rate": 1.8272876544158794e-05,
      "loss": 0.3095,
      "step": 302
    },
    {
      "epoch": 0.6460554371002132,
      "grad_norm": 0.2833421528339386,
      "learning_rate": 1.8259915614297332e-05,
      "loss": 0.3052,
      "step": 303
    },
    {
      "epoch": 0.6481876332622601,
      "grad_norm": 0.26801708340644836,
      "learning_rate": 1.8246910867054127e-05,
      "loss": 0.2704,
      "step": 304
    },
    {
      "epoch": 0.650319829424307,
      "grad_norm": 0.2821716070175171,
      "learning_rate": 1.8233862371417047e-05,
      "loss": 0.2862,
      "step": 305
    },
    {
      "epoch": 0.652452025586354,
      "grad_norm": 0.27771762013435364,
      "learning_rate": 1.8220770196606042e-05,
      "loss": 0.2967,
      "step": 306
    },
    {
      "epoch": 0.6545842217484008,
      "grad_norm": 0.3067030608654022,
      "learning_rate": 1.8207634412072765e-05,
      "loss": 0.3123,
      "step": 307
    },
    {
      "epoch": 0.6567164179104478,
      "grad_norm": 0.28362128138542175,
      "learning_rate": 1.8194455087500218e-05,
      "loss": 0.2988,
      "step": 308
    },
    {
      "epoch": 0.6588486140724946,
      "grad_norm": 0.3307797610759735,
      "learning_rate": 1.8181232292802365e-05,
      "loss": 0.2895,
      "step": 309
    },
    {
      "epoch": 0.6609808102345416,
      "grad_norm": 0.29549235105514526,
      "learning_rate": 1.8167966098123786e-05,
      "loss": 0.3052,
      "step": 310
    },
    {
      "epoch": 0.6631130063965884,
      "grad_norm": 0.28737345337867737,
      "learning_rate": 1.8154656573839276e-05,
      "loss": 0.278,
      "step": 311
    },
    {
      "epoch": 0.6652452025586354,
      "grad_norm": 0.33436882495880127,
      "learning_rate": 1.8141303790553495e-05,
      "loss": 0.2872,
      "step": 312
    },
    {
      "epoch": 0.6673773987206824,
      "grad_norm": 0.2988570034503937,
      "learning_rate": 1.8127907819100578e-05,
      "loss": 0.287,
      "step": 313
    },
    {
      "epoch": 0.6695095948827292,
      "grad_norm": 0.2795202136039734,
      "learning_rate": 1.8114468730543772e-05,
      "loss": 0.2839,
      "step": 314
    },
    {
      "epoch": 0.6716417910447762,
      "grad_norm": 0.2914721667766571,
      "learning_rate": 1.8100986596175046e-05,
      "loss": 0.2968,
      "step": 315
    },
    {
      "epoch": 0.673773987206823,
      "grad_norm": 0.3371770679950714,
      "learning_rate": 1.8087461487514725e-05,
      "loss": 0.3198,
      "step": 316
    },
    {
      "epoch": 0.67590618336887,
      "grad_norm": 0.3616895079612732,
      "learning_rate": 1.8073893476311096e-05,
      "loss": 0.2842,
      "step": 317
    },
    {
      "epoch": 0.6780383795309168,
      "grad_norm": 0.2803221642971039,
      "learning_rate": 1.8060282634540053e-05,
      "loss": 0.2896,
      "step": 318
    },
    {
      "epoch": 0.6801705756929638,
      "grad_norm": 0.3675381541252136,
      "learning_rate": 1.8046629034404683e-05,
      "loss": 0.3079,
      "step": 319
    },
    {
      "epoch": 0.6823027718550106,
      "grad_norm": 0.2990312874317169,
      "learning_rate": 1.8032932748334902e-05,
      "loss": 0.295,
      "step": 320
    },
    {
      "epoch": 0.6844349680170576,
      "grad_norm": 0.2737636864185333,
      "learning_rate": 1.8019193848987072e-05,
      "loss": 0.257,
      "step": 321
    },
    {
      "epoch": 0.6865671641791045,
      "grad_norm": 0.3228471875190735,
      "learning_rate": 1.8005412409243604e-05,
      "loss": 0.2938,
      "step": 322
    },
    {
      "epoch": 0.6886993603411514,
      "grad_norm": 0.29801830649375916,
      "learning_rate": 1.799158850221259e-05,
      "loss": 0.2933,
      "step": 323
    },
    {
      "epoch": 0.6908315565031983,
      "grad_norm": 0.2855466902256012,
      "learning_rate": 1.797772220122739e-05,
      "loss": 0.268,
      "step": 324
    },
    {
      "epoch": 0.6929637526652452,
      "grad_norm": 0.313484251499176,
      "learning_rate": 1.796381357984626e-05,
      "loss": 0.2889,
      "step": 325
    },
    {
      "epoch": 0.6950959488272921,
      "grad_norm": 0.3597797751426697,
      "learning_rate": 1.7949862711851966e-05,
      "loss": 0.3072,
      "step": 326
    },
    {
      "epoch": 0.697228144989339,
      "grad_norm": 0.29853928089141846,
      "learning_rate": 1.793586967125138e-05,
      "loss": 0.2753,
      "step": 327
    },
    {
      "epoch": 0.6993603411513859,
      "grad_norm": 0.2844715714454651,
      "learning_rate": 1.792183453227508e-05,
      "loss": 0.2886,
      "step": 328
    },
    {
      "epoch": 0.7014925373134329,
      "grad_norm": 0.32469627261161804,
      "learning_rate": 1.7907757369376984e-05,
      "loss": 0.3087,
      "step": 329
    },
    {
      "epoch": 0.7036247334754797,
      "grad_norm": 0.30987948179244995,
      "learning_rate": 1.7893638257233947e-05,
      "loss": 0.3049,
      "step": 330
    },
    {
      "epoch": 0.7057569296375267,
      "grad_norm": 0.30323904752731323,
      "learning_rate": 1.7879477270745328e-05,
      "loss": 0.3137,
      "step": 331
    },
    {
      "epoch": 0.7078891257995735,
      "grad_norm": 0.2869638204574585,
      "learning_rate": 1.786527448503265e-05,
      "loss": 0.2658,
      "step": 332
    },
    {
      "epoch": 0.7100213219616205,
      "grad_norm": 0.3307938873767853,
      "learning_rate": 1.785102997543916e-05,
      "loss": 0.2942,
      "step": 333
    },
    {
      "epoch": 0.7121535181236673,
      "grad_norm": 0.320188969373703,
      "learning_rate": 1.783674381752944e-05,
      "loss": 0.286,
      "step": 334
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.2945164740085602,
      "learning_rate": 1.7822416087089025e-05,
      "loss": 0.2912,
      "step": 335
    },
    {
      "epoch": 0.7164179104477612,
      "grad_norm": 0.2999993860721588,
      "learning_rate": 1.7808046860123962e-05,
      "loss": 0.2915,
      "step": 336
    },
    {
      "epoch": 0.7185501066098081,
      "grad_norm": 0.3164651095867157,
      "learning_rate": 1.779363621286045e-05,
      "loss": 0.2756,
      "step": 337
    },
    {
      "epoch": 0.720682302771855,
      "grad_norm": 0.29713675379753113,
      "learning_rate": 1.7779184221744407e-05,
      "loss": 0.2708,
      "step": 338
    },
    {
      "epoch": 0.7228144989339019,
      "grad_norm": 0.302568256855011,
      "learning_rate": 1.7764690963441067e-05,
      "loss": 0.2662,
      "step": 339
    },
    {
      "epoch": 0.7249466950959488,
      "grad_norm": 0.3065771758556366,
      "learning_rate": 1.775015651483459e-05,
      "loss": 0.2631,
      "step": 340
    },
    {
      "epoch": 0.7270788912579957,
      "grad_norm": 0.3414871096611023,
      "learning_rate": 1.7735580953027637e-05,
      "loss": 0.2728,
      "step": 341
    },
    {
      "epoch": 0.7292110874200426,
      "grad_norm": 0.2979874610900879,
      "learning_rate": 1.7720964355340964e-05,
      "loss": 0.2943,
      "step": 342
    },
    {
      "epoch": 0.7313432835820896,
      "grad_norm": 0.3017725646495819,
      "learning_rate": 1.7706306799313025e-05,
      "loss": 0.2623,
      "step": 343
    },
    {
      "epoch": 0.7334754797441365,
      "grad_norm": 0.31871533393859863,
      "learning_rate": 1.7691608362699546e-05,
      "loss": 0.3096,
      "step": 344
    },
    {
      "epoch": 0.7356076759061834,
      "grad_norm": 0.30933281779289246,
      "learning_rate": 1.7676869123473113e-05,
      "loss": 0.2649,
      "step": 345
    },
    {
      "epoch": 0.7377398720682303,
      "grad_norm": 0.5514667630195618,
      "learning_rate": 1.7662089159822765e-05,
      "loss": 0.2727,
      "step": 346
    },
    {
      "epoch": 0.7398720682302772,
      "grad_norm": 0.28424832224845886,
      "learning_rate": 1.7647268550153583e-05,
      "loss": 0.2605,
      "step": 347
    },
    {
      "epoch": 0.7420042643923241,
      "grad_norm": 0.2895672619342804,
      "learning_rate": 1.7632407373086256e-05,
      "loss": 0.2489,
      "step": 348
    },
    {
      "epoch": 0.744136460554371,
      "grad_norm": 0.32513612508773804,
      "learning_rate": 1.7617505707456682e-05,
      "loss": 0.2851,
      "step": 349
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 0.28852328658103943,
      "learning_rate": 1.7602563632315552e-05,
      "loss": 0.2455,
      "step": 350
    },
    {
      "epoch": 0.7484008528784648,
      "grad_norm": 0.3061446249485016,
      "learning_rate": 1.758758122692791e-05,
      "loss": 0.2654,
      "step": 351
    },
    {
      "epoch": 0.7505330490405118,
      "grad_norm": 0.32455676794052124,
      "learning_rate": 1.757255857077275e-05,
      "loss": 0.277,
      "step": 352
    },
    {
      "epoch": 0.7526652452025586,
      "grad_norm": 0.33169376850128174,
      "learning_rate": 1.7557495743542586e-05,
      "loss": 0.2478,
      "step": 353
    },
    {
      "epoch": 0.7547974413646056,
      "grad_norm": 0.31279683113098145,
      "learning_rate": 1.7542392825143032e-05,
      "loss": 0.2745,
      "step": 354
    },
    {
      "epoch": 0.7569296375266524,
      "grad_norm": 0.2912912368774414,
      "learning_rate": 1.752724989569239e-05,
      "loss": 0.2707,
      "step": 355
    },
    {
      "epoch": 0.7590618336886994,
      "grad_norm": 0.31171470880508423,
      "learning_rate": 1.7512067035521202e-05,
      "loss": 0.2624,
      "step": 356
    },
    {
      "epoch": 0.7611940298507462,
      "grad_norm": 0.3546862304210663,
      "learning_rate": 1.749684432517183e-05,
      "loss": 0.2762,
      "step": 357
    },
    {
      "epoch": 0.7633262260127932,
      "grad_norm": 0.3221682608127594,
      "learning_rate": 1.748158184539805e-05,
      "loss": 0.2642,
      "step": 358
    },
    {
      "epoch": 0.7654584221748401,
      "grad_norm": 0.29247939586639404,
      "learning_rate": 1.7466279677164598e-05,
      "loss": 0.2584,
      "step": 359
    },
    {
      "epoch": 0.767590618336887,
      "grad_norm": 0.3233579993247986,
      "learning_rate": 1.7450937901646756e-05,
      "loss": 0.2623,
      "step": 360
    },
    {
      "epoch": 0.7697228144989339,
      "grad_norm": 0.2868787944316864,
      "learning_rate": 1.7435556600229904e-05,
      "loss": 0.2743,
      "step": 361
    },
    {
      "epoch": 0.7718550106609808,
      "grad_norm": 0.31915149092674255,
      "learning_rate": 1.742013585450911e-05,
      "loss": 0.254,
      "step": 362
    },
    {
      "epoch": 0.7739872068230277,
      "grad_norm": 0.29351532459259033,
      "learning_rate": 1.7404675746288686e-05,
      "loss": 0.2705,
      "step": 363
    },
    {
      "epoch": 0.7761194029850746,
      "grad_norm": 0.29857710003852844,
      "learning_rate": 1.7389176357581752e-05,
      "loss": 0.2623,
      "step": 364
    },
    {
      "epoch": 0.7782515991471215,
      "grad_norm": 0.2983666956424713,
      "learning_rate": 1.7373637770609813e-05,
      "loss": 0.2529,
      "step": 365
    },
    {
      "epoch": 0.7803837953091685,
      "grad_norm": 0.31919601559638977,
      "learning_rate": 1.7358060067802297e-05,
      "loss": 0.2699,
      "step": 366
    },
    {
      "epoch": 0.7825159914712153,
      "grad_norm": 0.2907225489616394,
      "learning_rate": 1.7342443331796147e-05,
      "loss": 0.2642,
      "step": 367
    },
    {
      "epoch": 0.7846481876332623,
      "grad_norm": 0.3311938941478729,
      "learning_rate": 1.732678764543537e-05,
      "loss": 0.2497,
      "step": 368
    },
    {
      "epoch": 0.7867803837953091,
      "grad_norm": 0.30687811970710754,
      "learning_rate": 1.7311093091770587e-05,
      "loss": 0.2621,
      "step": 369
    },
    {
      "epoch": 0.7889125799573561,
      "grad_norm": 0.3105890452861786,
      "learning_rate": 1.729535975405862e-05,
      "loss": 0.2594,
      "step": 370
    },
    {
      "epoch": 0.7910447761194029,
      "grad_norm": 0.3166772425174713,
      "learning_rate": 1.727958771576202e-05,
      "loss": 0.2615,
      "step": 371
    },
    {
      "epoch": 0.7931769722814499,
      "grad_norm": 0.3458569347858429,
      "learning_rate": 1.7263777060548642e-05,
      "loss": 0.2652,
      "step": 372
    },
    {
      "epoch": 0.7953091684434968,
      "grad_norm": 0.3223593235015869,
      "learning_rate": 1.72479278722912e-05,
      "loss": 0.2572,
      "step": 373
    },
    {
      "epoch": 0.7974413646055437,
      "grad_norm": 0.3207191526889801,
      "learning_rate": 1.723204023506681e-05,
      "loss": 0.248,
      "step": 374
    },
    {
      "epoch": 0.7995735607675906,
      "grad_norm": 0.3328503966331482,
      "learning_rate": 1.7216114233156567e-05,
      "loss": 0.2437,
      "step": 375
    },
    {
      "epoch": 0.8017057569296375,
      "grad_norm": 0.3007630407810211,
      "learning_rate": 1.720014995104507e-05,
      "loss": 0.2498,
      "step": 376
    },
    {
      "epoch": 0.8038379530916845,
      "grad_norm": 0.3034293055534363,
      "learning_rate": 1.718414747341999e-05,
      "loss": 0.2632,
      "step": 377
    },
    {
      "epoch": 0.8059701492537313,
      "grad_norm": 0.3546721041202545,
      "learning_rate": 1.716810688517163e-05,
      "loss": 0.263,
      "step": 378
    },
    {
      "epoch": 0.8081023454157783,
      "grad_norm": 0.32060638070106506,
      "learning_rate": 1.7152028271392454e-05,
      "loss": 0.2457,
      "step": 379
    },
    {
      "epoch": 0.8102345415778252,
      "grad_norm": 0.2931840121746063,
      "learning_rate": 1.7135911717376638e-05,
      "loss": 0.2474,
      "step": 380
    },
    {
      "epoch": 0.8123667377398721,
      "grad_norm": 0.30380621552467346,
      "learning_rate": 1.7119757308619636e-05,
      "loss": 0.2784,
      "step": 381
    },
    {
      "epoch": 0.814498933901919,
      "grad_norm": 0.33506670594215393,
      "learning_rate": 1.7103565130817714e-05,
      "loss": 0.2902,
      "step": 382
    },
    {
      "epoch": 0.8166311300639659,
      "grad_norm": 0.2996463477611542,
      "learning_rate": 1.7087335269867486e-05,
      "loss": 0.2655,
      "step": 383
    },
    {
      "epoch": 0.8187633262260128,
      "grad_norm": 0.3007001280784607,
      "learning_rate": 1.7071067811865477e-05,
      "loss": 0.2733,
      "step": 384
    },
    {
      "epoch": 0.8208955223880597,
      "grad_norm": 0.32276785373687744,
      "learning_rate": 1.705476284310766e-05,
      "loss": 0.2603,
      "step": 385
    },
    {
      "epoch": 0.8230277185501066,
      "grad_norm": 0.35085591673851013,
      "learning_rate": 1.7038420450088982e-05,
      "loss": 0.2339,
      "step": 386
    },
    {
      "epoch": 0.8251599147121536,
      "grad_norm": 0.3518298864364624,
      "learning_rate": 1.7022040719502935e-05,
      "loss": 0.2674,
      "step": 387
    },
    {
      "epoch": 0.8272921108742004,
      "grad_norm": 0.3025285005569458,
      "learning_rate": 1.7005623738241074e-05,
      "loss": 0.2361,
      "step": 388
    },
    {
      "epoch": 0.8294243070362474,
      "grad_norm": 0.29637235403060913,
      "learning_rate": 1.698916959339256e-05,
      "loss": 0.2355,
      "step": 389
    },
    {
      "epoch": 0.8315565031982942,
      "grad_norm": 0.31208521127700806,
      "learning_rate": 1.6972678372243703e-05,
      "loss": 0.2718,
      "step": 390
    },
    {
      "epoch": 0.8336886993603412,
      "grad_norm": 0.2790257930755615,
      "learning_rate": 1.695615016227749e-05,
      "loss": 0.2163,
      "step": 391
    },
    {
      "epoch": 0.835820895522388,
      "grad_norm": 0.2971075177192688,
      "learning_rate": 1.693958505117314e-05,
      "loss": 0.2425,
      "step": 392
    },
    {
      "epoch": 0.837953091684435,
      "grad_norm": 0.33907845616340637,
      "learning_rate": 1.6922983126805613e-05,
      "loss": 0.2466,
      "step": 393
    },
    {
      "epoch": 0.8400852878464818,
      "grad_norm": 0.3229086399078369,
      "learning_rate": 1.6906344477245164e-05,
      "loss": 0.253,
      "step": 394
    },
    {
      "epoch": 0.8422174840085288,
      "grad_norm": 0.3146481513977051,
      "learning_rate": 1.688966919075687e-05,
      "loss": 0.2367,
      "step": 395
    },
    {
      "epoch": 0.8443496801705757,
      "grad_norm": 0.3061874508857727,
      "learning_rate": 1.6872957355800145e-05,
      "loss": 0.2626,
      "step": 396
    },
    {
      "epoch": 0.8464818763326226,
      "grad_norm": 0.3071669042110443,
      "learning_rate": 1.685620906102831e-05,
      "loss": 0.2627,
      "step": 397
    },
    {
      "epoch": 0.8486140724946695,
      "grad_norm": 0.29989731311798096,
      "learning_rate": 1.6839424395288083e-05,
      "loss": 0.237,
      "step": 398
    },
    {
      "epoch": 0.8507462686567164,
      "grad_norm": 0.3031643331050873,
      "learning_rate": 1.6822603447619127e-05,
      "loss": 0.2435,
      "step": 399
    },
    {
      "epoch": 0.8528784648187633,
      "grad_norm": 0.31406062841415405,
      "learning_rate": 1.6805746307253575e-05,
      "loss": 0.2423,
      "step": 400
    },
    {
      "epoch": 0.8550106609808102,
      "grad_norm": 0.3121655583381653,
      "learning_rate": 1.6788853063615555e-05,
      "loss": 0.2444,
      "step": 401
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.3035156726837158,
      "learning_rate": 1.677192380632072e-05,
      "loss": 0.2159,
      "step": 402
    },
    {
      "epoch": 0.8592750533049041,
      "grad_norm": 0.3064214587211609,
      "learning_rate": 1.675495862517576e-05,
      "loss": 0.2467,
      "step": 403
    },
    {
      "epoch": 0.8614072494669509,
      "grad_norm": 0.31326013803482056,
      "learning_rate": 1.6737957610177945e-05,
      "loss": 0.2385,
      "step": 404
    },
    {
      "epoch": 0.8635394456289979,
      "grad_norm": 0.32894694805145264,
      "learning_rate": 1.672092085151463e-05,
      "loss": 0.2314,
      "step": 405
    },
    {
      "epoch": 0.8656716417910447,
      "grad_norm": 0.3179277181625366,
      "learning_rate": 1.6703848439562787e-05,
      "loss": 0.2364,
      "step": 406
    },
    {
      "epoch": 0.8678038379530917,
      "grad_norm": 0.3072924315929413,
      "learning_rate": 1.668674046488852e-05,
      "loss": 0.2389,
      "step": 407
    },
    {
      "epoch": 0.8699360341151386,
      "grad_norm": 0.3515948951244354,
      "learning_rate": 1.66695970182466e-05,
      "loss": 0.2188,
      "step": 408
    },
    {
      "epoch": 0.8720682302771855,
      "grad_norm": 0.315778911113739,
      "learning_rate": 1.6652418190579946e-05,
      "loss": 0.2627,
      "step": 409
    },
    {
      "epoch": 0.8742004264392325,
      "grad_norm": 0.31990423798561096,
      "learning_rate": 1.663520407301918e-05,
      "loss": 0.2542,
      "step": 410
    },
    {
      "epoch": 0.8763326226012793,
      "grad_norm": 0.3202512264251709,
      "learning_rate": 1.6617954756882143e-05,
      "loss": 0.2331,
      "step": 411
    },
    {
      "epoch": 0.8784648187633263,
      "grad_norm": 0.31171080470085144,
      "learning_rate": 1.6600670333673376e-05,
      "loss": 0.2455,
      "step": 412
    },
    {
      "epoch": 0.8805970149253731,
      "grad_norm": 0.3256244659423828,
      "learning_rate": 1.6583350895083667e-05,
      "loss": 0.2557,
      "step": 413
    },
    {
      "epoch": 0.8827292110874201,
      "grad_norm": 0.31526151299476624,
      "learning_rate": 1.6565996532989562e-05,
      "loss": 0.2594,
      "step": 414
    },
    {
      "epoch": 0.8848614072494669,
      "grad_norm": 0.3179241120815277,
      "learning_rate": 1.6548607339452853e-05,
      "loss": 0.2408,
      "step": 415
    },
    {
      "epoch": 0.8869936034115139,
      "grad_norm": 0.2799939811229706,
      "learning_rate": 1.653118340672012e-05,
      "loss": 0.2113,
      "step": 416
    },
    {
      "epoch": 0.8891257995735607,
      "grad_norm": 0.31419071555137634,
      "learning_rate": 1.6513724827222225e-05,
      "loss": 0.2395,
      "step": 417
    },
    {
      "epoch": 0.8912579957356077,
      "grad_norm": 0.3537348210811615,
      "learning_rate": 1.649623169357382e-05,
      "loss": 0.2734,
      "step": 418
    },
    {
      "epoch": 0.8933901918976546,
      "grad_norm": 0.30522972345352173,
      "learning_rate": 1.647870409857287e-05,
      "loss": 0.2178,
      "step": 419
    },
    {
      "epoch": 0.8955223880597015,
      "grad_norm": 0.3199632465839386,
      "learning_rate": 1.6461142135200142e-05,
      "loss": 0.2403,
      "step": 420
    },
    {
      "epoch": 0.8976545842217484,
      "grad_norm": 0.3165355920791626,
      "learning_rate": 1.6443545896618726e-05,
      "loss": 0.2276,
      "step": 421
    },
    {
      "epoch": 0.8997867803837953,
      "grad_norm": 0.3041881024837494,
      "learning_rate": 1.6425915476173533e-05,
      "loss": 0.2201,
      "step": 422
    },
    {
      "epoch": 0.9019189765458422,
      "grad_norm": 0.3385501801967621,
      "learning_rate": 1.6408250967390806e-05,
      "loss": 0.2378,
      "step": 423
    },
    {
      "epoch": 0.9040511727078892,
      "grad_norm": 0.30699652433395386,
      "learning_rate": 1.6390552463977622e-05,
      "loss": 0.2359,
      "step": 424
    },
    {
      "epoch": 0.906183368869936,
      "grad_norm": 0.28736257553100586,
      "learning_rate": 1.637282005982139e-05,
      "loss": 0.232,
      "step": 425
    },
    {
      "epoch": 0.908315565031983,
      "grad_norm": 0.2983381152153015,
      "learning_rate": 1.635505384898935e-05,
      "loss": 0.238,
      "step": 426
    },
    {
      "epoch": 0.9104477611940298,
      "grad_norm": 0.2965700328350067,
      "learning_rate": 1.633725392572809e-05,
      "loss": 0.2388,
      "step": 427
    },
    {
      "epoch": 0.9125799573560768,
      "grad_norm": 0.301069974899292,
      "learning_rate": 1.631942038446304e-05,
      "loss": 0.2206,
      "step": 428
    },
    {
      "epoch": 0.9147121535181236,
      "grad_norm": 0.30051255226135254,
      "learning_rate": 1.630155331979796e-05,
      "loss": 0.2268,
      "step": 429
    },
    {
      "epoch": 0.9168443496801706,
      "grad_norm": 0.3053097426891327,
      "learning_rate": 1.628365282651444e-05,
      "loss": 0.2493,
      "step": 430
    },
    {
      "epoch": 0.9189765458422174,
      "grad_norm": 0.3192027807235718,
      "learning_rate": 1.6265718999571416e-05,
      "loss": 0.2588,
      "step": 431
    },
    {
      "epoch": 0.9211087420042644,
      "grad_norm": 0.30249109864234924,
      "learning_rate": 1.6247751934104648e-05,
      "loss": 0.2538,
      "step": 432
    },
    {
      "epoch": 0.9232409381663113,
      "grad_norm": 0.31638646125793457,
      "learning_rate": 1.6229751725426214e-05,
      "loss": 0.2471,
      "step": 433
    },
    {
      "epoch": 0.9253731343283582,
      "grad_norm": 0.29675063490867615,
      "learning_rate": 1.6211718469024022e-05,
      "loss": 0.2383,
      "step": 434
    },
    {
      "epoch": 0.9275053304904051,
      "grad_norm": 0.30853796005249023,
      "learning_rate": 1.619365226056128e-05,
      "loss": 0.2606,
      "step": 435
    },
    {
      "epoch": 0.929637526652452,
      "grad_norm": 0.3136747479438782,
      "learning_rate": 1.617555319587601e-05,
      "loss": 0.2293,
      "step": 436
    },
    {
      "epoch": 0.9317697228144989,
      "grad_norm": 0.31922483444213867,
      "learning_rate": 1.6157421370980532e-05,
      "loss": 0.2129,
      "step": 437
    },
    {
      "epoch": 0.9339019189765458,
      "grad_norm": 0.30623361468315125,
      "learning_rate": 1.6139256882060944e-05,
      "loss": 0.2132,
      "step": 438
    },
    {
      "epoch": 0.9360341151385928,
      "grad_norm": 0.3088095188140869,
      "learning_rate": 1.612105982547663e-05,
      "loss": 0.2058,
      "step": 439
    },
    {
      "epoch": 0.9381663113006397,
      "grad_norm": 0.323637992143631,
      "learning_rate": 1.610283029775973e-05,
      "loss": 0.2233,
      "step": 440
    },
    {
      "epoch": 0.9402985074626866,
      "grad_norm": 0.3161788880825043,
      "learning_rate": 1.6084568395614647e-05,
      "loss": 0.2415,
      "step": 441
    },
    {
      "epoch": 0.9424307036247335,
      "grad_norm": 0.30679893493652344,
      "learning_rate": 1.606627421591752e-05,
      "loss": 0.2211,
      "step": 442
    },
    {
      "epoch": 0.9445628997867804,
      "grad_norm": 0.2846530079841614,
      "learning_rate": 1.6047947855715714e-05,
      "loss": 0.2062,
      "step": 443
    },
    {
      "epoch": 0.9466950959488273,
      "grad_norm": 0.2886843979358673,
      "learning_rate": 1.602958941222731e-05,
      "loss": 0.2132,
      "step": 444
    },
    {
      "epoch": 0.9488272921108742,
      "grad_norm": 0.3010450005531311,
      "learning_rate": 1.6011198982840577e-05,
      "loss": 0.2387,
      "step": 445
    },
    {
      "epoch": 0.9509594882729211,
      "grad_norm": 0.3125992715358734,
      "learning_rate": 1.599277666511347e-05,
      "loss": 0.2058,
      "step": 446
    },
    {
      "epoch": 0.9530916844349681,
      "grad_norm": 0.3539835810661316,
      "learning_rate": 1.597432255677311e-05,
      "loss": 0.2444,
      "step": 447
    },
    {
      "epoch": 0.9552238805970149,
      "grad_norm": 0.31227004528045654,
      "learning_rate": 1.595583675571525e-05,
      "loss": 0.231,
      "step": 448
    },
    {
      "epoch": 0.9573560767590619,
      "grad_norm": 0.30113938450813293,
      "learning_rate": 1.5937319360003774e-05,
      "loss": 0.2114,
      "step": 449
    },
    {
      "epoch": 0.9594882729211087,
      "grad_norm": 0.31093505024909973,
      "learning_rate": 1.5918770467870174e-05,
      "loss": 0.2315,
      "step": 450
    },
    {
      "epoch": 0.9616204690831557,
      "grad_norm": 0.3155503273010254,
      "learning_rate": 1.5900190177713018e-05,
      "loss": 0.2391,
      "step": 451
    },
    {
      "epoch": 0.9637526652452025,
      "grad_norm": 0.2999875247478485,
      "learning_rate": 1.5881578588097432e-05,
      "loss": 0.2238,
      "step": 452
    },
    {
      "epoch": 0.9658848614072495,
      "grad_norm": 0.2931395173072815,
      "learning_rate": 1.5862935797754596e-05,
      "loss": 0.2158,
      "step": 453
    },
    {
      "epoch": 0.9680170575692963,
      "grad_norm": 0.30554911494255066,
      "learning_rate": 1.5844261905581183e-05,
      "loss": 0.2315,
      "step": 454
    },
    {
      "epoch": 0.9701492537313433,
      "grad_norm": 0.35460570454597473,
      "learning_rate": 1.582555701063887e-05,
      "loss": 0.212,
      "step": 455
    },
    {
      "epoch": 0.9722814498933902,
      "grad_norm": 0.3116441071033478,
      "learning_rate": 1.58068212121538e-05,
      "loss": 0.2293,
      "step": 456
    },
    {
      "epoch": 0.9744136460554371,
      "grad_norm": 0.3416669964790344,
      "learning_rate": 1.5788054609516045e-05,
      "loss": 0.2501,
      "step": 457
    },
    {
      "epoch": 0.976545842217484,
      "grad_norm": 0.29815787076950073,
      "learning_rate": 1.5769257302279087e-05,
      "loss": 0.2186,
      "step": 458
    },
    {
      "epoch": 0.9786780383795309,
      "grad_norm": 0.30607929825782776,
      "learning_rate": 1.5750429390159293e-05,
      "loss": 0.214,
      "step": 459
    },
    {
      "epoch": 0.9808102345415778,
      "grad_norm": 0.32121598720550537,
      "learning_rate": 1.573157097303539e-05,
      "loss": 0.195,
      "step": 460
    },
    {
      "epoch": 0.9829424307036247,
      "grad_norm": 0.309589684009552,
      "learning_rate": 1.5712682150947926e-05,
      "loss": 0.2322,
      "step": 461
    },
    {
      "epoch": 0.9850746268656716,
      "grad_norm": 0.3014459013938904,
      "learning_rate": 1.569376302409873e-05,
      "loss": 0.21,
      "step": 462
    },
    {
      "epoch": 0.9872068230277186,
      "grad_norm": 0.3332260549068451,
      "learning_rate": 1.567481369285041e-05,
      "loss": 0.2192,
      "step": 463
    },
    {
      "epoch": 0.9893390191897654,
      "grad_norm": 0.3000193238258362,
      "learning_rate": 1.565583425772579e-05,
      "loss": 0.1888,
      "step": 464
    },
    {
      "epoch": 0.9914712153518124,
      "grad_norm": 0.29573577642440796,
      "learning_rate": 1.563682481940739e-05,
      "loss": 0.2082,
      "step": 465
    },
    {
      "epoch": 0.9936034115138592,
      "grad_norm": 0.3111564517021179,
      "learning_rate": 1.5617785478736907e-05,
      "loss": 0.2262,
      "step": 466
    },
    {
      "epoch": 0.9957356076759062,
      "grad_norm": 0.3262016475200653,
      "learning_rate": 1.5598716336714645e-05,
      "loss": 0.213,
      "step": 467
    },
    {
      "epoch": 0.997867803837953,
      "grad_norm": 0.31491392850875854,
      "learning_rate": 1.557961749449901e-05,
      "loss": 0.1942,
      "step": 468
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.32798904180526733,
      "learning_rate": 1.556048905340596e-05,
      "loss": 0.2195,
      "step": 469
    },
    {
      "epoch": 1.0021321961620469,
      "grad_norm": 0.3295329809188843,
      "learning_rate": 1.554133111490847e-05,
      "loss": 0.1699,
      "step": 470
    },
    {
      "epoch": 1.004264392324094,
      "grad_norm": 0.2965591847896576,
      "learning_rate": 1.552214378063599e-05,
      "loss": 0.1556,
      "step": 471
    },
    {
      "epoch": 1.0063965884861408,
      "grad_norm": 0.31125229597091675,
      "learning_rate": 1.5502927152373913e-05,
      "loss": 0.1738,
      "step": 472
    },
    {
      "epoch": 1.0085287846481876,
      "grad_norm": 0.3141792118549347,
      "learning_rate": 1.5483681332063035e-05,
      "loss": 0.1468,
      "step": 473
    },
    {
      "epoch": 1.0106609808102345,
      "grad_norm": 0.3496270179748535,
      "learning_rate": 1.5464406421799e-05,
      "loss": 0.1638,
      "step": 474
    },
    {
      "epoch": 1.0127931769722816,
      "grad_norm": 0.2940869629383087,
      "learning_rate": 1.544510252383178e-05,
      "loss": 0.1405,
      "step": 475
    },
    {
      "epoch": 1.0149253731343284,
      "grad_norm": 0.31746092438697815,
      "learning_rate": 1.5425769740565116e-05,
      "loss": 0.161,
      "step": 476
    },
    {
      "epoch": 1.0170575692963753,
      "grad_norm": 0.2969200015068054,
      "learning_rate": 1.5406408174555978e-05,
      "loss": 0.1464,
      "step": 477
    },
    {
      "epoch": 1.019189765458422,
      "grad_norm": 0.3011854290962219,
      "learning_rate": 1.538701792851403e-05,
      "loss": 0.1565,
      "step": 478
    },
    {
      "epoch": 1.0213219616204692,
      "grad_norm": 0.2983570396900177,
      "learning_rate": 1.5367599105301068e-05,
      "loss": 0.1528,
      "step": 479
    },
    {
      "epoch": 1.023454157782516,
      "grad_norm": 0.3197585344314575,
      "learning_rate": 1.5348151807930507e-05,
      "loss": 0.1504,
      "step": 480
    },
    {
      "epoch": 1.0255863539445629,
      "grad_norm": 0.32494163513183594,
      "learning_rate": 1.532867613956678e-05,
      "loss": 0.139,
      "step": 481
    },
    {
      "epoch": 1.0277185501066097,
      "grad_norm": 0.28696775436401367,
      "learning_rate": 1.5309172203524852e-05,
      "loss": 0.1417,
      "step": 482
    },
    {
      "epoch": 1.0298507462686568,
      "grad_norm": 0.2993534803390503,
      "learning_rate": 1.5289640103269626e-05,
      "loss": 0.1465,
      "step": 483
    },
    {
      "epoch": 1.0319829424307037,
      "grad_norm": 0.2997646629810333,
      "learning_rate": 1.527007994241542e-05,
      "loss": 0.1318,
      "step": 484
    },
    {
      "epoch": 1.0341151385927505,
      "grad_norm": 0.2733721435070038,
      "learning_rate": 1.5250491824725397e-05,
      "loss": 0.1351,
      "step": 485
    },
    {
      "epoch": 1.0362473347547974,
      "grad_norm": 0.3121456503868103,
      "learning_rate": 1.5230875854111043e-05,
      "loss": 0.1403,
      "step": 486
    },
    {
      "epoch": 1.0383795309168444,
      "grad_norm": 0.3004245162010193,
      "learning_rate": 1.5211232134631586e-05,
      "loss": 0.133,
      "step": 487
    },
    {
      "epoch": 1.0405117270788913,
      "grad_norm": 0.29341989755630493,
      "learning_rate": 1.5191560770493459e-05,
      "loss": 0.1346,
      "step": 488
    },
    {
      "epoch": 1.0426439232409381,
      "grad_norm": 0.31332799792289734,
      "learning_rate": 1.5171861866049748e-05,
      "loss": 0.1431,
      "step": 489
    },
    {
      "epoch": 1.044776119402985,
      "grad_norm": 0.3201509714126587,
      "learning_rate": 1.5152135525799633e-05,
      "loss": 0.1478,
      "step": 490
    },
    {
      "epoch": 1.046908315565032,
      "grad_norm": 0.28502631187438965,
      "learning_rate": 1.513238185438784e-05,
      "loss": 0.1422,
      "step": 491
    },
    {
      "epoch": 1.049040511727079,
      "grad_norm": 0.3061836063861847,
      "learning_rate": 1.5112600956604076e-05,
      "loss": 0.1321,
      "step": 492
    },
    {
      "epoch": 1.0511727078891258,
      "grad_norm": 0.3047110438346863,
      "learning_rate": 1.5092792937382483e-05,
      "loss": 0.1622,
      "step": 493
    },
    {
      "epoch": 1.0533049040511726,
      "grad_norm": 0.2913031578063965,
      "learning_rate": 1.5072957901801075e-05,
      "loss": 0.1482,
      "step": 494
    },
    {
      "epoch": 1.0554371002132197,
      "grad_norm": 0.31915149092674255,
      "learning_rate": 1.5053095955081184e-05,
      "loss": 0.1594,
      "step": 495
    },
    {
      "epoch": 1.0575692963752665,
      "grad_norm": 0.3340446949005127,
      "learning_rate": 1.5033207202586906e-05,
      "loss": 0.1527,
      "step": 496
    },
    {
      "epoch": 1.0597014925373134,
      "grad_norm": 0.314988374710083,
      "learning_rate": 1.5013291749824528e-05,
      "loss": 0.1567,
      "step": 497
    },
    {
      "epoch": 1.0618336886993602,
      "grad_norm": 0.291768342256546,
      "learning_rate": 1.4993349702441977e-05,
      "loss": 0.1493,
      "step": 498
    },
    {
      "epoch": 1.0639658848614073,
      "grad_norm": 0.3032262623310089,
      "learning_rate": 1.4973381166228274e-05,
      "loss": 0.1533,
      "step": 499
    },
    {
      "epoch": 1.0660980810234542,
      "grad_norm": 0.29891133308410645,
      "learning_rate": 1.495338624711294e-05,
      "loss": 0.1402,
      "step": 500
    },
    {
      "epoch": 1.068230277185501,
      "grad_norm": 0.30199143290519714,
      "learning_rate": 1.4933365051165463e-05,
      "loss": 0.1587,
      "step": 501
    },
    {
      "epoch": 1.070362473347548,
      "grad_norm": 0.3228582739830017,
      "learning_rate": 1.4913317684594728e-05,
      "loss": 0.1654,
      "step": 502
    },
    {
      "epoch": 1.072494669509595,
      "grad_norm": 0.3152719736099243,
      "learning_rate": 1.4893244253748439e-05,
      "loss": 0.1553,
      "step": 503
    },
    {
      "epoch": 1.0746268656716418,
      "grad_norm": 0.2959187924861908,
      "learning_rate": 1.4873144865112573e-05,
      "loss": 0.143,
      "step": 504
    },
    {
      "epoch": 1.0767590618336886,
      "grad_norm": 0.28148701786994934,
      "learning_rate": 1.4853019625310813e-05,
      "loss": 0.1366,
      "step": 505
    },
    {
      "epoch": 1.0788912579957357,
      "grad_norm": 0.29893508553504944,
      "learning_rate": 1.4832868641103968e-05,
      "loss": 0.1426,
      "step": 506
    },
    {
      "epoch": 1.0810234541577826,
      "grad_norm": 0.2987864911556244,
      "learning_rate": 1.4812692019389426e-05,
      "loss": 0.1437,
      "step": 507
    },
    {
      "epoch": 1.0831556503198294,
      "grad_norm": 0.2864709794521332,
      "learning_rate": 1.479248986720057e-05,
      "loss": 0.1396,
      "step": 508
    },
    {
      "epoch": 1.0852878464818763,
      "grad_norm": 0.2992094159126282,
      "learning_rate": 1.4772262291706223e-05,
      "loss": 0.1466,
      "step": 509
    },
    {
      "epoch": 1.0874200426439233,
      "grad_norm": 0.2797418236732483,
      "learning_rate": 1.4752009400210067e-05,
      "loss": 0.1287,
      "step": 510
    },
    {
      "epoch": 1.0895522388059702,
      "grad_norm": 0.3073393404483795,
      "learning_rate": 1.4731731300150092e-05,
      "loss": 0.1316,
      "step": 511
    },
    {
      "epoch": 1.091684434968017,
      "grad_norm": 0.31149768829345703,
      "learning_rate": 1.4711428099098002e-05,
      "loss": 0.1466,
      "step": 512
    },
    {
      "epoch": 1.0938166311300639,
      "grad_norm": 0.29830631613731384,
      "learning_rate": 1.4691099904758667e-05,
      "loss": 0.1489,
      "step": 513
    },
    {
      "epoch": 1.095948827292111,
      "grad_norm": 0.2791934311389923,
      "learning_rate": 1.4670746824969544e-05,
      "loss": 0.1494,
      "step": 514
    },
    {
      "epoch": 1.0980810234541578,
      "grad_norm": 0.2777698338031769,
      "learning_rate": 1.4650368967700086e-05,
      "loss": 0.1437,
      "step": 515
    },
    {
      "epoch": 1.1002132196162047,
      "grad_norm": 0.28313368558883667,
      "learning_rate": 1.4629966441051208e-05,
      "loss": 0.1421,
      "step": 516
    },
    {
      "epoch": 1.1023454157782515,
      "grad_norm": 0.3060808479785919,
      "learning_rate": 1.4609539353254679e-05,
      "loss": 0.1446,
      "step": 517
    },
    {
      "epoch": 1.1044776119402986,
      "grad_norm": 0.2841283977031708,
      "learning_rate": 1.4589087812672558e-05,
      "loss": 0.1295,
      "step": 518
    },
    {
      "epoch": 1.1066098081023454,
      "grad_norm": 0.2956883907318115,
      "learning_rate": 1.456861192779663e-05,
      "loss": 0.1475,
      "step": 519
    },
    {
      "epoch": 1.1087420042643923,
      "grad_norm": 0.31035226583480835,
      "learning_rate": 1.4548111807247822e-05,
      "loss": 0.1373,
      "step": 520
    },
    {
      "epoch": 1.1108742004264391,
      "grad_norm": 0.34237828850746155,
      "learning_rate": 1.4527587559775617e-05,
      "loss": 0.1482,
      "step": 521
    },
    {
      "epoch": 1.1130063965884862,
      "grad_norm": 0.3233409523963928,
      "learning_rate": 1.45070392942575e-05,
      "loss": 0.1397,
      "step": 522
    },
    {
      "epoch": 1.115138592750533,
      "grad_norm": 0.28329330682754517,
      "learning_rate": 1.4486467119698358e-05,
      "loss": 0.1294,
      "step": 523
    },
    {
      "epoch": 1.11727078891258,
      "grad_norm": 0.29719725251197815,
      "learning_rate": 1.4465871145229913e-05,
      "loss": 0.12,
      "step": 524
    },
    {
      "epoch": 1.1194029850746268,
      "grad_norm": 0.2937355041503906,
      "learning_rate": 1.4445251480110145e-05,
      "loss": 0.144,
      "step": 525
    },
    {
      "epoch": 1.1215351812366738,
      "grad_norm": 0.29620063304901123,
      "learning_rate": 1.4424608233722708e-05,
      "loss": 0.1253,
      "step": 526
    },
    {
      "epoch": 1.1236673773987207,
      "grad_norm": 0.3143661618232727,
      "learning_rate": 1.4403941515576344e-05,
      "loss": 0.1517,
      "step": 527
    },
    {
      "epoch": 1.1257995735607675,
      "grad_norm": 0.2837240993976593,
      "learning_rate": 1.4383251435304315e-05,
      "loss": 0.1311,
      "step": 528
    },
    {
      "epoch": 1.1279317697228146,
      "grad_norm": 0.3126034736633301,
      "learning_rate": 1.436253810266382e-05,
      "loss": 0.1454,
      "step": 529
    },
    {
      "epoch": 1.1300639658848615,
      "grad_norm": 0.31662634015083313,
      "learning_rate": 1.4341801627535387e-05,
      "loss": 0.1469,
      "step": 530
    },
    {
      "epoch": 1.1321961620469083,
      "grad_norm": 0.2943142056465149,
      "learning_rate": 1.4321042119922337e-05,
      "loss": 0.1357,
      "step": 531
    },
    {
      "epoch": 1.1343283582089552,
      "grad_norm": 0.3376178443431854,
      "learning_rate": 1.4300259689950157e-05,
      "loss": 0.1641,
      "step": 532
    },
    {
      "epoch": 1.136460554371002,
      "grad_norm": 0.3290722966194153,
      "learning_rate": 1.4279454447865937e-05,
      "loss": 0.1547,
      "step": 533
    },
    {
      "epoch": 1.138592750533049,
      "grad_norm": 0.28633052110671997,
      "learning_rate": 1.4258626504037784e-05,
      "loss": 0.1322,
      "step": 534
    },
    {
      "epoch": 1.140724946695096,
      "grad_norm": 0.29939571022987366,
      "learning_rate": 1.4237775968954232e-05,
      "loss": 0.1433,
      "step": 535
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.30931729078292847,
      "learning_rate": 1.4216902953223657e-05,
      "loss": 0.132,
      "step": 536
    },
    {
      "epoch": 1.1449893390191899,
      "grad_norm": 0.30482009053230286,
      "learning_rate": 1.4196007567573688e-05,
      "loss": 0.1448,
      "step": 537
    },
    {
      "epoch": 1.1471215351812367,
      "grad_norm": 0.32131242752075195,
      "learning_rate": 1.4175089922850633e-05,
      "loss": 0.1551,
      "step": 538
    },
    {
      "epoch": 1.1492537313432836,
      "grad_norm": 0.29907363653182983,
      "learning_rate": 1.4154150130018867e-05,
      "loss": 0.1472,
      "step": 539
    },
    {
      "epoch": 1.1513859275053304,
      "grad_norm": 0.30013352632522583,
      "learning_rate": 1.4133188300160261e-05,
      "loss": 0.1449,
      "step": 540
    },
    {
      "epoch": 1.1535181236673775,
      "grad_norm": 0.28574904799461365,
      "learning_rate": 1.4112204544473598e-05,
      "loss": 0.1452,
      "step": 541
    },
    {
      "epoch": 1.1556503198294243,
      "grad_norm": 0.276412695646286,
      "learning_rate": 1.4091198974273962e-05,
      "loss": 0.138,
      "step": 542
    },
    {
      "epoch": 1.1577825159914712,
      "grad_norm": 0.2718970775604248,
      "learning_rate": 1.4070171700992158e-05,
      "loss": 0.1331,
      "step": 543
    },
    {
      "epoch": 1.159914712153518,
      "grad_norm": 0.2848507761955261,
      "learning_rate": 1.4049122836174137e-05,
      "loss": 0.1327,
      "step": 544
    },
    {
      "epoch": 1.1620469083155651,
      "grad_norm": 0.29536789655685425,
      "learning_rate": 1.402805249148037e-05,
      "loss": 0.142,
      "step": 545
    },
    {
      "epoch": 1.164179104477612,
      "grad_norm": 0.28323811292648315,
      "learning_rate": 1.400696077868529e-05,
      "loss": 0.1332,
      "step": 546
    },
    {
      "epoch": 1.1663113006396588,
      "grad_norm": 0.29875215888023376,
      "learning_rate": 1.3985847809676681e-05,
      "loss": 0.1292,
      "step": 547
    },
    {
      "epoch": 1.1684434968017057,
      "grad_norm": 0.3060342073440552,
      "learning_rate": 1.3964713696455074e-05,
      "loss": 0.1387,
      "step": 548
    },
    {
      "epoch": 1.1705756929637527,
      "grad_norm": 0.3175595998764038,
      "learning_rate": 1.3943558551133186e-05,
      "loss": 0.1273,
      "step": 549
    },
    {
      "epoch": 1.1727078891257996,
      "grad_norm": 0.2990242838859558,
      "learning_rate": 1.3922382485935297e-05,
      "loss": 0.1392,
      "step": 550
    },
    {
      "epoch": 1.1748400852878464,
      "grad_norm": 0.29762235283851624,
      "learning_rate": 1.3901185613196655e-05,
      "loss": 0.1245,
      "step": 551
    },
    {
      "epoch": 1.1769722814498933,
      "grad_norm": 0.29613518714904785,
      "learning_rate": 1.3879968045362902e-05,
      "loss": 0.1462,
      "step": 552
    },
    {
      "epoch": 1.1791044776119404,
      "grad_norm": 0.2918592691421509,
      "learning_rate": 1.3858729894989458e-05,
      "loss": 0.1324,
      "step": 553
    },
    {
      "epoch": 1.1812366737739872,
      "grad_norm": 0.275025874376297,
      "learning_rate": 1.3837471274740923e-05,
      "loss": 0.1337,
      "step": 554
    },
    {
      "epoch": 1.183368869936034,
      "grad_norm": 0.293966144323349,
      "learning_rate": 1.3816192297390503e-05,
      "loss": 0.1407,
      "step": 555
    },
    {
      "epoch": 1.1855010660980811,
      "grad_norm": 0.2768610119819641,
      "learning_rate": 1.3794893075819372e-05,
      "loss": 0.1327,
      "step": 556
    },
    {
      "epoch": 1.187633262260128,
      "grad_norm": 0.2820916175842285,
      "learning_rate": 1.3773573723016122e-05,
      "loss": 0.1112,
      "step": 557
    },
    {
      "epoch": 1.1897654584221748,
      "grad_norm": 0.2815762162208557,
      "learning_rate": 1.3752234352076116e-05,
      "loss": 0.1318,
      "step": 558
    },
    {
      "epoch": 1.1918976545842217,
      "grad_norm": 0.28573477268218994,
      "learning_rate": 1.3730875076200913e-05,
      "loss": 0.1306,
      "step": 559
    },
    {
      "epoch": 1.1940298507462686,
      "grad_norm": 0.2934608459472656,
      "learning_rate": 1.370949600869768e-05,
      "loss": 0.1496,
      "step": 560
    },
    {
      "epoch": 1.1961620469083156,
      "grad_norm": 0.28666195273399353,
      "learning_rate": 1.3688097262978555e-05,
      "loss": 0.1307,
      "step": 561
    },
    {
      "epoch": 1.1982942430703625,
      "grad_norm": 0.3158617615699768,
      "learning_rate": 1.3666678952560077e-05,
      "loss": 0.1313,
      "step": 562
    },
    {
      "epoch": 1.2004264392324093,
      "grad_norm": 0.2996523082256317,
      "learning_rate": 1.3645241191062572e-05,
      "loss": 0.1276,
      "step": 563
    },
    {
      "epoch": 1.2025586353944564,
      "grad_norm": 0.30069977045059204,
      "learning_rate": 1.3623784092209544e-05,
      "loss": 0.1281,
      "step": 564
    },
    {
      "epoch": 1.2046908315565032,
      "grad_norm": 0.3160804510116577,
      "learning_rate": 1.3602307769827083e-05,
      "loss": 0.1247,
      "step": 565
    },
    {
      "epoch": 1.20682302771855,
      "grad_norm": 0.2858118712902069,
      "learning_rate": 1.3580812337843262e-05,
      "loss": 0.1182,
      "step": 566
    },
    {
      "epoch": 1.208955223880597,
      "grad_norm": 0.2983522117137909,
      "learning_rate": 1.3559297910287509e-05,
      "loss": 0.1319,
      "step": 567
    },
    {
      "epoch": 1.2110874200426438,
      "grad_norm": 0.3152024745941162,
      "learning_rate": 1.3537764601290039e-05,
      "loss": 0.1456,
      "step": 568
    },
    {
      "epoch": 1.2132196162046909,
      "grad_norm": 0.2773161828517914,
      "learning_rate": 1.3516212525081222e-05,
      "loss": 0.1274,
      "step": 569
    },
    {
      "epoch": 1.2153518123667377,
      "grad_norm": 0.30222707986831665,
      "learning_rate": 1.3494641795990986e-05,
      "loss": 0.1448,
      "step": 570
    },
    {
      "epoch": 1.2174840085287846,
      "grad_norm": 0.2967292070388794,
      "learning_rate": 1.3473052528448203e-05,
      "loss": 0.1426,
      "step": 571
    },
    {
      "epoch": 1.2196162046908317,
      "grad_norm": 0.26482120156288147,
      "learning_rate": 1.3451444836980101e-05,
      "loss": 0.122,
      "step": 572
    },
    {
      "epoch": 1.2217484008528785,
      "grad_norm": 0.26890939474105835,
      "learning_rate": 1.3429818836211633e-05,
      "loss": 0.1249,
      "step": 573
    },
    {
      "epoch": 1.2238805970149254,
      "grad_norm": 0.28393739461898804,
      "learning_rate": 1.340817464086488e-05,
      "loss": 0.129,
      "step": 574
    },
    {
      "epoch": 1.2260127931769722,
      "grad_norm": 0.27766379714012146,
      "learning_rate": 1.3386512365758448e-05,
      "loss": 0.1245,
      "step": 575
    },
    {
      "epoch": 1.2281449893390193,
      "grad_norm": 0.2764897346496582,
      "learning_rate": 1.336483212580685e-05,
      "loss": 0.1174,
      "step": 576
    },
    {
      "epoch": 1.2302771855010661,
      "grad_norm": 0.311836838722229,
      "learning_rate": 1.3343134036019896e-05,
      "loss": 0.1275,
      "step": 577
    },
    {
      "epoch": 1.232409381663113,
      "grad_norm": 0.2901398241519928,
      "learning_rate": 1.3321418211502092e-05,
      "loss": 0.1263,
      "step": 578
    },
    {
      "epoch": 1.2345415778251598,
      "grad_norm": 0.29598554968833923,
      "learning_rate": 1.3299684767452022e-05,
      "loss": 0.1347,
      "step": 579
    },
    {
      "epoch": 1.236673773987207,
      "grad_norm": 0.30042678117752075,
      "learning_rate": 1.3277933819161732e-05,
      "loss": 0.1261,
      "step": 580
    },
    {
      "epoch": 1.2388059701492538,
      "grad_norm": 0.3075614273548126,
      "learning_rate": 1.3256165482016136e-05,
      "loss": 0.1269,
      "step": 581
    },
    {
      "epoch": 1.2409381663113006,
      "grad_norm": 0.3054574131965637,
      "learning_rate": 1.3234379871492381e-05,
      "loss": 0.1324,
      "step": 582
    },
    {
      "epoch": 1.2430703624733475,
      "grad_norm": 0.2944338321685791,
      "learning_rate": 1.3212577103159258e-05,
      "loss": 0.1357,
      "step": 583
    },
    {
      "epoch": 1.2452025586353945,
      "grad_norm": 0.2848133146762848,
      "learning_rate": 1.319075729267657e-05,
      "loss": 0.1349,
      "step": 584
    },
    {
      "epoch": 1.2473347547974414,
      "grad_norm": 0.29471203684806824,
      "learning_rate": 1.3168920555794524e-05,
      "loss": 0.1404,
      "step": 585
    },
    {
      "epoch": 1.2494669509594882,
      "grad_norm": 0.2983267307281494,
      "learning_rate": 1.3147067008353123e-05,
      "loss": 0.1486,
      "step": 586
    },
    {
      "epoch": 1.251599147121535,
      "grad_norm": 0.3300533592700958,
      "learning_rate": 1.3125196766281546e-05,
      "loss": 0.1461,
      "step": 587
    },
    {
      "epoch": 1.2537313432835822,
      "grad_norm": 0.30575454235076904,
      "learning_rate": 1.310330994559753e-05,
      "loss": 0.1318,
      "step": 588
    },
    {
      "epoch": 1.255863539445629,
      "grad_norm": 0.29243308305740356,
      "learning_rate": 1.3081406662406764e-05,
      "loss": 0.1411,
      "step": 589
    },
    {
      "epoch": 1.2579957356076759,
      "grad_norm": 0.281562864780426,
      "learning_rate": 1.305948703290227e-05,
      "loss": 0.1373,
      "step": 590
    },
    {
      "epoch": 1.260127931769723,
      "grad_norm": 0.2830953598022461,
      "learning_rate": 1.3037551173363775e-05,
      "loss": 0.1315,
      "step": 591
    },
    {
      "epoch": 1.2622601279317698,
      "grad_norm": 0.31127020716667175,
      "learning_rate": 1.3015599200157108e-05,
      "loss": 0.132,
      "step": 592
    },
    {
      "epoch": 1.2643923240938166,
      "grad_norm": 0.3360152542591095,
      "learning_rate": 1.2993631229733584e-05,
      "loss": 0.1602,
      "step": 593
    },
    {
      "epoch": 1.2665245202558635,
      "grad_norm": 0.2867451310157776,
      "learning_rate": 1.2971647378629367e-05,
      "loss": 0.1209,
      "step": 594
    },
    {
      "epoch": 1.2686567164179103,
      "grad_norm": 0.2722858786582947,
      "learning_rate": 1.2949647763464879e-05,
      "loss": 0.1235,
      "step": 595
    },
    {
      "epoch": 1.2707889125799574,
      "grad_norm": 0.28699299693107605,
      "learning_rate": 1.292763250094416e-05,
      "loss": 0.1189,
      "step": 596
    },
    {
      "epoch": 1.2729211087420043,
      "grad_norm": 0.31939896941185,
      "learning_rate": 1.2905601707854257e-05,
      "loss": 0.1694,
      "step": 597
    },
    {
      "epoch": 1.275053304904051,
      "grad_norm": 0.2996886372566223,
      "learning_rate": 1.2883555501064603e-05,
      "loss": 0.1341,
      "step": 598
    },
    {
      "epoch": 1.2771855010660982,
      "grad_norm": 0.2666231691837311,
      "learning_rate": 1.2861493997526409e-05,
      "loss": 0.1197,
      "step": 599
    },
    {
      "epoch": 1.279317697228145,
      "grad_norm": 0.30322062969207764,
      "learning_rate": 1.2839417314272016e-05,
      "loss": 0.1256,
      "step": 600
    },
    {
      "epoch": 1.2814498933901919,
      "grad_norm": 0.2866310179233551,
      "learning_rate": 1.2817325568414299e-05,
      "loss": 0.1253,
      "step": 601
    },
    {
      "epoch": 1.2835820895522387,
      "grad_norm": 0.27121296525001526,
      "learning_rate": 1.2795218877146036e-05,
      "loss": 0.1126,
      "step": 602
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 0.29578840732574463,
      "learning_rate": 1.2773097357739288e-05,
      "loss": 0.1269,
      "step": 603
    },
    {
      "epoch": 1.2878464818763327,
      "grad_norm": 0.3106514811515808,
      "learning_rate": 1.2750961127544782e-05,
      "loss": 0.141,
      "step": 604
    },
    {
      "epoch": 1.2899786780383795,
      "grad_norm": 0.33178550004959106,
      "learning_rate": 1.2728810303991273e-05,
      "loss": 0.1291,
      "step": 605
    },
    {
      "epoch": 1.2921108742004264,
      "grad_norm": 0.2680860757827759,
      "learning_rate": 1.2706645004584936e-05,
      "loss": 0.1206,
      "step": 606
    },
    {
      "epoch": 1.2942430703624734,
      "grad_norm": 0.28381457924842834,
      "learning_rate": 1.2684465346908742e-05,
      "loss": 0.1245,
      "step": 607
    },
    {
      "epoch": 1.2963752665245203,
      "grad_norm": 0.3239479959011078,
      "learning_rate": 1.2662271448621823e-05,
      "loss": 0.142,
      "step": 608
    },
    {
      "epoch": 1.2985074626865671,
      "grad_norm": 0.2966885566711426,
      "learning_rate": 1.2640063427458858e-05,
      "loss": 0.1236,
      "step": 609
    },
    {
      "epoch": 1.3006396588486142,
      "grad_norm": 0.3145623803138733,
      "learning_rate": 1.2617841401229445e-05,
      "loss": 0.128,
      "step": 610
    },
    {
      "epoch": 1.302771855010661,
      "grad_norm": 0.2816142737865448,
      "learning_rate": 1.2595605487817481e-05,
      "loss": 0.1267,
      "step": 611
    },
    {
      "epoch": 1.304904051172708,
      "grad_norm": 0.3208594024181366,
      "learning_rate": 1.2573355805180523e-05,
      "loss": 0.1355,
      "step": 612
    },
    {
      "epoch": 1.3070362473347548,
      "grad_norm": 0.2827913463115692,
      "learning_rate": 1.2551092471349177e-05,
      "loss": 0.1218,
      "step": 613
    },
    {
      "epoch": 1.3091684434968016,
      "grad_norm": 0.27586838603019714,
      "learning_rate": 1.2528815604426469e-05,
      "loss": 0.1273,
      "step": 614
    },
    {
      "epoch": 1.3113006396588487,
      "grad_norm": 0.2845800817012787,
      "learning_rate": 1.2506525322587207e-05,
      "loss": 0.129,
      "step": 615
    },
    {
      "epoch": 1.3134328358208955,
      "grad_norm": 0.28390008211135864,
      "learning_rate": 1.2484221744077367e-05,
      "loss": 0.1216,
      "step": 616
    },
    {
      "epoch": 1.3155650319829424,
      "grad_norm": 0.2897316813468933,
      "learning_rate": 1.2461904987213469e-05,
      "loss": 0.1365,
      "step": 617
    },
    {
      "epoch": 1.3176972281449895,
      "grad_norm": 0.2884681522846222,
      "learning_rate": 1.2439575170381928e-05,
      "loss": 0.1241,
      "step": 618
    },
    {
      "epoch": 1.3198294243070363,
      "grad_norm": 0.29738593101501465,
      "learning_rate": 1.241723241203845e-05,
      "loss": 0.1277,
      "step": 619
    },
    {
      "epoch": 1.3219616204690832,
      "grad_norm": 0.2872629463672638,
      "learning_rate": 1.2394876830707388e-05,
      "loss": 0.1184,
      "step": 620
    },
    {
      "epoch": 1.32409381663113,
      "grad_norm": 0.29579243063926697,
      "learning_rate": 1.2372508544981121e-05,
      "loss": 0.1219,
      "step": 621
    },
    {
      "epoch": 1.3262260127931769,
      "grad_norm": 0.3117382824420929,
      "learning_rate": 1.2350127673519425e-05,
      "loss": 0.1377,
      "step": 622
    },
    {
      "epoch": 1.328358208955224,
      "grad_norm": 0.29269376397132874,
      "learning_rate": 1.2327734335048838e-05,
      "loss": 0.1267,
      "step": 623
    },
    {
      "epoch": 1.3304904051172708,
      "grad_norm": 0.32437101006507874,
      "learning_rate": 1.2305328648362029e-05,
      "loss": 0.1268,
      "step": 624
    },
    {
      "epoch": 1.3326226012793176,
      "grad_norm": 0.28904077410697937,
      "learning_rate": 1.2282910732317181e-05,
      "loss": 0.1322,
      "step": 625
    },
    {
      "epoch": 1.3347547974413647,
      "grad_norm": 0.2851308286190033,
      "learning_rate": 1.226048070583735e-05,
      "loss": 0.1289,
      "step": 626
    },
    {
      "epoch": 1.3368869936034116,
      "grad_norm": 0.28353792428970337,
      "learning_rate": 1.2238038687909828e-05,
      "loss": 0.1232,
      "step": 627
    },
    {
      "epoch": 1.3390191897654584,
      "grad_norm": 0.28267207741737366,
      "learning_rate": 1.2215584797585525e-05,
      "loss": 0.1076,
      "step": 628
    },
    {
      "epoch": 1.3411513859275053,
      "grad_norm": 0.30818670988082886,
      "learning_rate": 1.2193119153978332e-05,
      "loss": 0.1191,
      "step": 629
    },
    {
      "epoch": 1.3432835820895521,
      "grad_norm": 0.3344326913356781,
      "learning_rate": 1.217064187626449e-05,
      "loss": 0.1408,
      "step": 630
    },
    {
      "epoch": 1.3454157782515992,
      "grad_norm": 0.3269572854042053,
      "learning_rate": 1.2148153083681956e-05,
      "loss": 0.1323,
      "step": 631
    },
    {
      "epoch": 1.347547974413646,
      "grad_norm": 0.2918147146701813,
      "learning_rate": 1.2125652895529766e-05,
      "loss": 0.1121,
      "step": 632
    },
    {
      "epoch": 1.349680170575693,
      "grad_norm": 0.2786194384098053,
      "learning_rate": 1.210314143116742e-05,
      "loss": 0.0995,
      "step": 633
    },
    {
      "epoch": 1.35181236673774,
      "grad_norm": 0.2949158251285553,
      "learning_rate": 1.2080618810014221e-05,
      "loss": 0.1309,
      "step": 634
    },
    {
      "epoch": 1.3539445628997868,
      "grad_norm": 0.2867473363876343,
      "learning_rate": 1.2058085151548668e-05,
      "loss": 0.1219,
      "step": 635
    },
    {
      "epoch": 1.3560767590618337,
      "grad_norm": 0.31275904178619385,
      "learning_rate": 1.203554057530781e-05,
      "loss": 0.1259,
      "step": 636
    },
    {
      "epoch": 1.3582089552238805,
      "grad_norm": 0.31117039918899536,
      "learning_rate": 1.2012985200886602e-05,
      "loss": 0.1345,
      "step": 637
    },
    {
      "epoch": 1.3603411513859274,
      "grad_norm": 0.30509188771247864,
      "learning_rate": 1.1990419147937296e-05,
      "loss": 0.1259,
      "step": 638
    },
    {
      "epoch": 1.3624733475479744,
      "grad_norm": 0.29434773325920105,
      "learning_rate": 1.1967842536168785e-05,
      "loss": 0.1222,
      "step": 639
    },
    {
      "epoch": 1.3646055437100213,
      "grad_norm": 0.2976706624031067,
      "learning_rate": 1.1945255485345973e-05,
      "loss": 0.1218,
      "step": 640
    },
    {
      "epoch": 1.3667377398720681,
      "grad_norm": 0.2863085865974426,
      "learning_rate": 1.1922658115289141e-05,
      "loss": 0.1254,
      "step": 641
    },
    {
      "epoch": 1.3688699360341152,
      "grad_norm": 0.30139487981796265,
      "learning_rate": 1.190005054587332e-05,
      "loss": 0.1278,
      "step": 642
    },
    {
      "epoch": 1.371002132196162,
      "grad_norm": 0.26754313707351685,
      "learning_rate": 1.1877432897027637e-05,
      "loss": 0.1021,
      "step": 643
    },
    {
      "epoch": 1.373134328358209,
      "grad_norm": 0.2978397011756897,
      "learning_rate": 1.185480528873469e-05,
      "loss": 0.137,
      "step": 644
    },
    {
      "epoch": 1.375266524520256,
      "grad_norm": 0.26995065808296204,
      "learning_rate": 1.1832167841029918e-05,
      "loss": 0.1122,
      "step": 645
    },
    {
      "epoch": 1.3773987206823028,
      "grad_norm": 0.28850165009498596,
      "learning_rate": 1.1809520674000946e-05,
      "loss": 0.117,
      "step": 646
    },
    {
      "epoch": 1.3795309168443497,
      "grad_norm": 0.2815125584602356,
      "learning_rate": 1.1786863907786966e-05,
      "loss": 0.1063,
      "step": 647
    },
    {
      "epoch": 1.3816631130063965,
      "grad_norm": 0.2836846709251404,
      "learning_rate": 1.1764197662578087e-05,
      "loss": 0.1095,
      "step": 648
    },
    {
      "epoch": 1.3837953091684434,
      "grad_norm": 0.26442912220954895,
      "learning_rate": 1.1741522058614705e-05,
      "loss": 0.1046,
      "step": 649
    },
    {
      "epoch": 1.3859275053304905,
      "grad_norm": 0.28688374161720276,
      "learning_rate": 1.171883721618686e-05,
      "loss": 0.1105,
      "step": 650
    },
    {
      "epoch": 1.3880597014925373,
      "grad_norm": 0.2822731137275696,
      "learning_rate": 1.1696143255633607e-05,
      "loss": 0.1086,
      "step": 651
    },
    {
      "epoch": 1.3901918976545842,
      "grad_norm": 0.29498419165611267,
      "learning_rate": 1.1673440297342365e-05,
      "loss": 0.1119,
      "step": 652
    },
    {
      "epoch": 1.3923240938166312,
      "grad_norm": 0.27823448181152344,
      "learning_rate": 1.165072846174828e-05,
      "loss": 0.1144,
      "step": 653
    },
    {
      "epoch": 1.394456289978678,
      "grad_norm": 0.284491628408432,
      "learning_rate": 1.1628007869333604e-05,
      "loss": 0.1191,
      "step": 654
    },
    {
      "epoch": 1.396588486140725,
      "grad_norm": 0.2788254916667938,
      "learning_rate": 1.1605278640627029e-05,
      "loss": 0.1225,
      "step": 655
    },
    {
      "epoch": 1.3987206823027718,
      "grad_norm": 0.27423039078712463,
      "learning_rate": 1.1582540896203067e-05,
      "loss": 0.1101,
      "step": 656
    },
    {
      "epoch": 1.4008528784648187,
      "grad_norm": 0.2706218361854553,
      "learning_rate": 1.155979475668141e-05,
      "loss": 0.1057,
      "step": 657
    },
    {
      "epoch": 1.4029850746268657,
      "grad_norm": 0.26912498474121094,
      "learning_rate": 1.153704034272627e-05,
      "loss": 0.1161,
      "step": 658
    },
    {
      "epoch": 1.4051172707889126,
      "grad_norm": 0.2669185698032379,
      "learning_rate": 1.1514277775045768e-05,
      "loss": 0.1155,
      "step": 659
    },
    {
      "epoch": 1.4072494669509594,
      "grad_norm": 0.2882708013057709,
      "learning_rate": 1.1491507174391272e-05,
      "loss": 0.1282,
      "step": 660
    },
    {
      "epoch": 1.4093816631130065,
      "grad_norm": 0.28854480385780334,
      "learning_rate": 1.1468728661556761e-05,
      "loss": 0.1125,
      "step": 661
    },
    {
      "epoch": 1.4115138592750534,
      "grad_norm": 0.3083078861236572,
      "learning_rate": 1.1445942357378193e-05,
      "loss": 0.122,
      "step": 662
    },
    {
      "epoch": 1.4136460554371002,
      "grad_norm": 0.26903215050697327,
      "learning_rate": 1.1423148382732854e-05,
      "loss": 0.1051,
      "step": 663
    },
    {
      "epoch": 1.415778251599147,
      "grad_norm": 0.307066410779953,
      "learning_rate": 1.140034685853872e-05,
      "loss": 0.136,
      "step": 664
    },
    {
      "epoch": 1.417910447761194,
      "grad_norm": 0.2715030312538147,
      "learning_rate": 1.137753790575382e-05,
      "loss": 0.0984,
      "step": 665
    },
    {
      "epoch": 1.420042643923241,
      "grad_norm": 0.33102524280548096,
      "learning_rate": 1.1354721645375587e-05,
      "loss": 0.1415,
      "step": 666
    },
    {
      "epoch": 1.4221748400852878,
      "grad_norm": 0.28740158677101135,
      "learning_rate": 1.133189819844022e-05,
      "loss": 0.1086,
      "step": 667
    },
    {
      "epoch": 1.4243070362473347,
      "grad_norm": 0.29252275824546814,
      "learning_rate": 1.1309067686022038e-05,
      "loss": 0.1262,
      "step": 668
    },
    {
      "epoch": 1.4264392324093818,
      "grad_norm": 0.2780110239982605,
      "learning_rate": 1.1286230229232851e-05,
      "loss": 0.1107,
      "step": 669
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.2761909067630768,
      "learning_rate": 1.1263385949221294e-05,
      "loss": 0.1202,
      "step": 670
    },
    {
      "epoch": 1.4307036247334755,
      "grad_norm": 0.2905082106590271,
      "learning_rate": 1.1240534967172209e-05,
      "loss": 0.1241,
      "step": 671
    },
    {
      "epoch": 1.4328358208955223,
      "grad_norm": 0.29942044615745544,
      "learning_rate": 1.1217677404305993e-05,
      "loss": 0.1247,
      "step": 672
    },
    {
      "epoch": 1.4349680170575694,
      "grad_norm": 0.2836439907550812,
      "learning_rate": 1.1194813381877939e-05,
      "loss": 0.1179,
      "step": 673
    },
    {
      "epoch": 1.4371002132196162,
      "grad_norm": 0.35415342450141907,
      "learning_rate": 1.1171943021177616e-05,
      "loss": 0.133,
      "step": 674
    },
    {
      "epoch": 1.439232409381663,
      "grad_norm": 0.31049808859825134,
      "learning_rate": 1.1149066443528218e-05,
      "loss": 0.1258,
      "step": 675
    },
    {
      "epoch": 1.44136460554371,
      "grad_norm": 0.2875591516494751,
      "learning_rate": 1.1126183770285918e-05,
      "loss": 0.1191,
      "step": 676
    },
    {
      "epoch": 1.443496801705757,
      "grad_norm": 0.27964743971824646,
      "learning_rate": 1.1103295122839222e-05,
      "loss": 0.1133,
      "step": 677
    },
    {
      "epoch": 1.4456289978678039,
      "grad_norm": 0.2736676335334778,
      "learning_rate": 1.1080400622608329e-05,
      "loss": 0.1065,
      "step": 678
    },
    {
      "epoch": 1.4477611940298507,
      "grad_norm": 0.2715415060520172,
      "learning_rate": 1.1057500391044489e-05,
      "loss": 0.1101,
      "step": 679
    },
    {
      "epoch": 1.4498933901918978,
      "grad_norm": 0.28062522411346436,
      "learning_rate": 1.1034594549629349e-05,
      "loss": 0.1151,
      "step": 680
    },
    {
      "epoch": 1.4520255863539446,
      "grad_norm": 0.2814277112483978,
      "learning_rate": 1.1011683219874324e-05,
      "loss": 0.115,
      "step": 681
    },
    {
      "epoch": 1.4541577825159915,
      "grad_norm": 0.2992006242275238,
      "learning_rate": 1.0988766523319936e-05,
      "loss": 0.1142,
      "step": 682
    },
    {
      "epoch": 1.4562899786780383,
      "grad_norm": 0.2845548093318939,
      "learning_rate": 1.0965844581535179e-05,
      "loss": 0.11,
      "step": 683
    },
    {
      "epoch": 1.4584221748400852,
      "grad_norm": 0.2885189950466156,
      "learning_rate": 1.094291751611688e-05,
      "loss": 0.114,
      "step": 684
    },
    {
      "epoch": 1.4605543710021323,
      "grad_norm": 0.25957709550857544,
      "learning_rate": 1.0919985448689032e-05,
      "loss": 0.0992,
      "step": 685
    },
    {
      "epoch": 1.462686567164179,
      "grad_norm": 0.28382349014282227,
      "learning_rate": 1.0897048500902172e-05,
      "loss": 0.1101,
      "step": 686
    },
    {
      "epoch": 1.464818763326226,
      "grad_norm": 0.28266605734825134,
      "learning_rate": 1.0874106794432728e-05,
      "loss": 0.1204,
      "step": 687
    },
    {
      "epoch": 1.466950959488273,
      "grad_norm": 0.26493799686431885,
      "learning_rate": 1.0851160450982363e-05,
      "loss": 0.1175,
      "step": 688
    },
    {
      "epoch": 1.4690831556503199,
      "grad_norm": 0.2843646705150604,
      "learning_rate": 1.0828209592277345e-05,
      "loss": 0.12,
      "step": 689
    },
    {
      "epoch": 1.4712153518123667,
      "grad_norm": 0.3063797354698181,
      "learning_rate": 1.08052543400679e-05,
      "loss": 0.1319,
      "step": 690
    },
    {
      "epoch": 1.4733475479744136,
      "grad_norm": 0.27840349078178406,
      "learning_rate": 1.0782294816127541e-05,
      "loss": 0.1189,
      "step": 691
    },
    {
      "epoch": 1.4754797441364604,
      "grad_norm": 0.2832636535167694,
      "learning_rate": 1.0759331142252463e-05,
      "loss": 0.1251,
      "step": 692
    },
    {
      "epoch": 1.4776119402985075,
      "grad_norm": 0.27502548694610596,
      "learning_rate": 1.0736363440260868e-05,
      "loss": 0.1002,
      "step": 693
    },
    {
      "epoch": 1.4797441364605544,
      "grad_norm": 0.30334800481796265,
      "learning_rate": 1.0713391831992324e-05,
      "loss": 0.109,
      "step": 694
    },
    {
      "epoch": 1.4818763326226012,
      "grad_norm": 0.2801240384578705,
      "learning_rate": 1.0690416439307123e-05,
      "loss": 0.1208,
      "step": 695
    },
    {
      "epoch": 1.4840085287846483,
      "grad_norm": 0.3226374685764313,
      "learning_rate": 1.0667437384085635e-05,
      "loss": 0.1369,
      "step": 696
    },
    {
      "epoch": 1.4861407249466951,
      "grad_norm": 0.42007389664649963,
      "learning_rate": 1.0644454788227651e-05,
      "loss": 0.0996,
      "step": 697
    },
    {
      "epoch": 1.488272921108742,
      "grad_norm": 0.2665589451789856,
      "learning_rate": 1.0621468773651755e-05,
      "loss": 0.1021,
      "step": 698
    },
    {
      "epoch": 1.4904051172707888,
      "grad_norm": 0.2792797088623047,
      "learning_rate": 1.0598479462294665e-05,
      "loss": 0.1177,
      "step": 699
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 0.26719143986701965,
      "learning_rate": 1.0575486976110576e-05,
      "loss": 0.1062,
      "step": 700
    },
    {
      "epoch": 1.4946695095948828,
      "grad_norm": 0.27116918563842773,
      "learning_rate": 1.0552491437070537e-05,
      "loss": 0.0988,
      "step": 701
    },
    {
      "epoch": 1.4968017057569296,
      "grad_norm": 0.2862342298030853,
      "learning_rate": 1.0529492967161794e-05,
      "loss": 0.1196,
      "step": 702
    },
    {
      "epoch": 1.4989339019189765,
      "grad_norm": 0.3090691566467285,
      "learning_rate": 1.0506491688387128e-05,
      "loss": 0.1143,
      "step": 703
    },
    {
      "epoch": 1.5010660980810235,
      "grad_norm": 0.28765439987182617,
      "learning_rate": 1.0483487722764232e-05,
      "loss": 0.1121,
      "step": 704
    },
    {
      "epoch": 1.5031982942430704,
      "grad_norm": 0.27287769317626953,
      "learning_rate": 1.0460481192325045e-05,
      "loss": 0.1088,
      "step": 705
    },
    {
      "epoch": 1.5053304904051172,
      "grad_norm": 0.32534995675086975,
      "learning_rate": 1.0437472219115119e-05,
      "loss": 0.1247,
      "step": 706
    },
    {
      "epoch": 1.5074626865671643,
      "grad_norm": 0.27077364921569824,
      "learning_rate": 1.0414460925192957e-05,
      "loss": 0.1073,
      "step": 707
    },
    {
      "epoch": 1.509594882729211,
      "grad_norm": 0.29241102933883667,
      "learning_rate": 1.0391447432629376e-05,
      "loss": 0.1158,
      "step": 708
    },
    {
      "epoch": 1.511727078891258,
      "grad_norm": 0.28685319423675537,
      "learning_rate": 1.0368431863506861e-05,
      "loss": 0.1163,
      "step": 709
    },
    {
      "epoch": 1.5138592750533049,
      "grad_norm": 0.2969968914985657,
      "learning_rate": 1.0345414339918902e-05,
      "loss": 0.1263,
      "step": 710
    },
    {
      "epoch": 1.5159914712153517,
      "grad_norm": 0.2584787607192993,
      "learning_rate": 1.0322394983969369e-05,
      "loss": 0.0977,
      "step": 711
    },
    {
      "epoch": 1.5181236673773988,
      "grad_norm": 0.283424437046051,
      "learning_rate": 1.0299373917771846e-05,
      "loss": 0.1115,
      "step": 712
    },
    {
      "epoch": 1.5202558635394456,
      "grad_norm": 0.27194857597351074,
      "learning_rate": 1.027635126344899e-05,
      "loss": 0.1177,
      "step": 713
    },
    {
      "epoch": 1.5223880597014925,
      "grad_norm": 0.2881547212600708,
      "learning_rate": 1.025332714313188e-05,
      "loss": 0.1244,
      "step": 714
    },
    {
      "epoch": 1.5245202558635396,
      "grad_norm": 0.29802486300468445,
      "learning_rate": 1.023030167895938e-05,
      "loss": 0.1203,
      "step": 715
    },
    {
      "epoch": 1.5266524520255862,
      "grad_norm": 0.296964555978775,
      "learning_rate": 1.0207274993077475e-05,
      "loss": 0.1222,
      "step": 716
    },
    {
      "epoch": 1.5287846481876333,
      "grad_norm": 0.2928577959537506,
      "learning_rate": 1.0184247207638636e-05,
      "loss": 0.1209,
      "step": 717
    },
    {
      "epoch": 1.5309168443496801,
      "grad_norm": 0.28409287333488464,
      "learning_rate": 1.0161218444801164e-05,
      "loss": 0.1112,
      "step": 718
    },
    {
      "epoch": 1.533049040511727,
      "grad_norm": 0.2740783393383026,
      "learning_rate": 1.0138188826728544e-05,
      "loss": 0.1048,
      "step": 719
    },
    {
      "epoch": 1.535181236673774,
      "grad_norm": 0.2585115432739258,
      "learning_rate": 1.01151584755888e-05,
      "loss": 0.0959,
      "step": 720
    },
    {
      "epoch": 1.537313432835821,
      "grad_norm": 0.3090876042842865,
      "learning_rate": 1.0092127513553852e-05,
      "loss": 0.1186,
      "step": 721
    },
    {
      "epoch": 1.5394456289978677,
      "grad_norm": 0.2472897619009018,
      "learning_rate": 1.006909606279884e-05,
      "loss": 0.0858,
      "step": 722
    },
    {
      "epoch": 1.5415778251599148,
      "grad_norm": 0.27307748794555664,
      "learning_rate": 1.0046064245501519e-05,
      "loss": 0.1035,
      "step": 723
    },
    {
      "epoch": 1.5437100213219617,
      "grad_norm": 0.2620445191860199,
      "learning_rate": 1.0023032183841579e-05,
      "loss": 0.1014,
      "step": 724
    },
    {
      "epoch": 1.5458422174840085,
      "grad_norm": 0.28344202041625977,
      "learning_rate": 1e-05,
      "loss": 0.1101,
      "step": 725
    },
    {
      "epoch": 1.5479744136460556,
      "grad_norm": 0.3007964491844177,
      "learning_rate": 9.976967816158424e-06,
      "loss": 0.1262,
      "step": 726
    },
    {
      "epoch": 1.5501066098081022,
      "grad_norm": 0.2514021098613739,
      "learning_rate": 9.953935754498484e-06,
      "loss": 0.1001,
      "step": 727
    },
    {
      "epoch": 1.5522388059701493,
      "grad_norm": 0.2804054021835327,
      "learning_rate": 9.930903937201163e-06,
      "loss": 0.1177,
      "step": 728
    },
    {
      "epoch": 1.5543710021321961,
      "grad_norm": 0.28405043482780457,
      "learning_rate": 9.907872486446153e-06,
      "loss": 0.1117,
      "step": 729
    },
    {
      "epoch": 1.556503198294243,
      "grad_norm": 0.27032312750816345,
      "learning_rate": 9.884841524411202e-06,
      "loss": 0.0908,
      "step": 730
    },
    {
      "epoch": 1.55863539445629,
      "grad_norm": 0.29671114683151245,
      "learning_rate": 9.86181117327146e-06,
      "loss": 0.1145,
      "step": 731
    },
    {
      "epoch": 1.560767590618337,
      "grad_norm": 0.33382168412208557,
      "learning_rate": 9.838781555198839e-06,
      "loss": 0.1089,
      "step": 732
    },
    {
      "epoch": 1.5628997867803838,
      "grad_norm": 0.2781282663345337,
      "learning_rate": 9.815752792361369e-06,
      "loss": 0.0928,
      "step": 733
    },
    {
      "epoch": 1.5650319829424308,
      "grad_norm": 0.25717800855636597,
      "learning_rate": 9.792725006922528e-06,
      "loss": 0.0941,
      "step": 734
    },
    {
      "epoch": 1.5671641791044775,
      "grad_norm": 0.28582993149757385,
      "learning_rate": 9.769698321040622e-06,
      "loss": 0.1146,
      "step": 735
    },
    {
      "epoch": 1.5692963752665245,
      "grad_norm": 0.2915722727775574,
      "learning_rate": 9.746672856868124e-06,
      "loss": 0.106,
      "step": 736
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.27611804008483887,
      "learning_rate": 9.723648736551015e-06,
      "loss": 0.1009,
      "step": 737
    },
    {
      "epoch": 1.5735607675906182,
      "grad_norm": 0.2677275836467743,
      "learning_rate": 9.700626082228155e-06,
      "loss": 0.109,
      "step": 738
    },
    {
      "epoch": 1.5756929637526653,
      "grad_norm": 0.2777155637741089,
      "learning_rate": 9.677605016030633e-06,
      "loss": 0.1088,
      "step": 739
    },
    {
      "epoch": 1.5778251599147122,
      "grad_norm": 0.2872233986854553,
      "learning_rate": 9.6545856600811e-06,
      "loss": 0.1151,
      "step": 740
    },
    {
      "epoch": 1.579957356076759,
      "grad_norm": 0.27333804965019226,
      "learning_rate": 9.631568136493142e-06,
      "loss": 0.0898,
      "step": 741
    },
    {
      "epoch": 1.582089552238806,
      "grad_norm": 0.25844424962997437,
      "learning_rate": 9.608552567370627e-06,
      "loss": 0.0966,
      "step": 742
    },
    {
      "epoch": 1.5842217484008527,
      "grad_norm": 0.3176112174987793,
      "learning_rate": 9.585539074807046e-06,
      "loss": 0.1248,
      "step": 743
    },
    {
      "epoch": 1.5863539445628998,
      "grad_norm": 0.27444198727607727,
      "learning_rate": 9.562527780884884e-06,
      "loss": 0.1101,
      "step": 744
    },
    {
      "epoch": 1.5884861407249466,
      "grad_norm": 0.28177401423454285,
      "learning_rate": 9.539518807674958e-06,
      "loss": 0.111,
      "step": 745
    },
    {
      "epoch": 1.5906183368869935,
      "grad_norm": 0.29310888051986694,
      "learning_rate": 9.516512277235771e-06,
      "loss": 0.1159,
      "step": 746
    },
    {
      "epoch": 1.5927505330490406,
      "grad_norm": 0.33907216787338257,
      "learning_rate": 9.493508311612874e-06,
      "loss": 0.1351,
      "step": 747
    },
    {
      "epoch": 1.5948827292110874,
      "grad_norm": 0.2683156430721283,
      "learning_rate": 9.470507032838208e-06,
      "loss": 0.0998,
      "step": 748
    },
    {
      "epoch": 1.5970149253731343,
      "grad_norm": 0.288318008184433,
      "learning_rate": 9.447508562929465e-06,
      "loss": 0.1305,
      "step": 749
    },
    {
      "epoch": 1.5991471215351813,
      "grad_norm": 0.25735047459602356,
      "learning_rate": 9.424513023889427e-06,
      "loss": 0.105,
      "step": 750
    },
    {
      "epoch": 1.6012793176972282,
      "grad_norm": 0.3115786910057068,
      "learning_rate": 9.401520537705339e-06,
      "loss": 0.1267,
      "step": 751
    },
    {
      "epoch": 1.603411513859275,
      "grad_norm": 0.2693006098270416,
      "learning_rate": 9.378531226348247e-06,
      "loss": 0.1073,
      "step": 752
    },
    {
      "epoch": 1.6055437100213221,
      "grad_norm": 1.2381782531738281,
      "learning_rate": 9.35554521177235e-06,
      "loss": 0.0958,
      "step": 753
    },
    {
      "epoch": 1.6076759061833688,
      "grad_norm": 0.2881345748901367,
      "learning_rate": 9.332562615914369e-06,
      "loss": 0.1151,
      "step": 754
    },
    {
      "epoch": 1.6098081023454158,
      "grad_norm": 0.3106001019477844,
      "learning_rate": 9.30958356069288e-06,
      "loss": 0.1275,
      "step": 755
    },
    {
      "epoch": 1.6119402985074627,
      "grad_norm": 0.29780668020248413,
      "learning_rate": 9.286608168007678e-06,
      "loss": 0.1109,
      "step": 756
    },
    {
      "epoch": 1.6140724946695095,
      "grad_norm": 0.2577870190143585,
      "learning_rate": 9.263636559739134e-06,
      "loss": 0.0917,
      "step": 757
    },
    {
      "epoch": 1.6162046908315566,
      "grad_norm": 0.32105955481529236,
      "learning_rate": 9.24066885774754e-06,
      "loss": 0.1223,
      "step": 758
    },
    {
      "epoch": 1.6183368869936035,
      "grad_norm": 0.26291677355766296,
      "learning_rate": 9.217705183872462e-06,
      "loss": 0.1036,
      "step": 759
    },
    {
      "epoch": 1.6204690831556503,
      "grad_norm": 0.2605167329311371,
      "learning_rate": 9.194745659932106e-06,
      "loss": 0.0951,
      "step": 760
    },
    {
      "epoch": 1.6226012793176974,
      "grad_norm": 0.2719053030014038,
      "learning_rate": 9.171790407722657e-06,
      "loss": 0.11,
      "step": 761
    },
    {
      "epoch": 1.624733475479744,
      "grad_norm": 0.2709570825099945,
      "learning_rate": 9.14883954901764e-06,
      "loss": 0.1071,
      "step": 762
    },
    {
      "epoch": 1.626865671641791,
      "grad_norm": 0.2657148241996765,
      "learning_rate": 9.125893205567274e-06,
      "loss": 0.1035,
      "step": 763
    },
    {
      "epoch": 1.628997867803838,
      "grad_norm": 0.27934330701828003,
      "learning_rate": 9.10295149909783e-06,
      "loss": 0.1171,
      "step": 764
    },
    {
      "epoch": 1.6311300639658848,
      "grad_norm": 0.2798602283000946,
      "learning_rate": 9.08001455131097e-06,
      "loss": 0.1078,
      "step": 765
    },
    {
      "epoch": 1.6332622601279319,
      "grad_norm": 0.27460166811943054,
      "learning_rate": 9.057082483883123e-06,
      "loss": 0.1083,
      "step": 766
    },
    {
      "epoch": 1.6353944562899787,
      "grad_norm": 0.2971448302268982,
      "learning_rate": 9.034155418464823e-06,
      "loss": 0.1144,
      "step": 767
    },
    {
      "epoch": 1.6375266524520256,
      "grad_norm": 0.27758264541625977,
      "learning_rate": 9.011233476680068e-06,
      "loss": 0.1013,
      "step": 768
    },
    {
      "epoch": 1.6396588486140726,
      "grad_norm": 0.2626176178455353,
      "learning_rate": 8.98831678012568e-06,
      "loss": 0.1007,
      "step": 769
    },
    {
      "epoch": 1.6417910447761193,
      "grad_norm": 0.2866419553756714,
      "learning_rate": 8.965405450370656e-06,
      "loss": 0.1038,
      "step": 770
    },
    {
      "epoch": 1.6439232409381663,
      "grad_norm": 0.2638983428478241,
      "learning_rate": 8.942499608955516e-06,
      "loss": 0.0914,
      "step": 771
    },
    {
      "epoch": 1.6460554371002132,
      "grad_norm": 0.26549509167671204,
      "learning_rate": 8.919599377391673e-06,
      "loss": 0.101,
      "step": 772
    },
    {
      "epoch": 1.64818763326226,
      "grad_norm": 0.262743204832077,
      "learning_rate": 8.896704877160783e-06,
      "loss": 0.0957,
      "step": 773
    },
    {
      "epoch": 1.650319829424307,
      "grad_norm": 0.2885585129261017,
      "learning_rate": 8.873816229714085e-06,
      "loss": 0.1167,
      "step": 774
    },
    {
      "epoch": 1.652452025586354,
      "grad_norm": 0.27898725867271423,
      "learning_rate": 8.850933556471785e-06,
      "loss": 0.1127,
      "step": 775
    },
    {
      "epoch": 1.6545842217484008,
      "grad_norm": 0.26870277523994446,
      "learning_rate": 8.828056978822391e-06,
      "loss": 0.1036,
      "step": 776
    },
    {
      "epoch": 1.6567164179104479,
      "grad_norm": 0.24517139792442322,
      "learning_rate": 8.805186618122068e-06,
      "loss": 0.0914,
      "step": 777
    },
    {
      "epoch": 1.6588486140724945,
      "grad_norm": 0.277749240398407,
      "learning_rate": 8.782322595694014e-06,
      "loss": 0.1034,
      "step": 778
    },
    {
      "epoch": 1.6609808102345416,
      "grad_norm": 0.301876962184906,
      "learning_rate": 8.759465032827794e-06,
      "loss": 0.1097,
      "step": 779
    },
    {
      "epoch": 1.6631130063965884,
      "grad_norm": 0.2629639208316803,
      "learning_rate": 8.73661405077871e-06,
      "loss": 0.103,
      "step": 780
    },
    {
      "epoch": 1.6652452025586353,
      "grad_norm": 0.25491002202033997,
      "learning_rate": 8.713769770767156e-06,
      "loss": 0.0885,
      "step": 781
    },
    {
      "epoch": 1.6673773987206824,
      "grad_norm": 0.28675857186317444,
      "learning_rate": 8.690932313977967e-06,
      "loss": 0.1129,
      "step": 782
    },
    {
      "epoch": 1.6695095948827292,
      "grad_norm": 0.27493375539779663,
      "learning_rate": 8.668101801559786e-06,
      "loss": 0.101,
      "step": 783
    },
    {
      "epoch": 1.671641791044776,
      "grad_norm": 0.3009682893753052,
      "learning_rate": 8.645278354624418e-06,
      "loss": 0.1068,
      "step": 784
    },
    {
      "epoch": 1.6737739872068231,
      "grad_norm": 0.2607211768627167,
      "learning_rate": 8.622462094246185e-06,
      "loss": 0.0932,
      "step": 785
    },
    {
      "epoch": 1.67590618336887,
      "grad_norm": 0.27017372846603394,
      "learning_rate": 8.599653141461283e-06,
      "loss": 0.1053,
      "step": 786
    },
    {
      "epoch": 1.6780383795309168,
      "grad_norm": 0.29809850454330444,
      "learning_rate": 8.576851617267151e-06,
      "loss": 0.113,
      "step": 787
    },
    {
      "epoch": 1.680170575692964,
      "grad_norm": 0.2696080803871155,
      "learning_rate": 8.554057642621814e-06,
      "loss": 0.1056,
      "step": 788
    },
    {
      "epoch": 1.6823027718550105,
      "grad_norm": 0.28189557790756226,
      "learning_rate": 8.531271338443244e-06,
      "loss": 0.1029,
      "step": 789
    },
    {
      "epoch": 1.6844349680170576,
      "grad_norm": 0.25726526975631714,
      "learning_rate": 8.508492825608733e-06,
      "loss": 0.1053,
      "step": 790
    },
    {
      "epoch": 1.6865671641791045,
      "grad_norm": 0.25537461042404175,
      "learning_rate": 8.485722224954237e-06,
      "loss": 0.1021,
      "step": 791
    },
    {
      "epoch": 1.6886993603411513,
      "grad_norm": 0.2638709545135498,
      "learning_rate": 8.462959657273735e-06,
      "loss": 0.104,
      "step": 792
    },
    {
      "epoch": 1.6908315565031984,
      "grad_norm": 0.27003422379493713,
      "learning_rate": 8.440205243318596e-06,
      "loss": 0.1187,
      "step": 793
    },
    {
      "epoch": 1.6929637526652452,
      "grad_norm": 0.2627168893814087,
      "learning_rate": 8.417459103796935e-06,
      "loss": 0.0981,
      "step": 794
    },
    {
      "epoch": 1.695095948827292,
      "grad_norm": 0.2809109389781952,
      "learning_rate": 8.394721359372978e-06,
      "loss": 0.1166,
      "step": 795
    },
    {
      "epoch": 1.6972281449893392,
      "grad_norm": 0.2589755356311798,
      "learning_rate": 8.371992130666403e-06,
      "loss": 0.097,
      "step": 796
    },
    {
      "epoch": 1.6993603411513858,
      "grad_norm": 0.28637266159057617,
      "learning_rate": 8.349271538251724e-06,
      "loss": 0.1118,
      "step": 797
    },
    {
      "epoch": 1.7014925373134329,
      "grad_norm": 0.25500744581222534,
      "learning_rate": 8.326559702657642e-06,
      "loss": 0.0999,
      "step": 798
    },
    {
      "epoch": 1.7036247334754797,
      "grad_norm": 0.2977273464202881,
      "learning_rate": 8.303856744366396e-06,
      "loss": 0.101,
      "step": 799
    },
    {
      "epoch": 1.7057569296375266,
      "grad_norm": 0.2691889703273773,
      "learning_rate": 8.281162783813143e-06,
      "loss": 0.107,
      "step": 800
    },
    {
      "epoch": 1.7078891257995736,
      "grad_norm": 0.25940942764282227,
      "learning_rate": 8.258477941385302e-06,
      "loss": 0.0959,
      "step": 801
    },
    {
      "epoch": 1.7100213219616205,
      "grad_norm": 0.2768906354904175,
      "learning_rate": 8.23580233742192e-06,
      "loss": 0.0901,
      "step": 802
    },
    {
      "epoch": 1.7121535181236673,
      "grad_norm": 0.26150742173194885,
      "learning_rate": 8.21313609221304e-06,
      "loss": 0.0992,
      "step": 803
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.2625720202922821,
      "learning_rate": 8.19047932599906e-06,
      "loss": 0.0987,
      "step": 804
    },
    {
      "epoch": 1.716417910447761,
      "grad_norm": 0.2659949064254761,
      "learning_rate": 8.167832158970087e-06,
      "loss": 0.0995,
      "step": 805
    },
    {
      "epoch": 1.7185501066098081,
      "grad_norm": 0.282241553068161,
      "learning_rate": 8.145194711265312e-06,
      "loss": 0.1038,
      "step": 806
    },
    {
      "epoch": 1.720682302771855,
      "grad_norm": 0.30754536390304565,
      "learning_rate": 8.12256710297237e-06,
      "loss": 0.1048,
      "step": 807
    },
    {
      "epoch": 1.7228144989339018,
      "grad_norm": 0.28580236434936523,
      "learning_rate": 8.099949454126685e-06,
      "loss": 0.1025,
      "step": 808
    },
    {
      "epoch": 1.724946695095949,
      "grad_norm": 0.29419755935668945,
      "learning_rate": 8.077341884710862e-06,
      "loss": 0.1038,
      "step": 809
    },
    {
      "epoch": 1.7270788912579957,
      "grad_norm": 0.266012966632843,
      "learning_rate": 8.054744514654034e-06,
      "loss": 0.1028,
      "step": 810
    },
    {
      "epoch": 1.7292110874200426,
      "grad_norm": 0.26800766587257385,
      "learning_rate": 8.032157463831217e-06,
      "loss": 0.1139,
      "step": 811
    },
    {
      "epoch": 1.7313432835820897,
      "grad_norm": 0.27773192524909973,
      "learning_rate": 8.009580852062706e-06,
      "loss": 0.1128,
      "step": 812
    },
    {
      "epoch": 1.7334754797441365,
      "grad_norm": 0.26873037219047546,
      "learning_rate": 7.987014799113398e-06,
      "loss": 0.0997,
      "step": 813
    },
    {
      "epoch": 1.7356076759061834,
      "grad_norm": 0.2467321753501892,
      "learning_rate": 7.964459424692192e-06,
      "loss": 0.0888,
      "step": 814
    },
    {
      "epoch": 1.7377398720682304,
      "grad_norm": 0.25924941897392273,
      "learning_rate": 7.941914848451332e-06,
      "loss": 0.1028,
      "step": 815
    },
    {
      "epoch": 1.739872068230277,
      "grad_norm": 0.3044951856136322,
      "learning_rate": 7.919381189985779e-06,
      "loss": 0.1096,
      "step": 816
    },
    {
      "epoch": 1.7420042643923241,
      "grad_norm": 0.2743630111217499,
      "learning_rate": 7.896858568832581e-06,
      "loss": 0.0913,
      "step": 817
    },
    {
      "epoch": 1.744136460554371,
      "grad_norm": 0.2596747875213623,
      "learning_rate": 7.874347104470234e-06,
      "loss": 0.089,
      "step": 818
    },
    {
      "epoch": 1.7462686567164178,
      "grad_norm": 0.2736132740974426,
      "learning_rate": 7.851846916318046e-06,
      "loss": 0.1083,
      "step": 819
    },
    {
      "epoch": 1.748400852878465,
      "grad_norm": 0.26958805322647095,
      "learning_rate": 7.829358123735508e-06,
      "loss": 0.0978,
      "step": 820
    },
    {
      "epoch": 1.7505330490405118,
      "grad_norm": 0.266304612159729,
      "learning_rate": 7.80688084602167e-06,
      "loss": 0.0992,
      "step": 821
    },
    {
      "epoch": 1.7526652452025586,
      "grad_norm": 0.27590808272361755,
      "learning_rate": 7.784415202414476e-06,
      "loss": 0.0888,
      "step": 822
    },
    {
      "epoch": 1.7547974413646057,
      "grad_norm": 0.2872757017612457,
      "learning_rate": 7.761961312090173e-06,
      "loss": 0.0971,
      "step": 823
    },
    {
      "epoch": 1.7569296375266523,
      "grad_norm": 0.2898893654346466,
      "learning_rate": 7.739519294162652e-06,
      "loss": 0.0884,
      "step": 824
    },
    {
      "epoch": 1.7590618336886994,
      "grad_norm": 0.2638833224773407,
      "learning_rate": 7.717089267682817e-06,
      "loss": 0.0902,
      "step": 825
    },
    {
      "epoch": 1.7611940298507462,
      "grad_norm": 0.24104033410549164,
      "learning_rate": 7.69467135163797e-06,
      "loss": 0.0922,
      "step": 826
    },
    {
      "epoch": 1.763326226012793,
      "grad_norm": 0.2872030735015869,
      "learning_rate": 7.672265664951166e-06,
      "loss": 0.1109,
      "step": 827
    },
    {
      "epoch": 1.7654584221748402,
      "grad_norm": 0.2887815833091736,
      "learning_rate": 7.649872326480577e-06,
      "loss": 0.1117,
      "step": 828
    },
    {
      "epoch": 1.767590618336887,
      "grad_norm": 0.2680191099643707,
      "learning_rate": 7.627491455018878e-06,
      "loss": 0.1114,
      "step": 829
    },
    {
      "epoch": 1.7697228144989339,
      "grad_norm": 0.2648072838783264,
      "learning_rate": 7.605123169292614e-06,
      "loss": 0.0871,
      "step": 830
    },
    {
      "epoch": 1.771855010660981,
      "grad_norm": 0.2563895583152771,
      "learning_rate": 7.5827675879615525e-06,
      "loss": 0.0957,
      "step": 831
    },
    {
      "epoch": 1.7739872068230276,
      "grad_norm": 0.24483340978622437,
      "learning_rate": 7.560424829618073e-06,
      "loss": 0.0927,
      "step": 832
    },
    {
      "epoch": 1.7761194029850746,
      "grad_norm": 0.28321292996406555,
      "learning_rate": 7.538095012786534e-06,
      "loss": 0.1086,
      "step": 833
    },
    {
      "epoch": 1.7782515991471215,
      "grad_norm": 0.25625845789909363,
      "learning_rate": 7.515778255922632e-06,
      "loss": 0.0821,
      "step": 834
    },
    {
      "epoch": 1.7803837953091683,
      "grad_norm": 0.2671845257282257,
      "learning_rate": 7.493474677412795e-06,
      "loss": 0.0853,
      "step": 835
    },
    {
      "epoch": 1.7825159914712154,
      "grad_norm": 0.294260174036026,
      "learning_rate": 7.4711843955735344e-06,
      "loss": 0.1024,
      "step": 836
    },
    {
      "epoch": 1.7846481876332623,
      "grad_norm": 0.26987335085868835,
      "learning_rate": 7.448907528650823e-06,
      "loss": 0.0793,
      "step": 837
    },
    {
      "epoch": 1.7867803837953091,
      "grad_norm": 0.32182586193084717,
      "learning_rate": 7.426644194819477e-06,
      "loss": 0.1151,
      "step": 838
    },
    {
      "epoch": 1.7889125799573562,
      "grad_norm": 0.28432780504226685,
      "learning_rate": 7.40439451218252e-06,
      "loss": 0.102,
      "step": 839
    },
    {
      "epoch": 1.7910447761194028,
      "grad_norm": 0.3126707673072815,
      "learning_rate": 7.3821585987705545e-06,
      "loss": 0.1019,
      "step": 840
    },
    {
      "epoch": 1.79317697228145,
      "grad_norm": 0.2579263746738434,
      "learning_rate": 7.359936572541142e-06,
      "loss": 0.0933,
      "step": 841
    },
    {
      "epoch": 1.7953091684434968,
      "grad_norm": 0.30452072620391846,
      "learning_rate": 7.337728551378179e-06,
      "loss": 0.1142,
      "step": 842
    },
    {
      "epoch": 1.7974413646055436,
      "grad_norm": 0.2645359933376312,
      "learning_rate": 7.315534653091259e-06,
      "loss": 0.0982,
      "step": 843
    },
    {
      "epoch": 1.7995735607675907,
      "grad_norm": 0.24714215099811554,
      "learning_rate": 7.293354995415064e-06,
      "loss": 0.08,
      "step": 844
    },
    {
      "epoch": 1.8017057569296375,
      "grad_norm": 0.28243589401245117,
      "learning_rate": 7.271189696008729e-06,
      "loss": 0.1189,
      "step": 845
    },
    {
      "epoch": 1.8038379530916844,
      "grad_norm": 0.2663539946079254,
      "learning_rate": 7.24903887245522e-06,
      "loss": 0.0977,
      "step": 846
    },
    {
      "epoch": 1.8059701492537314,
      "grad_norm": 0.2551312744617462,
      "learning_rate": 7.226902642260711e-06,
      "loss": 0.0815,
      "step": 847
    },
    {
      "epoch": 1.8081023454157783,
      "grad_norm": 0.2673572897911072,
      "learning_rate": 7.204781122853967e-06,
      "loss": 0.0975,
      "step": 848
    },
    {
      "epoch": 1.8102345415778252,
      "grad_norm": 0.2849844992160797,
      "learning_rate": 7.182674431585703e-06,
      "loss": 0.1081,
      "step": 849
    },
    {
      "epoch": 1.8123667377398722,
      "grad_norm": 0.27592960000038147,
      "learning_rate": 7.160582685727986e-06,
      "loss": 0.1075,
      "step": 850
    },
    {
      "epoch": 1.8144989339019189,
      "grad_norm": 0.28597497940063477,
      "learning_rate": 7.13850600247359e-06,
      "loss": 0.1024,
      "step": 851
    },
    {
      "epoch": 1.816631130063966,
      "grad_norm": 0.3014627695083618,
      "learning_rate": 7.116444498935397e-06,
      "loss": 0.0992,
      "step": 852
    },
    {
      "epoch": 1.8187633262260128,
      "grad_norm": 0.30377641320228577,
      "learning_rate": 7.094398292145745e-06,
      "loss": 0.1063,
      "step": 853
    },
    {
      "epoch": 1.8208955223880596,
      "grad_norm": 0.314344584941864,
      "learning_rate": 7.072367499055843e-06,
      "loss": 0.112,
      "step": 854
    },
    {
      "epoch": 1.8230277185501067,
      "grad_norm": 0.28258654475212097,
      "learning_rate": 7.050352236535125e-06,
      "loss": 0.118,
      "step": 855
    },
    {
      "epoch": 1.8251599147121536,
      "grad_norm": 0.2725238502025604,
      "learning_rate": 7.028352621370636e-06,
      "loss": 0.0954,
      "step": 856
    },
    {
      "epoch": 1.8272921108742004,
      "grad_norm": 0.26779016852378845,
      "learning_rate": 7.006368770266421e-06,
      "loss": 0.0989,
      "step": 857
    },
    {
      "epoch": 1.8294243070362475,
      "grad_norm": 0.272737056016922,
      "learning_rate": 6.984400799842894e-06,
      "loss": 0.1133,
      "step": 858
    },
    {
      "epoch": 1.831556503198294,
      "grad_norm": 0.30630674958229065,
      "learning_rate": 6.962448826636228e-06,
      "loss": 0.1064,
      "step": 859
    },
    {
      "epoch": 1.8336886993603412,
      "grad_norm": 0.271496057510376,
      "learning_rate": 6.940512967097732e-06,
      "loss": 0.1009,
      "step": 860
    },
    {
      "epoch": 1.835820895522388,
      "grad_norm": 0.2701859474182129,
      "learning_rate": 6.918593337593238e-06,
      "loss": 0.0979,
      "step": 861
    },
    {
      "epoch": 1.8379530916844349,
      "grad_norm": 0.28491953015327454,
      "learning_rate": 6.896690054402473e-06,
      "loss": 0.1126,
      "step": 862
    },
    {
      "epoch": 1.840085287846482,
      "grad_norm": 0.2736054062843323,
      "learning_rate": 6.874803233718459e-06,
      "loss": 0.0911,
      "step": 863
    },
    {
      "epoch": 1.8422174840085288,
      "grad_norm": 0.2885487973690033,
      "learning_rate": 6.852932991646882e-06,
      "loss": 0.1029,
      "step": 864
    },
    {
      "epoch": 1.8443496801705757,
      "grad_norm": 0.2993279695510864,
      "learning_rate": 6.831079444205479e-06,
      "loss": 0.1038,
      "step": 865
    },
    {
      "epoch": 1.8464818763326227,
      "grad_norm": 0.2496788203716278,
      "learning_rate": 6.809242707323433e-06,
      "loss": 0.0801,
      "step": 866
    },
    {
      "epoch": 1.8486140724946694,
      "grad_norm": 0.2610734701156616,
      "learning_rate": 6.787422896840744e-06,
      "loss": 0.0851,
      "step": 867
    },
    {
      "epoch": 1.8507462686567164,
      "grad_norm": 0.28491464257240295,
      "learning_rate": 6.7656201285076195e-06,
      "loss": 0.1021,
      "step": 868
    },
    {
      "epoch": 1.8528784648187633,
      "grad_norm": 0.25890055298805237,
      "learning_rate": 6.743834517983866e-06,
      "loss": 0.0978,
      "step": 869
    },
    {
      "epoch": 1.8550106609808101,
      "grad_norm": 0.24235054850578308,
      "learning_rate": 6.7220661808382705e-06,
      "loss": 0.0875,
      "step": 870
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 0.2682596743106842,
      "learning_rate": 6.7003152325479806e-06,
      "loss": 0.1038,
      "step": 871
    },
    {
      "epoch": 1.859275053304904,
      "grad_norm": 0.27238109707832336,
      "learning_rate": 6.678581788497908e-06,
      "loss": 0.106,
      "step": 872
    },
    {
      "epoch": 1.861407249466951,
      "grad_norm": 0.26403164863586426,
      "learning_rate": 6.656865963980106e-06,
      "loss": 0.0933,
      "step": 873
    },
    {
      "epoch": 1.863539445628998,
      "grad_norm": 0.2892472743988037,
      "learning_rate": 6.635167874193154e-06,
      "loss": 0.1065,
      "step": 874
    },
    {
      "epoch": 1.8656716417910446,
      "grad_norm": 0.2729005217552185,
      "learning_rate": 6.613487634241554e-06,
      "loss": 0.0995,
      "step": 875
    },
    {
      "epoch": 1.8678038379530917,
      "grad_norm": 0.26247525215148926,
      "learning_rate": 6.591825359135123e-06,
      "loss": 0.0971,
      "step": 876
    },
    {
      "epoch": 1.8699360341151388,
      "grad_norm": 0.26162049174308777,
      "learning_rate": 6.570181163788371e-06,
      "loss": 0.1094,
      "step": 877
    },
    {
      "epoch": 1.8720682302771854,
      "grad_norm": 0.2681301534175873,
      "learning_rate": 6.5485551630199006e-06,
      "loss": 0.0943,
      "step": 878
    },
    {
      "epoch": 1.8742004264392325,
      "grad_norm": 0.2630378007888794,
      "learning_rate": 6.526947471551799e-06,
      "loss": 0.0957,
      "step": 879
    },
    {
      "epoch": 1.8763326226012793,
      "grad_norm": 0.28650999069213867,
      "learning_rate": 6.505358204009018e-06,
      "loss": 0.1097,
      "step": 880
    },
    {
      "epoch": 1.8784648187633262,
      "grad_norm": 0.27526068687438965,
      "learning_rate": 6.483787474918779e-06,
      "loss": 0.1087,
      "step": 881
    },
    {
      "epoch": 1.8805970149253732,
      "grad_norm": 0.25837650895118713,
      "learning_rate": 6.462235398709964e-06,
      "loss": 0.0961,
      "step": 882
    },
    {
      "epoch": 1.88272921108742,
      "grad_norm": 0.2780832350254059,
      "learning_rate": 6.440702089712494e-06,
      "loss": 0.1073,
      "step": 883
    },
    {
      "epoch": 1.884861407249467,
      "grad_norm": 0.27449747920036316,
      "learning_rate": 6.419187662156742e-06,
      "loss": 0.0973,
      "step": 884
    },
    {
      "epoch": 1.886993603411514,
      "grad_norm": 0.26612693071365356,
      "learning_rate": 6.397692230172918e-06,
      "loss": 0.1124,
      "step": 885
    },
    {
      "epoch": 1.8891257995735606,
      "grad_norm": 0.24240176379680634,
      "learning_rate": 6.376215907790458e-06,
      "loss": 0.0863,
      "step": 886
    },
    {
      "epoch": 1.8912579957356077,
      "grad_norm": 0.2698936462402344,
      "learning_rate": 6.35475880893743e-06,
      "loss": 0.0881,
      "step": 887
    },
    {
      "epoch": 1.8933901918976546,
      "grad_norm": 0.24287991225719452,
      "learning_rate": 6.333321047439925e-06,
      "loss": 0.0881,
      "step": 888
    },
    {
      "epoch": 1.8955223880597014,
      "grad_norm": 0.27559274435043335,
      "learning_rate": 6.311902737021447e-06,
      "loss": 0.0998,
      "step": 889
    },
    {
      "epoch": 1.8976545842217485,
      "grad_norm": 0.4559750556945801,
      "learning_rate": 6.290503991302324e-06,
      "loss": 0.0841,
      "step": 890
    },
    {
      "epoch": 1.8997867803837953,
      "grad_norm": 0.29231712222099304,
      "learning_rate": 6.269124923799089e-06,
      "loss": 0.1006,
      "step": 891
    },
    {
      "epoch": 1.9019189765458422,
      "grad_norm": 0.26426538825035095,
      "learning_rate": 6.2477656479238895e-06,
      "loss": 0.0884,
      "step": 892
    },
    {
      "epoch": 1.9040511727078893,
      "grad_norm": 0.2763548791408539,
      "learning_rate": 6.22642627698388e-06,
      "loss": 0.1003,
      "step": 893
    },
    {
      "epoch": 1.906183368869936,
      "grad_norm": 0.2678588032722473,
      "learning_rate": 6.205106924180628e-06,
      "loss": 0.0931,
      "step": 894
    },
    {
      "epoch": 1.908315565031983,
      "grad_norm": 0.2619234025478363,
      "learning_rate": 6.183807702609501e-06,
      "loss": 0.0856,
      "step": 895
    },
    {
      "epoch": 1.9104477611940298,
      "grad_norm": 0.24362461268901825,
      "learning_rate": 6.162528725259078e-06,
      "loss": 0.0836,
      "step": 896
    },
    {
      "epoch": 1.9125799573560767,
      "grad_norm": 0.2564876675605774,
      "learning_rate": 6.141270105010546e-06,
      "loss": 0.0777,
      "step": 897
    },
    {
      "epoch": 1.9147121535181237,
      "grad_norm": 0.27880388498306274,
      "learning_rate": 6.120031954637101e-06,
      "loss": 0.0992,
      "step": 898
    },
    {
      "epoch": 1.9168443496801706,
      "grad_norm": 0.2928105294704437,
      "learning_rate": 6.0988143868033475e-06,
      "loss": 0.0969,
      "step": 899
    },
    {
      "epoch": 1.9189765458422174,
      "grad_norm": 0.25942912697792053,
      "learning_rate": 6.077617514064706e-06,
      "loss": 0.0853,
      "step": 900
    },
    {
      "epoch": 1.9211087420042645,
      "grad_norm": 0.2557505965232849,
      "learning_rate": 6.056441448866817e-06,
      "loss": 0.0931,
      "step": 901
    },
    {
      "epoch": 1.9232409381663111,
      "grad_norm": 0.25430017709732056,
      "learning_rate": 6.035286303544927e-06,
      "loss": 0.1018,
      "step": 902
    },
    {
      "epoch": 1.9253731343283582,
      "grad_norm": 0.26005131006240845,
      "learning_rate": 6.014152190323324e-06,
      "loss": 0.0955,
      "step": 903
    },
    {
      "epoch": 1.927505330490405,
      "grad_norm": 0.2394425868988037,
      "learning_rate": 5.993039221314712e-06,
      "loss": 0.092,
      "step": 904
    },
    {
      "epoch": 1.929637526652452,
      "grad_norm": 0.2550469934940338,
      "learning_rate": 5.971947508519631e-06,
      "loss": 0.0891,
      "step": 905
    },
    {
      "epoch": 1.931769722814499,
      "grad_norm": 0.25418761372566223,
      "learning_rate": 5.950877163825866e-06,
      "loss": 0.0815,
      "step": 906
    },
    {
      "epoch": 1.9339019189765458,
      "grad_norm": 0.254525750875473,
      "learning_rate": 5.929828299007845e-06,
      "loss": 0.0862,
      "step": 907
    },
    {
      "epoch": 1.9360341151385927,
      "grad_norm": 0.26039227843284607,
      "learning_rate": 5.9088010257260435e-06,
      "loss": 0.1005,
      "step": 908
    },
    {
      "epoch": 1.9381663113006398,
      "grad_norm": 0.2689777910709381,
      "learning_rate": 5.887795455526404e-06,
      "loss": 0.1029,
      "step": 909
    },
    {
      "epoch": 1.9402985074626866,
      "grad_norm": 0.2745499014854431,
      "learning_rate": 5.8668116998397405e-06,
      "loss": 0.1072,
      "step": 910
    },
    {
      "epoch": 1.9424307036247335,
      "grad_norm": 0.2668236196041107,
      "learning_rate": 5.845849869981137e-06,
      "loss": 0.108,
      "step": 911
    },
    {
      "epoch": 1.9445628997867805,
      "grad_norm": 0.2435191422700882,
      "learning_rate": 5.824910077149372e-06,
      "loss": 0.0883,
      "step": 912
    },
    {
      "epoch": 1.9466950959488272,
      "grad_norm": 0.24722059071063995,
      "learning_rate": 5.803992432426313e-06,
      "loss": 0.0881,
      "step": 913
    },
    {
      "epoch": 1.9488272921108742,
      "grad_norm": 0.2620576024055481,
      "learning_rate": 5.783097046776346e-06,
      "loss": 0.1006,
      "step": 914
    },
    {
      "epoch": 1.950959488272921,
      "grad_norm": 0.2545486390590668,
      "learning_rate": 5.762224031045769e-06,
      "loss": 0.0858,
      "step": 915
    },
    {
      "epoch": 1.953091684434968,
      "grad_norm": 0.2402542233467102,
      "learning_rate": 5.741373495962216e-06,
      "loss": 0.0793,
      "step": 916
    },
    {
      "epoch": 1.955223880597015,
      "grad_norm": 0.29079994559288025,
      "learning_rate": 5.720545552134067e-06,
      "loss": 0.1079,
      "step": 917
    },
    {
      "epoch": 1.9573560767590619,
      "grad_norm": 0.24883019924163818,
      "learning_rate": 5.699740310049847e-06,
      "loss": 0.0828,
      "step": 918
    },
    {
      "epoch": 1.9594882729211087,
      "grad_norm": 0.2584170699119568,
      "learning_rate": 5.678957880077666e-06,
      "loss": 0.099,
      "step": 919
    },
    {
      "epoch": 1.9616204690831558,
      "grad_norm": 0.2927014231681824,
      "learning_rate": 5.6581983724646136e-06,
      "loss": 0.1166,
      "step": 920
    },
    {
      "epoch": 1.9637526652452024,
      "grad_norm": 0.251585990190506,
      "learning_rate": 5.637461897336185e-06,
      "loss": 0.0911,
      "step": 921
    },
    {
      "epoch": 1.9658848614072495,
      "grad_norm": 0.2761441469192505,
      "learning_rate": 5.616748564695685e-06,
      "loss": 0.0967,
      "step": 922
    },
    {
      "epoch": 1.9680170575692963,
      "grad_norm": 0.2705329656600952,
      "learning_rate": 5.5960584844236565e-06,
      "loss": 0.0921,
      "step": 923
    },
    {
      "epoch": 1.9701492537313432,
      "grad_norm": 0.26987528800964355,
      "learning_rate": 5.575391766277297e-06,
      "loss": 0.0977,
      "step": 924
    },
    {
      "epoch": 1.9722814498933903,
      "grad_norm": 0.40624138712882996,
      "learning_rate": 5.554748519889858e-06,
      "loss": 0.1014,
      "step": 925
    },
    {
      "epoch": 1.9744136460554371,
      "grad_norm": 0.2521529197692871,
      "learning_rate": 5.534128854770089e-06,
      "loss": 0.0776,
      "step": 926
    },
    {
      "epoch": 1.976545842217484,
      "grad_norm": 0.24275125563144684,
      "learning_rate": 5.513532880301645e-06,
      "loss": 0.091,
      "step": 927
    },
    {
      "epoch": 1.978678038379531,
      "grad_norm": 0.2787420153617859,
      "learning_rate": 5.492960705742501e-06,
      "loss": 0.1069,
      "step": 928
    },
    {
      "epoch": 1.9808102345415777,
      "grad_norm": 0.24945791065692902,
      "learning_rate": 5.472412440224384e-06,
      "loss": 0.0934,
      "step": 929
    },
    {
      "epoch": 1.9829424307036247,
      "grad_norm": 0.262301504611969,
      "learning_rate": 5.451888192752184e-06,
      "loss": 0.1024,
      "step": 930
    },
    {
      "epoch": 1.9850746268656716,
      "grad_norm": 0.2765779197216034,
      "learning_rate": 5.431388072203373e-06,
      "loss": 0.1099,
      "step": 931
    },
    {
      "epoch": 1.9872068230277184,
      "grad_norm": 0.2653478682041168,
      "learning_rate": 5.410912187327446e-06,
      "loss": 0.0994,
      "step": 932
    },
    {
      "epoch": 1.9893390191897655,
      "grad_norm": 0.25118252635002136,
      "learning_rate": 5.3904606467453255e-06,
      "loss": 0.0837,
      "step": 933
    },
    {
      "epoch": 1.9914712153518124,
      "grad_norm": 0.25172990560531616,
      "learning_rate": 5.370033558948793e-06,
      "loss": 0.0784,
      "step": 934
    },
    {
      "epoch": 1.9936034115138592,
      "grad_norm": 0.27245134115219116,
      "learning_rate": 5.3496310322999135e-06,
      "loss": 0.0936,
      "step": 935
    },
    {
      "epoch": 1.9957356076759063,
      "grad_norm": 0.2606491148471832,
      "learning_rate": 5.329253175030462e-06,
      "loss": 0.0937,
      "step": 936
    },
    {
      "epoch": 1.997867803837953,
      "grad_norm": 0.27671176195144653,
      "learning_rate": 5.308900095241335e-06,
      "loss": 0.098,
      "step": 937
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2577654719352722,
      "learning_rate": 5.288571900902001e-06,
      "loss": 0.0936,
      "step": 938
    },
    {
      "epoch": 2.002132196162047,
      "grad_norm": 0.2220434844493866,
      "learning_rate": 5.268268699849912e-06,
      "loss": 0.0514,
      "step": 939
    },
    {
      "epoch": 2.0042643923240937,
      "grad_norm": 0.25386038422584534,
      "learning_rate": 5.247990599789935e-06,
      "loss": 0.0562,
      "step": 940
    },
    {
      "epoch": 2.0063965884861408,
      "grad_norm": 0.2388574182987213,
      "learning_rate": 5.227737708293781e-06,
      "loss": 0.0602,
      "step": 941
    },
    {
      "epoch": 2.008528784648188,
      "grad_norm": 0.22387711703777313,
      "learning_rate": 5.207510132799436e-06,
      "loss": 0.0525,
      "step": 942
    },
    {
      "epoch": 2.0106609808102345,
      "grad_norm": 0.23469755053520203,
      "learning_rate": 5.187307980610579e-06,
      "loss": 0.0594,
      "step": 943
    },
    {
      "epoch": 2.0127931769722816,
      "grad_norm": 0.20779183506965637,
      "learning_rate": 5.167131358896036e-06,
      "loss": 0.0558,
      "step": 944
    },
    {
      "epoch": 2.014925373134328,
      "grad_norm": 0.34288448095321655,
      "learning_rate": 5.146980374689192e-06,
      "loss": 0.0617,
      "step": 945
    },
    {
      "epoch": 2.0170575692963753,
      "grad_norm": 0.25099045038223267,
      "learning_rate": 5.12685513488743e-06,
      "loss": 0.0575,
      "step": 946
    },
    {
      "epoch": 2.0191897654584223,
      "grad_norm": 0.2553821802139282,
      "learning_rate": 5.106755746251565e-06,
      "loss": 0.055,
      "step": 947
    },
    {
      "epoch": 2.021321961620469,
      "grad_norm": 0.2901664674282074,
      "learning_rate": 5.086682315405279e-06,
      "loss": 0.064,
      "step": 948
    },
    {
      "epoch": 2.023454157782516,
      "grad_norm": 3.4335732460021973,
      "learning_rate": 5.066634948834541e-06,
      "loss": 0.0944,
      "step": 949
    },
    {
      "epoch": 2.025586353944563,
      "grad_norm": 0.27641573548316956,
      "learning_rate": 5.046613752887064e-06,
      "loss": 0.0513,
      "step": 950
    },
    {
      "epoch": 2.0277185501066097,
      "grad_norm": 0.29117321968078613,
      "learning_rate": 5.02661883377173e-06,
      "loss": 0.0657,
      "step": 951
    },
    {
      "epoch": 2.029850746268657,
      "grad_norm": 0.2617288827896118,
      "learning_rate": 5.006650297558025e-06,
      "loss": 0.0629,
      "step": 952
    },
    {
      "epoch": 2.0319829424307034,
      "grad_norm": 0.26571235060691833,
      "learning_rate": 4.986708250175476e-06,
      "loss": 0.0644,
      "step": 953
    },
    {
      "epoch": 2.0341151385927505,
      "grad_norm": 0.21941013634204865,
      "learning_rate": 4.9667927974131e-06,
      "loss": 0.0563,
      "step": 954
    },
    {
      "epoch": 2.0362473347547976,
      "grad_norm": 0.208079531788826,
      "learning_rate": 4.946904044918819e-06,
      "loss": 0.0476,
      "step": 955
    },
    {
      "epoch": 2.038379530916844,
      "grad_norm": 0.2558842897415161,
      "learning_rate": 4.9270420981989295e-06,
      "loss": 0.0658,
      "step": 956
    },
    {
      "epoch": 2.0405117270788913,
      "grad_norm": 0.2419043928384781,
      "learning_rate": 4.907207062617521e-06,
      "loss": 0.062,
      "step": 957
    },
    {
      "epoch": 2.0426439232409384,
      "grad_norm": 0.20672503113746643,
      "learning_rate": 4.887399043395927e-06,
      "loss": 0.0527,
      "step": 958
    },
    {
      "epoch": 2.044776119402985,
      "grad_norm": 0.21846912801265717,
      "learning_rate": 4.8676181456121616e-06,
      "loss": 0.0515,
      "step": 959
    },
    {
      "epoch": 2.046908315565032,
      "grad_norm": 0.22013252973556519,
      "learning_rate": 4.847864474200371e-06,
      "loss": 0.0496,
      "step": 960
    },
    {
      "epoch": 2.0490405117270787,
      "grad_norm": 0.23697197437286377,
      "learning_rate": 4.828138133950256e-06,
      "loss": 0.0539,
      "step": 961
    },
    {
      "epoch": 2.0511727078891258,
      "grad_norm": 0.2568018436431885,
      "learning_rate": 4.808439229506546e-06,
      "loss": 0.0564,
      "step": 962
    },
    {
      "epoch": 2.053304904051173,
      "grad_norm": 0.21920357644557953,
      "learning_rate": 4.788767865368419e-06,
      "loss": 0.0543,
      "step": 963
    },
    {
      "epoch": 2.0554371002132195,
      "grad_norm": 0.23630008101463318,
      "learning_rate": 4.769124145888961e-06,
      "loss": 0.0549,
      "step": 964
    },
    {
      "epoch": 2.0575692963752665,
      "grad_norm": 0.238305002450943,
      "learning_rate": 4.749508175274605e-06,
      "loss": 0.0595,
      "step": 965
    },
    {
      "epoch": 2.0597014925373136,
      "grad_norm": 0.21672426164150238,
      "learning_rate": 4.729920057584584e-06,
      "loss": 0.0468,
      "step": 966
    },
    {
      "epoch": 2.0618336886993602,
      "grad_norm": 0.23357173800468445,
      "learning_rate": 4.710359896730379e-06,
      "loss": 0.0542,
      "step": 967
    },
    {
      "epoch": 2.0639658848614073,
      "grad_norm": 0.20534676313400269,
      "learning_rate": 4.690827796475152e-06,
      "loss": 0.0461,
      "step": 968
    },
    {
      "epoch": 2.066098081023454,
      "grad_norm": 0.23503899574279785,
      "learning_rate": 4.671323860433222e-06,
      "loss": 0.0605,
      "step": 969
    },
    {
      "epoch": 2.068230277185501,
      "grad_norm": 0.24988935887813568,
      "learning_rate": 4.651848192069498e-06,
      "loss": 0.0626,
      "step": 970
    },
    {
      "epoch": 2.070362473347548,
      "grad_norm": 0.23702888190746307,
      "learning_rate": 4.632400894698932e-06,
      "loss": 0.0501,
      "step": 971
    },
    {
      "epoch": 2.0724946695095947,
      "grad_norm": 0.24375790357589722,
      "learning_rate": 4.612982071485974e-06,
      "loss": 0.0539,
      "step": 972
    },
    {
      "epoch": 2.074626865671642,
      "grad_norm": 0.2261868566274643,
      "learning_rate": 4.593591825444028e-06,
      "loss": 0.0553,
      "step": 973
    },
    {
      "epoch": 2.076759061833689,
      "grad_norm": 0.2634316086769104,
      "learning_rate": 4.5742302594348895e-06,
      "loss": 0.0658,
      "step": 974
    },
    {
      "epoch": 2.0788912579957355,
      "grad_norm": 0.23410454392433167,
      "learning_rate": 4.554897476168223e-06,
      "loss": 0.0622,
      "step": 975
    },
    {
      "epoch": 2.0810234541577826,
      "grad_norm": 0.2392917424440384,
      "learning_rate": 4.535593578201002e-06,
      "loss": 0.0575,
      "step": 976
    },
    {
      "epoch": 2.0831556503198296,
      "grad_norm": 0.2351149320602417,
      "learning_rate": 4.516318667936968e-06,
      "loss": 0.0603,
      "step": 977
    },
    {
      "epoch": 2.0852878464818763,
      "grad_norm": 0.2172447144985199,
      "learning_rate": 4.497072847626087e-06,
      "loss": 0.0545,
      "step": 978
    },
    {
      "epoch": 2.0874200426439233,
      "grad_norm": 0.2221793383359909,
      "learning_rate": 4.477856219364015e-06,
      "loss": 0.0541,
      "step": 979
    },
    {
      "epoch": 2.08955223880597,
      "grad_norm": 0.20132124423980713,
      "learning_rate": 4.458668885091535e-06,
      "loss": 0.0478,
      "step": 980
    },
    {
      "epoch": 2.091684434968017,
      "grad_norm": 0.2138369232416153,
      "learning_rate": 4.43951094659404e-06,
      "loss": 0.0509,
      "step": 981
    },
    {
      "epoch": 2.093816631130064,
      "grad_norm": 0.22759543359279633,
      "learning_rate": 4.42038250550099e-06,
      "loss": 0.0509,
      "step": 982
    },
    {
      "epoch": 2.0959488272921107,
      "grad_norm": 0.229288712143898,
      "learning_rate": 4.401283663285355e-06,
      "loss": 0.0587,
      "step": 983
    },
    {
      "epoch": 2.098081023454158,
      "grad_norm": 0.23256701231002808,
      "learning_rate": 4.382214521263096e-06,
      "loss": 0.0611,
      "step": 984
    },
    {
      "epoch": 2.100213219616205,
      "grad_norm": 0.3104761242866516,
      "learning_rate": 4.3631751805926115e-06,
      "loss": 0.0598,
      "step": 985
    },
    {
      "epoch": 2.1023454157782515,
      "grad_norm": 0.22512002289295197,
      "learning_rate": 4.3441657422742145e-06,
      "loss": 0.0582,
      "step": 986
    },
    {
      "epoch": 2.1044776119402986,
      "grad_norm": 0.23154813051223755,
      "learning_rate": 4.325186307149593e-06,
      "loss": 0.0565,
      "step": 987
    },
    {
      "epoch": 2.106609808102345,
      "grad_norm": 0.21448864042758942,
      "learning_rate": 4.3062369759012705e-06,
      "loss": 0.0544,
      "step": 988
    },
    {
      "epoch": 2.1087420042643923,
      "grad_norm": 0.22317570447921753,
      "learning_rate": 4.287317849052075e-06,
      "loss": 0.0509,
      "step": 989
    },
    {
      "epoch": 2.1108742004264394,
      "grad_norm": 0.24263601005077362,
      "learning_rate": 4.268429026964611e-06,
      "loss": 0.0581,
      "step": 990
    },
    {
      "epoch": 2.113006396588486,
      "grad_norm": 0.23799146711826324,
      "learning_rate": 4.2495706098407085e-06,
      "loss": 0.0545,
      "step": 991
    },
    {
      "epoch": 2.115138592750533,
      "grad_norm": 0.23505844175815582,
      "learning_rate": 4.230742697720917e-06,
      "loss": 0.0597,
      "step": 992
    },
    {
      "epoch": 2.11727078891258,
      "grad_norm": 0.24611367285251617,
      "learning_rate": 4.2119453904839565e-06,
      "loss": 0.0631,
      "step": 993
    },
    {
      "epoch": 2.1194029850746268,
      "grad_norm": 0.22561804950237274,
      "learning_rate": 4.193178787846198e-06,
      "loss": 0.0589,
      "step": 994
    },
    {
      "epoch": 2.121535181236674,
      "grad_norm": 0.22046783566474915,
      "learning_rate": 4.174442989361126e-06,
      "loss": 0.0589,
      "step": 995
    },
    {
      "epoch": 2.1236673773987205,
      "grad_norm": 0.22016407549381256,
      "learning_rate": 4.155738094418818e-06,
      "loss": 0.0519,
      "step": 996
    },
    {
      "epoch": 2.1257995735607675,
      "grad_norm": 0.2577105164527893,
      "learning_rate": 4.137064202245408e-06,
      "loss": 0.0691,
      "step": 997
    },
    {
      "epoch": 2.1279317697228146,
      "grad_norm": 0.21616974472999573,
      "learning_rate": 4.118421411902568e-06,
      "loss": 0.0552,
      "step": 998
    },
    {
      "epoch": 2.1300639658848612,
      "grad_norm": 0.2460293173789978,
      "learning_rate": 4.0998098222869845e-06,
      "loss": 0.0523,
      "step": 999
    },
    {
      "epoch": 2.1321961620469083,
      "grad_norm": 0.24527323246002197,
      "learning_rate": 4.081229532129826e-06,
      "loss": 0.0589,
      "step": 1000
    },
    {
      "epoch": 2.1343283582089554,
      "grad_norm": 0.26068782806396484,
      "learning_rate": 4.062680639996225e-06,
      "loss": 0.0673,
      "step": 1001
    },
    {
      "epoch": 2.136460554371002,
      "grad_norm": 0.21945926547050476,
      "learning_rate": 4.044163244284753e-06,
      "loss": 0.051,
      "step": 1002
    },
    {
      "epoch": 2.138592750533049,
      "grad_norm": 0.22312557697296143,
      "learning_rate": 4.025677443226894e-06,
      "loss": 0.0551,
      "step": 1003
    },
    {
      "epoch": 2.140724946695096,
      "grad_norm": 0.24721676111221313,
      "learning_rate": 4.007223334886531e-06,
      "loss": 0.058,
      "step": 1004
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.21975429356098175,
      "learning_rate": 3.988801017159425e-06,
      "loss": 0.0543,
      "step": 1005
    },
    {
      "epoch": 2.14498933901919,
      "grad_norm": 0.1993921995162964,
      "learning_rate": 3.970410587772692e-06,
      "loss": 0.0452,
      "step": 1006
    },
    {
      "epoch": 2.1471215351812365,
      "grad_norm": 0.23132158815860748,
      "learning_rate": 3.952052144284285e-06,
      "loss": 0.0636,
      "step": 1007
    },
    {
      "epoch": 2.1492537313432836,
      "grad_norm": 0.24150718748569489,
      "learning_rate": 3.933725784082483e-06,
      "loss": 0.0603,
      "step": 1008
    },
    {
      "epoch": 2.1513859275053306,
      "grad_norm": 0.24764305353164673,
      "learning_rate": 3.915431604385355e-06,
      "loss": 0.063,
      "step": 1009
    },
    {
      "epoch": 2.1535181236673773,
      "grad_norm": 0.24039016664028168,
      "learning_rate": 3.897169702240271e-06,
      "loss": 0.0623,
      "step": 1010
    },
    {
      "epoch": 2.1556503198294243,
      "grad_norm": 0.2507581412792206,
      "learning_rate": 3.878940174523371e-06,
      "loss": 0.0651,
      "step": 1011
    },
    {
      "epoch": 2.1577825159914714,
      "grad_norm": 0.23795253038406372,
      "learning_rate": 3.860743117939055e-06,
      "loss": 0.0594,
      "step": 1012
    },
    {
      "epoch": 2.159914712153518,
      "grad_norm": 0.2393694370985031,
      "learning_rate": 3.842578629019468e-06,
      "loss": 0.0563,
      "step": 1013
    },
    {
      "epoch": 2.162046908315565,
      "grad_norm": 0.223679780960083,
      "learning_rate": 3.824446804123992e-06,
      "loss": 0.0563,
      "step": 1014
    },
    {
      "epoch": 2.1641791044776117,
      "grad_norm": 0.22407235205173492,
      "learning_rate": 3.8063477394387236e-06,
      "loss": 0.0521,
      "step": 1015
    },
    {
      "epoch": 2.166311300639659,
      "grad_norm": 0.20272193849086761,
      "learning_rate": 3.788281530975982e-06,
      "loss": 0.05,
      "step": 1016
    },
    {
      "epoch": 2.168443496801706,
      "grad_norm": 0.22376754879951477,
      "learning_rate": 3.7702482745737876e-06,
      "loss": 0.0547,
      "step": 1017
    },
    {
      "epoch": 2.1705756929637525,
      "grad_norm": 0.2280762642621994,
      "learning_rate": 3.752248065895354e-06,
      "loss": 0.0506,
      "step": 1018
    },
    {
      "epoch": 2.1727078891257996,
      "grad_norm": 0.27107295393943787,
      "learning_rate": 3.7342810004285835e-06,
      "loss": 0.0585,
      "step": 1019
    },
    {
      "epoch": 2.1748400852878467,
      "grad_norm": 0.23341915011405945,
      "learning_rate": 3.7163471734855627e-06,
      "loss": 0.0539,
      "step": 1020
    },
    {
      "epoch": 2.1769722814498933,
      "grad_norm": 0.2199372798204422,
      "learning_rate": 3.6984466802020436e-06,
      "loss": 0.05,
      "step": 1021
    },
    {
      "epoch": 2.1791044776119404,
      "grad_norm": 0.2809966504573822,
      "learning_rate": 3.680579615536961e-06,
      "loss": 0.0682,
      "step": 1022
    },
    {
      "epoch": 2.181236673773987,
      "grad_norm": 0.20876768231391907,
      "learning_rate": 3.66274607427191e-06,
      "loss": 0.0489,
      "step": 1023
    },
    {
      "epoch": 2.183368869936034,
      "grad_norm": 0.2279953956604004,
      "learning_rate": 3.6449461510106542e-06,
      "loss": 0.0548,
      "step": 1024
    },
    {
      "epoch": 2.185501066098081,
      "grad_norm": 0.2080584317445755,
      "learning_rate": 3.627179940178616e-06,
      "loss": 0.0514,
      "step": 1025
    },
    {
      "epoch": 2.1876332622601278,
      "grad_norm": 0.21797923743724823,
      "learning_rate": 3.6094475360223792e-06,
      "loss": 0.0487,
      "step": 1026
    },
    {
      "epoch": 2.189765458422175,
      "grad_norm": 0.19843338429927826,
      "learning_rate": 3.5917490326091974e-06,
      "loss": 0.0461,
      "step": 1027
    },
    {
      "epoch": 2.191897654584222,
      "grad_norm": 0.3520326018333435,
      "learning_rate": 3.574084523826471e-06,
      "loss": 0.0506,
      "step": 1028
    },
    {
      "epoch": 2.1940298507462686,
      "grad_norm": 0.24233146011829376,
      "learning_rate": 3.556454103381278e-06,
      "loss": 0.0654,
      "step": 1029
    },
    {
      "epoch": 2.1961620469083156,
      "grad_norm": 0.21291451156139374,
      "learning_rate": 3.538857864799862e-06,
      "loss": 0.0553,
      "step": 1030
    },
    {
      "epoch": 2.1982942430703627,
      "grad_norm": 0.21280260384082794,
      "learning_rate": 3.521295901427132e-06,
      "loss": 0.0505,
      "step": 1031
    },
    {
      "epoch": 2.2004264392324093,
      "grad_norm": 0.2080870270729065,
      "learning_rate": 3.5037683064261806e-06,
      "loss": 0.0528,
      "step": 1032
    },
    {
      "epoch": 2.2025586353944564,
      "grad_norm": 0.2234102338552475,
      "learning_rate": 3.48627517277778e-06,
      "loss": 0.0596,
      "step": 1033
    },
    {
      "epoch": 2.204690831556503,
      "grad_norm": 0.22944635152816772,
      "learning_rate": 3.4688165932798835e-06,
      "loss": 0.0583,
      "step": 1034
    },
    {
      "epoch": 2.20682302771855,
      "grad_norm": 0.23323926329612732,
      "learning_rate": 3.4513926605471504e-06,
      "loss": 0.0641,
      "step": 1035
    },
    {
      "epoch": 2.208955223880597,
      "grad_norm": 0.2463182657957077,
      "learning_rate": 3.4340034670104414e-06,
      "loss": 0.0601,
      "step": 1036
    },
    {
      "epoch": 2.211087420042644,
      "grad_norm": 0.24988777935504913,
      "learning_rate": 3.4166491049163332e-06,
      "loss": 0.0533,
      "step": 1037
    },
    {
      "epoch": 2.213219616204691,
      "grad_norm": 0.2162133753299713,
      "learning_rate": 3.3993296663266253e-06,
      "loss": 0.0489,
      "step": 1038
    },
    {
      "epoch": 2.2153518123667375,
      "grad_norm": 0.2347920536994934,
      "learning_rate": 3.3820452431178607e-06,
      "loss": 0.0494,
      "step": 1039
    },
    {
      "epoch": 2.2174840085287846,
      "grad_norm": 0.239857017993927,
      "learning_rate": 3.3647959269808207e-06,
      "loss": 0.0574,
      "step": 1040
    },
    {
      "epoch": 2.2196162046908317,
      "grad_norm": 0.22466036677360535,
      "learning_rate": 3.3475818094200584e-06,
      "loss": 0.0464,
      "step": 1041
    },
    {
      "epoch": 2.2217484008528783,
      "grad_norm": 0.2233474850654602,
      "learning_rate": 3.3304029817534032e-06,
      "loss": 0.0471,
      "step": 1042
    },
    {
      "epoch": 2.2238805970149254,
      "grad_norm": 0.2319781631231308,
      "learning_rate": 3.3132595351114784e-06,
      "loss": 0.0599,
      "step": 1043
    },
    {
      "epoch": 2.2260127931769724,
      "grad_norm": 0.23936490714550018,
      "learning_rate": 3.296151560437214e-06,
      "loss": 0.0619,
      "step": 1044
    },
    {
      "epoch": 2.228144989339019,
      "grad_norm": 0.21182645857334137,
      "learning_rate": 3.2790791484853747e-06,
      "loss": 0.0512,
      "step": 1045
    },
    {
      "epoch": 2.230277185501066,
      "grad_norm": 0.24313655495643616,
      "learning_rate": 3.26204238982206e-06,
      "loss": 0.0606,
      "step": 1046
    },
    {
      "epoch": 2.232409381663113,
      "grad_norm": 0.22780823707580566,
      "learning_rate": 3.2450413748242437e-06,
      "loss": 0.0557,
      "step": 1047
    },
    {
      "epoch": 2.23454157782516,
      "grad_norm": 0.2207408845424652,
      "learning_rate": 3.2280761936792836e-06,
      "loss": 0.0488,
      "step": 1048
    },
    {
      "epoch": 2.236673773987207,
      "grad_norm": 0.2337723672389984,
      "learning_rate": 3.211146936384445e-06,
      "loss": 0.0536,
      "step": 1049
    },
    {
      "epoch": 2.2388059701492535,
      "grad_norm": 0.21380271017551422,
      "learning_rate": 3.194253692746425e-06,
      "loss": 0.0504,
      "step": 1050
    },
    {
      "epoch": 2.2409381663113006,
      "grad_norm": 0.2149089127779007,
      "learning_rate": 3.177396552380876e-06,
      "loss": 0.0483,
      "step": 1051
    },
    {
      "epoch": 2.2430703624733477,
      "grad_norm": 0.24041645228862762,
      "learning_rate": 3.1605756047119196e-06,
      "loss": 0.0596,
      "step": 1052
    },
    {
      "epoch": 2.2452025586353943,
      "grad_norm": 0.249374121427536,
      "learning_rate": 3.1437909389716915e-06,
      "loss": 0.0555,
      "step": 1053
    },
    {
      "epoch": 2.2473347547974414,
      "grad_norm": 0.24089211225509644,
      "learning_rate": 3.1270426441998557e-06,
      "loss": 0.0581,
      "step": 1054
    },
    {
      "epoch": 2.2494669509594885,
      "grad_norm": 0.24043092131614685,
      "learning_rate": 3.110330809243134e-06,
      "loss": 0.0609,
      "step": 1055
    },
    {
      "epoch": 2.251599147121535,
      "grad_norm": 0.22055768966674805,
      "learning_rate": 3.093655522754836e-06,
      "loss": 0.0493,
      "step": 1056
    },
    {
      "epoch": 2.253731343283582,
      "grad_norm": 0.2343435436487198,
      "learning_rate": 3.0770168731943894e-06,
      "loss": 0.0587,
      "step": 1057
    },
    {
      "epoch": 2.2558635394456292,
      "grad_norm": 0.23495404422283173,
      "learning_rate": 3.060414948826862e-06,
      "loss": 0.062,
      "step": 1058
    },
    {
      "epoch": 2.257995735607676,
      "grad_norm": 0.21247462928295135,
      "learning_rate": 3.0438498377225113e-06,
      "loss": 0.0522,
      "step": 1059
    },
    {
      "epoch": 2.260127931769723,
      "grad_norm": 0.2531813979148865,
      "learning_rate": 3.0273216277563e-06,
      "loss": 0.0614,
      "step": 1060
    },
    {
      "epoch": 2.2622601279317696,
      "grad_norm": 0.23326893150806427,
      "learning_rate": 3.0108304066074412e-06,
      "loss": 0.0593,
      "step": 1061
    },
    {
      "epoch": 2.2643923240938166,
      "grad_norm": 0.23381245136260986,
      "learning_rate": 2.9943762617589265e-06,
      "loss": 0.0606,
      "step": 1062
    },
    {
      "epoch": 2.2665245202558637,
      "grad_norm": 0.22729799151420593,
      "learning_rate": 2.977959280497068e-06,
      "loss": 0.0549,
      "step": 1063
    },
    {
      "epoch": 2.2686567164179103,
      "grad_norm": 0.23308208584785461,
      "learning_rate": 2.9615795499110225e-06,
      "loss": 0.0537,
      "step": 1064
    },
    {
      "epoch": 2.2707889125799574,
      "grad_norm": 0.22012831270694733,
      "learning_rate": 2.9452371568923453e-06,
      "loss": 0.0518,
      "step": 1065
    },
    {
      "epoch": 2.272921108742004,
      "grad_norm": 0.2221381515264511,
      "learning_rate": 2.9289321881345257e-06,
      "loss": 0.053,
      "step": 1066
    },
    {
      "epoch": 2.275053304904051,
      "grad_norm": 0.24291571974754333,
      "learning_rate": 2.9126647301325173e-06,
      "loss": 0.0594,
      "step": 1067
    },
    {
      "epoch": 2.277185501066098,
      "grad_norm": 0.2220359444618225,
      "learning_rate": 2.8964348691822896e-06,
      "loss": 0.0564,
      "step": 1068
    },
    {
      "epoch": 2.279317697228145,
      "grad_norm": 0.23937420547008514,
      "learning_rate": 2.880242691380364e-06,
      "loss": 0.0567,
      "step": 1069
    },
    {
      "epoch": 2.281449893390192,
      "grad_norm": 0.22826716303825378,
      "learning_rate": 2.864088282623366e-06,
      "loss": 0.0485,
      "step": 1070
    },
    {
      "epoch": 2.283582089552239,
      "grad_norm": 0.27520662546157837,
      "learning_rate": 2.8479717286075505e-06,
      "loss": 0.0576,
      "step": 1071
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.2345166951417923,
      "learning_rate": 2.83189311482837e-06,
      "loss": 0.0538,
      "step": 1072
    },
    {
      "epoch": 2.2878464818763327,
      "grad_norm": 0.2019665390253067,
      "learning_rate": 2.8158525265800096e-06,
      "loss": 0.0442,
      "step": 1073
    },
    {
      "epoch": 2.2899786780383797,
      "grad_norm": 0.25253942608833313,
      "learning_rate": 2.799850048954932e-06,
      "loss": 0.0514,
      "step": 1074
    },
    {
      "epoch": 2.2921108742004264,
      "grad_norm": 0.23632194101810455,
      "learning_rate": 2.7838857668434326e-06,
      "loss": 0.0556,
      "step": 1075
    },
    {
      "epoch": 2.2942430703624734,
      "grad_norm": 0.23367993533611298,
      "learning_rate": 2.7679597649331903e-06,
      "loss": 0.0549,
      "step": 1076
    },
    {
      "epoch": 2.29637526652452,
      "grad_norm": 0.2228904664516449,
      "learning_rate": 2.7520721277088023e-06,
      "loss": 0.0554,
      "step": 1077
    },
    {
      "epoch": 2.298507462686567,
      "grad_norm": 0.21791662275791168,
      "learning_rate": 2.7362229394513585e-06,
      "loss": 0.0494,
      "step": 1078
    },
    {
      "epoch": 2.300639658848614,
      "grad_norm": 0.2480710744857788,
      "learning_rate": 2.7204122842379797e-06,
      "loss": 0.0659,
      "step": 1079
    },
    {
      "epoch": 2.302771855010661,
      "grad_norm": 0.2482113242149353,
      "learning_rate": 2.7046402459413802e-06,
      "loss": 0.0591,
      "step": 1080
    },
    {
      "epoch": 2.304904051172708,
      "grad_norm": 0.23330159485340118,
      "learning_rate": 2.6889069082294115e-06,
      "loss": 0.0585,
      "step": 1081
    },
    {
      "epoch": 2.307036247334755,
      "grad_norm": 0.21235162019729614,
      "learning_rate": 2.673212354564635e-06,
      "loss": 0.0464,
      "step": 1082
    },
    {
      "epoch": 2.3091684434968016,
      "grad_norm": 0.20900297164916992,
      "learning_rate": 2.6575566682038555e-06,
      "loss": 0.0503,
      "step": 1083
    },
    {
      "epoch": 2.3113006396588487,
      "grad_norm": 0.2110026329755783,
      "learning_rate": 2.6419399321977056e-06,
      "loss": 0.0547,
      "step": 1084
    },
    {
      "epoch": 2.3134328358208958,
      "grad_norm": 0.25010934472084045,
      "learning_rate": 2.626362229390189e-06,
      "loss": 0.0626,
      "step": 1085
    },
    {
      "epoch": 2.3155650319829424,
      "grad_norm": 0.20330990850925446,
      "learning_rate": 2.6108236424182463e-06,
      "loss": 0.0495,
      "step": 1086
    },
    {
      "epoch": 2.3176972281449895,
      "grad_norm": 0.2378339320421219,
      "learning_rate": 2.5953242537113143e-06,
      "loss": 0.0626,
      "step": 1087
    },
    {
      "epoch": 2.319829424307036,
      "grad_norm": 0.23582668602466583,
      "learning_rate": 2.5798641454908945e-06,
      "loss": 0.0584,
      "step": 1088
    },
    {
      "epoch": 2.321961620469083,
      "grad_norm": 0.21425281465053558,
      "learning_rate": 2.564443399770101e-06,
      "loss": 0.0537,
      "step": 1089
    },
    {
      "epoch": 2.3240938166311302,
      "grad_norm": 0.20950520038604736,
      "learning_rate": 2.54906209835325e-06,
      "loss": 0.0465,
      "step": 1090
    },
    {
      "epoch": 2.326226012793177,
      "grad_norm": 0.23375119268894196,
      "learning_rate": 2.5337203228354034e-06,
      "loss": 0.0543,
      "step": 1091
    },
    {
      "epoch": 2.328358208955224,
      "grad_norm": 0.23281742632389069,
      "learning_rate": 2.5184181546019515e-06,
      "loss": 0.0614,
      "step": 1092
    },
    {
      "epoch": 2.3304904051172706,
      "grad_norm": 0.21920596063137054,
      "learning_rate": 2.5031556748281716e-06,
      "loss": 0.0452,
      "step": 1093
    },
    {
      "epoch": 2.3326226012793176,
      "grad_norm": 0.21557077765464783,
      "learning_rate": 2.4879329644788054e-06,
      "loss": 0.0474,
      "step": 1094
    },
    {
      "epoch": 2.3347547974413647,
      "grad_norm": 0.2574343979358673,
      "learning_rate": 2.472750104307613e-06,
      "loss": 0.061,
      "step": 1095
    },
    {
      "epoch": 2.3368869936034113,
      "grad_norm": 0.21803924441337585,
      "learning_rate": 2.4576071748569695e-06,
      "loss": 0.0533,
      "step": 1096
    },
    {
      "epoch": 2.3390191897654584,
      "grad_norm": 0.23180830478668213,
      "learning_rate": 2.4425042564574186e-06,
      "loss": 0.0546,
      "step": 1097
    },
    {
      "epoch": 2.3411513859275055,
      "grad_norm": 0.26277685165405273,
      "learning_rate": 2.427441429227253e-06,
      "loss": 0.0615,
      "step": 1098
    },
    {
      "epoch": 2.343283582089552,
      "grad_norm": 0.23798400163650513,
      "learning_rate": 2.4124187730720916e-06,
      "loss": 0.0552,
      "step": 1099
    },
    {
      "epoch": 2.345415778251599,
      "grad_norm": 0.1956181675195694,
      "learning_rate": 2.3974363676844505e-06,
      "loss": 0.045,
      "step": 1100
    },
    {
      "epoch": 2.3475479744136463,
      "grad_norm": 0.24672454595565796,
      "learning_rate": 2.3824942925433192e-06,
      "loss": 0.0618,
      "step": 1101
    },
    {
      "epoch": 2.349680170575693,
      "grad_norm": 0.19652342796325684,
      "learning_rate": 2.3675926269137496e-06,
      "loss": 0.0457,
      "step": 1102
    },
    {
      "epoch": 2.35181236673774,
      "grad_norm": 0.23135274648666382,
      "learning_rate": 2.3527314498464214e-06,
      "loss": 0.058,
      "step": 1103
    },
    {
      "epoch": 2.3539445628997866,
      "grad_norm": 0.2064269483089447,
      "learning_rate": 2.3379108401772366e-06,
      "loss": 0.0453,
      "step": 1104
    },
    {
      "epoch": 2.3560767590618337,
      "grad_norm": 0.2458469569683075,
      "learning_rate": 2.323130876526889e-06,
      "loss": 0.0598,
      "step": 1105
    },
    {
      "epoch": 2.3582089552238807,
      "grad_norm": 0.2042500227689743,
      "learning_rate": 2.3083916373004577e-06,
      "loss": 0.0473,
      "step": 1106
    },
    {
      "epoch": 2.3603411513859274,
      "grad_norm": 0.2109072059392929,
      "learning_rate": 2.293693200686976e-06,
      "loss": 0.0535,
      "step": 1107
    },
    {
      "epoch": 2.3624733475479744,
      "grad_norm": 0.2323598563671112,
      "learning_rate": 2.2790356446590376e-06,
      "loss": 0.0551,
      "step": 1108
    },
    {
      "epoch": 2.364605543710021,
      "grad_norm": 0.23650850355625153,
      "learning_rate": 2.264419046972368e-06,
      "loss": 0.0568,
      "step": 1109
    },
    {
      "epoch": 2.366737739872068,
      "grad_norm": 0.22336384654045105,
      "learning_rate": 2.2498434851654125e-06,
      "loss": 0.0538,
      "step": 1110
    },
    {
      "epoch": 2.368869936034115,
      "grad_norm": 0.21191443502902985,
      "learning_rate": 2.2353090365589348e-06,
      "loss": 0.0508,
      "step": 1111
    },
    {
      "epoch": 2.3710021321961623,
      "grad_norm": 0.2382896989583969,
      "learning_rate": 2.2208157782555963e-06,
      "loss": 0.0564,
      "step": 1112
    },
    {
      "epoch": 2.373134328358209,
      "grad_norm": 0.2262413501739502,
      "learning_rate": 2.2063637871395527e-06,
      "loss": 0.0542,
      "step": 1113
    },
    {
      "epoch": 2.375266524520256,
      "grad_norm": 0.20672078430652618,
      "learning_rate": 2.1919531398760407e-06,
      "loss": 0.048,
      "step": 1114
    },
    {
      "epoch": 2.3773987206823026,
      "grad_norm": 0.24028021097183228,
      "learning_rate": 2.1775839129109786e-06,
      "loss": 0.056,
      "step": 1115
    },
    {
      "epoch": 2.3795309168443497,
      "grad_norm": 0.22955353558063507,
      "learning_rate": 2.16325618247056e-06,
      "loss": 0.0588,
      "step": 1116
    },
    {
      "epoch": 2.3816631130063968,
      "grad_norm": 0.2383897453546524,
      "learning_rate": 2.1489700245608436e-06,
      "loss": 0.0508,
      "step": 1117
    },
    {
      "epoch": 2.3837953091684434,
      "grad_norm": 0.24128498136997223,
      "learning_rate": 2.1347255149673507e-06,
      "loss": 0.0545,
      "step": 1118
    },
    {
      "epoch": 2.3859275053304905,
      "grad_norm": 0.2378612607717514,
      "learning_rate": 2.120522729254675e-06,
      "loss": 0.0556,
      "step": 1119
    },
    {
      "epoch": 2.388059701492537,
      "grad_norm": 0.25640541315078735,
      "learning_rate": 2.1063617427660576e-06,
      "loss": 0.0568,
      "step": 1120
    },
    {
      "epoch": 2.390191897654584,
      "grad_norm": 0.22302120923995972,
      "learning_rate": 2.092242630623016e-06,
      "loss": 0.0499,
      "step": 1121
    },
    {
      "epoch": 2.3923240938166312,
      "grad_norm": 0.24224920570850372,
      "learning_rate": 2.0781654677249243e-06,
      "loss": 0.0546,
      "step": 1122
    },
    {
      "epoch": 2.394456289978678,
      "grad_norm": 0.2117663472890854,
      "learning_rate": 2.0641303287486257e-06,
      "loss": 0.0506,
      "step": 1123
    },
    {
      "epoch": 2.396588486140725,
      "grad_norm": 0.20773568749427795,
      "learning_rate": 2.0501372881480353e-06,
      "loss": 0.0478,
      "step": 1124
    },
    {
      "epoch": 2.398720682302772,
      "grad_norm": 0.2195522040128708,
      "learning_rate": 2.0361864201537428e-06,
      "loss": 0.0507,
      "step": 1125
    },
    {
      "epoch": 2.4008528784648187,
      "grad_norm": 0.21374492347240448,
      "learning_rate": 2.0222777987726137e-06,
      "loss": 0.0515,
      "step": 1126
    },
    {
      "epoch": 2.4029850746268657,
      "grad_norm": 0.2184111624956131,
      "learning_rate": 2.0084114977874135e-06,
      "loss": 0.0521,
      "step": 1127
    },
    {
      "epoch": 2.405117270788913,
      "grad_norm": 0.19115708768367767,
      "learning_rate": 1.994587590756397e-06,
      "loss": 0.046,
      "step": 1128
    },
    {
      "epoch": 2.4072494669509594,
      "grad_norm": 0.2266920506954193,
      "learning_rate": 1.9808061510129318e-06,
      "loss": 0.0519,
      "step": 1129
    },
    {
      "epoch": 2.4093816631130065,
      "grad_norm": 0.23960624635219574,
      "learning_rate": 1.9670672516651014e-06,
      "loss": 0.0531,
      "step": 1130
    },
    {
      "epoch": 2.411513859275053,
      "grad_norm": 0.2218346744775772,
      "learning_rate": 1.953370965595324e-06,
      "loss": 0.0503,
      "step": 1131
    },
    {
      "epoch": 2.4136460554371,
      "grad_norm": 0.2274332046508789,
      "learning_rate": 1.939717365459952e-06,
      "loss": 0.0591,
      "step": 1132
    },
    {
      "epoch": 2.4157782515991473,
      "grad_norm": 0.2266741693019867,
      "learning_rate": 1.9261065236889064e-06,
      "loss": 0.0531,
      "step": 1133
    },
    {
      "epoch": 2.417910447761194,
      "grad_norm": 0.2258758246898651,
      "learning_rate": 1.9125385124852815e-06,
      "loss": 0.0494,
      "step": 1134
    },
    {
      "epoch": 2.420042643923241,
      "grad_norm": 0.2333182841539383,
      "learning_rate": 1.8990134038249586e-06,
      "loss": 0.0593,
      "step": 1135
    },
    {
      "epoch": 2.4221748400852876,
      "grad_norm": 0.2290368527173996,
      "learning_rate": 1.885531269456231e-06,
      "loss": 0.0498,
      "step": 1136
    },
    {
      "epoch": 2.4243070362473347,
      "grad_norm": 0.2093968391418457,
      "learning_rate": 1.8720921808994264e-06,
      "loss": 0.0501,
      "step": 1137
    },
    {
      "epoch": 2.4264392324093818,
      "grad_norm": 0.22613364458084106,
      "learning_rate": 1.85869620944651e-06,
      "loss": 0.0519,
      "step": 1138
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 0.21654915809631348,
      "learning_rate": 1.8453434261607272e-06,
      "loss": 0.051,
      "step": 1139
    },
    {
      "epoch": 2.4307036247334755,
      "grad_norm": 0.2505772113800049,
      "learning_rate": 1.8320339018762167e-06,
      "loss": 0.0619,
      "step": 1140
    },
    {
      "epoch": 2.4328358208955225,
      "grad_norm": 0.2316223829984665,
      "learning_rate": 1.8187677071976362e-06,
      "loss": 0.0539,
      "step": 1141
    },
    {
      "epoch": 2.434968017057569,
      "grad_norm": 0.21541567146778107,
      "learning_rate": 1.8055449124997858e-06,
      "loss": 0.0505,
      "step": 1142
    },
    {
      "epoch": 2.4371002132196162,
      "grad_norm": 0.20987720787525177,
      "learning_rate": 1.7923655879272395e-06,
      "loss": 0.0443,
      "step": 1143
    },
    {
      "epoch": 2.4392324093816633,
      "grad_norm": 0.2035149782896042,
      "learning_rate": 1.7792298033939625e-06,
      "loss": 0.0478,
      "step": 1144
    },
    {
      "epoch": 2.44136460554371,
      "grad_norm": 0.23207488656044006,
      "learning_rate": 1.7661376285829567e-06,
      "loss": 0.0571,
      "step": 1145
    },
    {
      "epoch": 2.443496801705757,
      "grad_norm": 0.20963245630264282,
      "learning_rate": 1.7530891329458766e-06,
      "loss": 0.0473,
      "step": 1146
    },
    {
      "epoch": 2.4456289978678036,
      "grad_norm": 0.2667348086833954,
      "learning_rate": 1.7400843857026707e-06,
      "loss": 0.0614,
      "step": 1147
    },
    {
      "epoch": 2.4477611940298507,
      "grad_norm": 0.21844926476478577,
      "learning_rate": 1.7271234558412054e-06,
      "loss": 0.0534,
      "step": 1148
    },
    {
      "epoch": 2.449893390191898,
      "grad_norm": 0.20393240451812744,
      "learning_rate": 1.714206412116911e-06,
      "loss": 0.046,
      "step": 1149
    },
    {
      "epoch": 2.4520255863539444,
      "grad_norm": 0.2578175365924835,
      "learning_rate": 1.7013333230523977e-06,
      "loss": 0.0562,
      "step": 1150
    },
    {
      "epoch": 2.4541577825159915,
      "grad_norm": 0.2339879274368286,
      "learning_rate": 1.6885042569371147e-06,
      "loss": 0.0554,
      "step": 1151
    },
    {
      "epoch": 2.4562899786780386,
      "grad_norm": 0.22656644880771637,
      "learning_rate": 1.6757192818269708e-06,
      "loss": 0.0542,
      "step": 1152
    },
    {
      "epoch": 2.458422174840085,
      "grad_norm": 0.21272753179073334,
      "learning_rate": 1.6629784655439873e-06,
      "loss": 0.0495,
      "step": 1153
    },
    {
      "epoch": 2.4605543710021323,
      "grad_norm": 0.24093826115131378,
      "learning_rate": 1.6502818756759275e-06,
      "loss": 0.0612,
      "step": 1154
    },
    {
      "epoch": 2.4626865671641793,
      "grad_norm": 0.2276080995798111,
      "learning_rate": 1.6376295795759333e-06,
      "loss": 0.0541,
      "step": 1155
    },
    {
      "epoch": 2.464818763326226,
      "grad_norm": 0.21568486094474792,
      "learning_rate": 1.625021644362187e-06,
      "loss": 0.0494,
      "step": 1156
    },
    {
      "epoch": 2.466950959488273,
      "grad_norm": 0.24736544489860535,
      "learning_rate": 1.6124581369175395e-06,
      "loss": 0.0623,
      "step": 1157
    },
    {
      "epoch": 2.4690831556503197,
      "grad_norm": 0.22455179691314697,
      "learning_rate": 1.5999391238891615e-06,
      "loss": 0.0565,
      "step": 1158
    },
    {
      "epoch": 2.4712153518123667,
      "grad_norm": 0.192163348197937,
      "learning_rate": 1.587464671688187e-06,
      "loss": 0.0439,
      "step": 1159
    },
    {
      "epoch": 2.473347547974414,
      "grad_norm": 0.23198038339614868,
      "learning_rate": 1.5750348464893684e-06,
      "loss": 0.0525,
      "step": 1160
    },
    {
      "epoch": 2.4754797441364604,
      "grad_norm": 0.26244139671325684,
      "learning_rate": 1.5626497142307085e-06,
      "loss": 0.0573,
      "step": 1161
    },
    {
      "epoch": 2.4776119402985075,
      "grad_norm": 0.2119283676147461,
      "learning_rate": 1.550309340613132e-06,
      "loss": 0.0524,
      "step": 1162
    },
    {
      "epoch": 2.479744136460554,
      "grad_norm": 0.208631232380867,
      "learning_rate": 1.5380137911001247e-06,
      "loss": 0.0443,
      "step": 1163
    },
    {
      "epoch": 2.481876332622601,
      "grad_norm": 0.2205098569393158,
      "learning_rate": 1.525763130917387e-06,
      "loss": 0.054,
      "step": 1164
    },
    {
      "epoch": 2.4840085287846483,
      "grad_norm": 0.21382370591163635,
      "learning_rate": 1.5135574250524898e-06,
      "loss": 0.0523,
      "step": 1165
    },
    {
      "epoch": 2.486140724946695,
      "grad_norm": 0.2371722161769867,
      "learning_rate": 1.5013967382545325e-06,
      "loss": 0.061,
      "step": 1166
    },
    {
      "epoch": 2.488272921108742,
      "grad_norm": 0.20538336038589478,
      "learning_rate": 1.4892811350337877e-06,
      "loss": 0.0489,
      "step": 1167
    },
    {
      "epoch": 2.490405117270789,
      "grad_norm": 0.23229824006557465,
      "learning_rate": 1.4772106796613772e-06,
      "loss": 0.0517,
      "step": 1168
    },
    {
      "epoch": 2.4925373134328357,
      "grad_norm": 0.23824086785316467,
      "learning_rate": 1.4651854361689177e-06,
      "loss": 0.0545,
      "step": 1169
    },
    {
      "epoch": 2.4946695095948828,
      "grad_norm": 0.2276456207036972,
      "learning_rate": 1.4532054683481833e-06,
      "loss": 0.0524,
      "step": 1170
    },
    {
      "epoch": 2.49680170575693,
      "grad_norm": 0.2067004144191742,
      "learning_rate": 1.4412708397507724e-06,
      "loss": 0.0478,
      "step": 1171
    },
    {
      "epoch": 2.4989339019189765,
      "grad_norm": 0.2410244196653366,
      "learning_rate": 1.4293816136877636e-06,
      "loss": 0.0586,
      "step": 1172
    },
    {
      "epoch": 2.5010660980810235,
      "grad_norm": 0.38677844405174255,
      "learning_rate": 1.417537853229387e-06,
      "loss": 0.0418,
      "step": 1173
    },
    {
      "epoch": 2.50319829424307,
      "grad_norm": 0.2247856706380844,
      "learning_rate": 1.4057396212046791e-06,
      "loss": 0.0541,
      "step": 1174
    },
    {
      "epoch": 2.5053304904051172,
      "grad_norm": 0.22971907258033752,
      "learning_rate": 1.3939869802011618e-06,
      "loss": 0.0512,
      "step": 1175
    },
    {
      "epoch": 2.5074626865671643,
      "grad_norm": 0.2152690291404724,
      "learning_rate": 1.3822799925645036e-06,
      "loss": 0.0529,
      "step": 1176
    },
    {
      "epoch": 2.509594882729211,
      "grad_norm": 0.22263559699058533,
      "learning_rate": 1.3706187203981891e-06,
      "loss": 0.0546,
      "step": 1177
    },
    {
      "epoch": 2.511727078891258,
      "grad_norm": 0.2448948472738266,
      "learning_rate": 1.3590032255631913e-06,
      "loss": 0.057,
      "step": 1178
    },
    {
      "epoch": 2.5138592750533046,
      "grad_norm": 0.2174321413040161,
      "learning_rate": 1.3474335696776453e-06,
      "loss": 0.0494,
      "step": 1179
    },
    {
      "epoch": 2.5159914712153517,
      "grad_norm": 0.1982700228691101,
      "learning_rate": 1.3359098141165094e-06,
      "loss": 0.0475,
      "step": 1180
    },
    {
      "epoch": 2.518123667377399,
      "grad_norm": 0.18189463019371033,
      "learning_rate": 1.3244320200112593e-06,
      "loss": 0.0373,
      "step": 1181
    },
    {
      "epoch": 2.520255863539446,
      "grad_norm": 0.22580622136592865,
      "learning_rate": 1.3130002482495486e-06,
      "loss": 0.0471,
      "step": 1182
    },
    {
      "epoch": 2.5223880597014925,
      "grad_norm": 0.21603994071483612,
      "learning_rate": 1.3016145594748909e-06,
      "loss": 0.0516,
      "step": 1183
    },
    {
      "epoch": 2.5245202558635396,
      "grad_norm": 0.23762941360473633,
      "learning_rate": 1.2902750140863374e-06,
      "loss": 0.0559,
      "step": 1184
    },
    {
      "epoch": 2.526652452025586,
      "grad_norm": 0.2469862550497055,
      "learning_rate": 1.2789816722381608e-06,
      "loss": 0.0527,
      "step": 1185
    },
    {
      "epoch": 2.5287846481876333,
      "grad_norm": 0.21156556904315948,
      "learning_rate": 1.2677345938395246e-06,
      "loss": 0.0483,
      "step": 1186
    },
    {
      "epoch": 2.5309168443496803,
      "grad_norm": 0.2110012322664261,
      "learning_rate": 1.2565338385541792e-06,
      "loss": 0.0495,
      "step": 1187
    },
    {
      "epoch": 2.533049040511727,
      "grad_norm": 0.2153310775756836,
      "learning_rate": 1.2453794658001373e-06,
      "loss": 0.055,
      "step": 1188
    },
    {
      "epoch": 2.535181236673774,
      "grad_norm": 0.22429095208644867,
      "learning_rate": 1.2342715347493595e-06,
      "loss": 0.0549,
      "step": 1189
    },
    {
      "epoch": 2.5373134328358207,
      "grad_norm": 0.27688464522361755,
      "learning_rate": 1.2232101043274437e-06,
      "loss": 0.0511,
      "step": 1190
    },
    {
      "epoch": 2.5394456289978677,
      "grad_norm": 0.23385070264339447,
      "learning_rate": 1.2121952332133091e-06,
      "loss": 0.0516,
      "step": 1191
    },
    {
      "epoch": 2.541577825159915,
      "grad_norm": 0.22249889373779297,
      "learning_rate": 1.2012269798388842e-06,
      "loss": 0.0526,
      "step": 1192
    },
    {
      "epoch": 2.543710021321962,
      "grad_norm": 0.22254019975662231,
      "learning_rate": 1.1903054023888016e-06,
      "loss": 0.0534,
      "step": 1193
    },
    {
      "epoch": 2.5458422174840085,
      "grad_norm": 0.21722152829170227,
      "learning_rate": 1.1794305588000842e-06,
      "loss": 0.0463,
      "step": 1194
    },
    {
      "epoch": 2.5479744136460556,
      "grad_norm": 0.24440951645374298,
      "learning_rate": 1.1686025067618423e-06,
      "loss": 0.0602,
      "step": 1195
    },
    {
      "epoch": 2.550106609808102,
      "grad_norm": 0.23727762699127197,
      "learning_rate": 1.1578213037149632e-06,
      "loss": 0.0519,
      "step": 1196
    },
    {
      "epoch": 2.5522388059701493,
      "grad_norm": 0.23101162910461426,
      "learning_rate": 1.1470870068518114e-06,
      "loss": 0.0577,
      "step": 1197
    },
    {
      "epoch": 2.5543710021321964,
      "grad_norm": 0.22767174243927002,
      "learning_rate": 1.1363996731159188e-06,
      "loss": 0.0524,
      "step": 1198
    },
    {
      "epoch": 2.556503198294243,
      "grad_norm": 0.19807380437850952,
      "learning_rate": 1.125759359201687e-06,
      "loss": 0.0436,
      "step": 1199
    },
    {
      "epoch": 2.55863539445629,
      "grad_norm": 0.22616969048976898,
      "learning_rate": 1.1151661215540887e-06,
      "loss": 0.0549,
      "step": 1200
    },
    {
      "epoch": 2.5607675906183367,
      "grad_norm": 0.21799996495246887,
      "learning_rate": 1.104620016368364e-06,
      "loss": 0.0508,
      "step": 1201
    },
    {
      "epoch": 2.5628997867803838,
      "grad_norm": 0.21655096113681793,
      "learning_rate": 1.0941210995897221e-06,
      "loss": 0.0561,
      "step": 1202
    },
    {
      "epoch": 2.565031982942431,
      "grad_norm": 0.21919812262058258,
      "learning_rate": 1.0836694269130498e-06,
      "loss": 0.0527,
      "step": 1203
    },
    {
      "epoch": 2.5671641791044775,
      "grad_norm": 0.22627535462379456,
      "learning_rate": 1.073265053782606e-06,
      "loss": 0.0567,
      "step": 1204
    },
    {
      "epoch": 2.5692963752665245,
      "grad_norm": 0.22218790650367737,
      "learning_rate": 1.0629080353917399e-06,
      "loss": 0.0526,
      "step": 1205
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.23666825890541077,
      "learning_rate": 1.0525984266825894e-06,
      "loss": 0.0586,
      "step": 1206
    },
    {
      "epoch": 2.5735607675906182,
      "grad_norm": 0.22821375727653503,
      "learning_rate": 1.0423362823457939e-06,
      "loss": 0.0531,
      "step": 1207
    },
    {
      "epoch": 2.5756929637526653,
      "grad_norm": 0.2092379927635193,
      "learning_rate": 1.032121656820202e-06,
      "loss": 0.0502,
      "step": 1208
    },
    {
      "epoch": 2.5778251599147124,
      "grad_norm": 0.2115100622177124,
      "learning_rate": 1.0219546042925842e-06,
      "loss": 0.0479,
      "step": 1209
    },
    {
      "epoch": 2.579957356076759,
      "grad_norm": 0.24398529529571533,
      "learning_rate": 1.0118351786973424e-06,
      "loss": 0.0584,
      "step": 1210
    },
    {
      "epoch": 2.582089552238806,
      "grad_norm": 0.23775357007980347,
      "learning_rate": 1.0017634337162275e-06,
      "loss": 0.0595,
      "step": 1211
    },
    {
      "epoch": 2.5842217484008527,
      "grad_norm": 0.22071796655654907,
      "learning_rate": 9.917394227780542e-07,
      "loss": 0.0588,
      "step": 1212
    },
    {
      "epoch": 2.5863539445629,
      "grad_norm": 0.22981111705303192,
      "learning_rate": 9.817631990584164e-07,
      "loss": 0.0494,
      "step": 1213
    },
    {
      "epoch": 2.588486140724947,
      "grad_norm": 0.23068822920322418,
      "learning_rate": 9.718348154794045e-07,
      "loss": 0.0547,
      "step": 1214
    },
    {
      "epoch": 2.5906183368869935,
      "grad_norm": 0.2322266548871994,
      "learning_rate": 9.619543247093255e-07,
      "loss": 0.0574,
      "step": 1215
    },
    {
      "epoch": 2.5927505330490406,
      "grad_norm": 0.22131426632404327,
      "learning_rate": 9.52121779162426e-07,
      "loss": 0.0461,
      "step": 1216
    },
    {
      "epoch": 2.594882729211087,
      "grad_norm": 0.19680458307266235,
      "learning_rate": 9.423372309986056e-07,
      "loss": 0.0426,
      "step": 1217
    },
    {
      "epoch": 2.5970149253731343,
      "grad_norm": 0.20943644642829895,
      "learning_rate": 9.326007321231523e-07,
      "loss": 0.0482,
      "step": 1218
    },
    {
      "epoch": 2.5991471215351813,
      "grad_norm": 0.23682045936584473,
      "learning_rate": 9.229123341864576e-07,
      "loss": 0.0575,
      "step": 1219
    },
    {
      "epoch": 2.6012793176972284,
      "grad_norm": 0.22865696251392365,
      "learning_rate": 9.132720885837509e-07,
      "loss": 0.0566,
      "step": 1220
    },
    {
      "epoch": 2.603411513859275,
      "grad_norm": 0.21382862329483032,
      "learning_rate": 9.036800464548157e-07,
      "loss": 0.0448,
      "step": 1221
    },
    {
      "epoch": 2.605543710021322,
      "grad_norm": 0.22458316385746002,
      "learning_rate": 8.94136258683731e-07,
      "loss": 0.0571,
      "step": 1222
    },
    {
      "epoch": 2.6076759061833688,
      "grad_norm": 0.22177888453006744,
      "learning_rate": 8.846407758985886e-07,
      "loss": 0.0596,
      "step": 1223
    },
    {
      "epoch": 2.609808102345416,
      "grad_norm": 0.2228085994720459,
      "learning_rate": 8.751936484712342e-07,
      "loss": 0.0496,
      "step": 1224
    },
    {
      "epoch": 2.611940298507463,
      "grad_norm": 0.22557418048381805,
      "learning_rate": 8.657949265169985e-07,
      "loss": 0.0531,
      "step": 1225
    },
    {
      "epoch": 2.6140724946695095,
      "grad_norm": 0.21692921221256256,
      "learning_rate": 8.564446598944276e-07,
      "loss": 0.0493,
      "step": 1226
    },
    {
      "epoch": 2.6162046908315566,
      "grad_norm": 0.21257899701595306,
      "learning_rate": 8.471428982050201e-07,
      "loss": 0.0492,
      "step": 1227
    },
    {
      "epoch": 2.6183368869936032,
      "grad_norm": 0.23886728286743164,
      "learning_rate": 8.37889690792969e-07,
      "loss": 0.0523,
      "step": 1228
    },
    {
      "epoch": 2.6204690831556503,
      "grad_norm": 0.23128777742385864,
      "learning_rate": 8.286850867448881e-07,
      "loss": 0.0536,
      "step": 1229
    },
    {
      "epoch": 2.6226012793176974,
      "grad_norm": 0.22413520514965057,
      "learning_rate": 8.195291348895651e-07,
      "loss": 0.0548,
      "step": 1230
    },
    {
      "epoch": 2.624733475479744,
      "grad_norm": 0.24104133248329163,
      "learning_rate": 8.10421883797694e-07,
      "loss": 0.0527,
      "step": 1231
    },
    {
      "epoch": 2.626865671641791,
      "grad_norm": 0.22596223652362823,
      "learning_rate": 8.013633817816202e-07,
      "loss": 0.0498,
      "step": 1232
    },
    {
      "epoch": 2.6289978678038377,
      "grad_norm": 0.20222055912017822,
      "learning_rate": 7.923536768950857e-07,
      "loss": 0.0494,
      "step": 1233
    },
    {
      "epoch": 2.631130063965885,
      "grad_norm": 0.2572534680366516,
      "learning_rate": 7.833928169329696e-07,
      "loss": 0.0457,
      "step": 1234
    },
    {
      "epoch": 2.633262260127932,
      "grad_norm": 0.2206631749868393,
      "learning_rate": 7.744808494310385e-07,
      "loss": 0.053,
      "step": 1235
    },
    {
      "epoch": 2.635394456289979,
      "grad_norm": 0.19971342384815216,
      "learning_rate": 7.656178216656929e-07,
      "loss": 0.0469,
      "step": 1236
    },
    {
      "epoch": 2.6375266524520256,
      "grad_norm": 0.20093713700771332,
      "learning_rate": 7.568037806537176e-07,
      "loss": 0.0498,
      "step": 1237
    },
    {
      "epoch": 2.6396588486140726,
      "grad_norm": 0.23866845667362213,
      "learning_rate": 7.480387731520311e-07,
      "loss": 0.0601,
      "step": 1238
    },
    {
      "epoch": 2.6417910447761193,
      "grad_norm": 0.20989155769348145,
      "learning_rate": 7.393228456574375e-07,
      "loss": 0.0461,
      "step": 1239
    },
    {
      "epoch": 2.6439232409381663,
      "grad_norm": 0.23133037984371185,
      "learning_rate": 7.306560444063826e-07,
      "loss": 0.0575,
      "step": 1240
    },
    {
      "epoch": 2.6460554371002134,
      "grad_norm": 0.20881067216396332,
      "learning_rate": 7.220384153746996e-07,
      "loss": 0.0484,
      "step": 1241
    },
    {
      "epoch": 2.64818763326226,
      "grad_norm": 0.23217949271202087,
      "learning_rate": 7.13470004277379e-07,
      "loss": 0.0534,
      "step": 1242
    },
    {
      "epoch": 2.650319829424307,
      "grad_norm": 0.2355199009180069,
      "learning_rate": 7.04950856568315e-07,
      "loss": 0.0563,
      "step": 1243
    },
    {
      "epoch": 2.6524520255863537,
      "grad_norm": 0.22371132671833038,
      "learning_rate": 6.964810174400704e-07,
      "loss": 0.0497,
      "step": 1244
    },
    {
      "epoch": 2.654584221748401,
      "grad_norm": 0.21455399692058563,
      "learning_rate": 6.880605318236344e-07,
      "loss": 0.0487,
      "step": 1245
    },
    {
      "epoch": 2.656716417910448,
      "grad_norm": 0.2394973635673523,
      "learning_rate": 6.79689444388184e-07,
      "loss": 0.0599,
      "step": 1246
    },
    {
      "epoch": 2.6588486140724945,
      "grad_norm": 0.19315074384212494,
      "learning_rate": 6.713677995408452e-07,
      "loss": 0.045,
      "step": 1247
    },
    {
      "epoch": 2.6609808102345416,
      "grad_norm": 0.2317826896905899,
      "learning_rate": 6.630956414264644e-07,
      "loss": 0.055,
      "step": 1248
    },
    {
      "epoch": 2.663113006396588,
      "grad_norm": 0.20489586889743805,
      "learning_rate": 6.548730139273662e-07,
      "loss": 0.0477,
      "step": 1249
    },
    {
      "epoch": 2.6652452025586353,
      "grad_norm": 0.22426342964172363,
      "learning_rate": 6.466999606631274e-07,
      "loss": 0.0537,
      "step": 1250
    },
    {
      "epoch": 2.6673773987206824,
      "grad_norm": 0.21178294718265533,
      "learning_rate": 6.385765249903397e-07,
      "loss": 0.0484,
      "step": 1251
    },
    {
      "epoch": 2.6695095948827294,
      "grad_norm": 0.21796123683452606,
      "learning_rate": 6.305027500023841e-07,
      "loss": 0.0473,
      "step": 1252
    },
    {
      "epoch": 2.671641791044776,
      "grad_norm": 0.21536174416542053,
      "learning_rate": 6.22478678529197e-07,
      "loss": 0.0522,
      "step": 1253
    },
    {
      "epoch": 2.673773987206823,
      "grad_norm": 0.2321811318397522,
      "learning_rate": 6.145043531370498e-07,
      "loss": 0.0562,
      "step": 1254
    },
    {
      "epoch": 2.6759061833688698,
      "grad_norm": 0.20110896229743958,
      "learning_rate": 6.065798161283187e-07,
      "loss": 0.0444,
      "step": 1255
    },
    {
      "epoch": 2.678038379530917,
      "grad_norm": 0.21924516558647156,
      "learning_rate": 5.987051095412632e-07,
      "loss": 0.051,
      "step": 1256
    },
    {
      "epoch": 2.680170575692964,
      "grad_norm": 0.21690461039543152,
      "learning_rate": 5.908802751497989e-07,
      "loss": 0.051,
      "step": 1257
    },
    {
      "epoch": 2.6823027718550105,
      "grad_norm": 0.22746185958385468,
      "learning_rate": 5.831053544632803e-07,
      "loss": 0.0567,
      "step": 1258
    },
    {
      "epoch": 2.6844349680170576,
      "grad_norm": 0.2544980049133301,
      "learning_rate": 5.753803887262744e-07,
      "loss": 0.0576,
      "step": 1259
    },
    {
      "epoch": 2.6865671641791042,
      "grad_norm": 0.23131033778190613,
      "learning_rate": 5.677054189183517e-07,
      "loss": 0.0532,
      "step": 1260
    },
    {
      "epoch": 2.6886993603411513,
      "grad_norm": 0.21470314264297485,
      "learning_rate": 5.600804857538589e-07,
      "loss": 0.0508,
      "step": 1261
    },
    {
      "epoch": 2.6908315565031984,
      "grad_norm": 0.23335564136505127,
      "learning_rate": 5.5250562968171e-07,
      "loss": 0.0525,
      "step": 1262
    },
    {
      "epoch": 2.6929637526652455,
      "grad_norm": 0.20290954411029816,
      "learning_rate": 5.449808908851672e-07,
      "loss": 0.0483,
      "step": 1263
    },
    {
      "epoch": 2.695095948827292,
      "grad_norm": 0.22519215941429138,
      "learning_rate": 5.375063092816313e-07,
      "loss": 0.0551,
      "step": 1264
    },
    {
      "epoch": 2.697228144989339,
      "grad_norm": 0.24245548248291016,
      "learning_rate": 5.300819245224276e-07,
      "loss": 0.0577,
      "step": 1265
    },
    {
      "epoch": 2.699360341151386,
      "grad_norm": 0.2037343531847,
      "learning_rate": 5.227077759925914e-07,
      "loss": 0.0483,
      "step": 1266
    },
    {
      "epoch": 2.701492537313433,
      "grad_norm": 0.2301633059978485,
      "learning_rate": 5.153839028106711e-07,
      "loss": 0.0614,
      "step": 1267
    },
    {
      "epoch": 2.70362473347548,
      "grad_norm": 0.21382567286491394,
      "learning_rate": 5.081103438285096e-07,
      "loss": 0.0498,
      "step": 1268
    },
    {
      "epoch": 2.7057569296375266,
      "grad_norm": 0.22296099364757538,
      "learning_rate": 5.008871376310409e-07,
      "loss": 0.0529,
      "step": 1269
    },
    {
      "epoch": 2.7078891257995736,
      "grad_norm": 0.219898983836174,
      "learning_rate": 4.937143225360897e-07,
      "loss": 0.0482,
      "step": 1270
    },
    {
      "epoch": 2.7100213219616203,
      "grad_norm": 0.2354460060596466,
      "learning_rate": 4.865919365941629e-07,
      "loss": 0.0558,
      "step": 1271
    },
    {
      "epoch": 2.7121535181236673,
      "grad_norm": 0.2088022381067276,
      "learning_rate": 4.795200175882486e-07,
      "loss": 0.0505,
      "step": 1272
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 0.2365206778049469,
      "learning_rate": 4.724986030336176e-07,
      "loss": 0.0568,
      "step": 1273
    },
    {
      "epoch": 2.716417910447761,
      "grad_norm": 0.2339891940355301,
      "learning_rate": 4.655277301776262e-07,
      "loss": 0.0612,
      "step": 1274
    },
    {
      "epoch": 2.718550106609808,
      "grad_norm": 0.20840026438236237,
      "learning_rate": 4.5860743599951186e-07,
      "loss": 0.0498,
      "step": 1275
    },
    {
      "epoch": 2.7206823027718547,
      "grad_norm": 0.1949423849582672,
      "learning_rate": 4.517377572102044e-07,
      "loss": 0.0426,
      "step": 1276
    },
    {
      "epoch": 2.722814498933902,
      "grad_norm": 0.20975562930107117,
      "learning_rate": 4.449187302521263e-07,
      "loss": 0.049,
      "step": 1277
    },
    {
      "epoch": 2.724946695095949,
      "grad_norm": 0.2182762622833252,
      "learning_rate": 4.381503912990015e-07,
      "loss": 0.0515,
      "step": 1278
    },
    {
      "epoch": 2.727078891257996,
      "grad_norm": 0.24049383401870728,
      "learning_rate": 4.314327762556625e-07,
      "loss": 0.0556,
      "step": 1279
    },
    {
      "epoch": 2.7292110874200426,
      "grad_norm": 0.23033450543880463,
      "learning_rate": 4.247659207578614e-07,
      "loss": 0.0551,
      "step": 1280
    },
    {
      "epoch": 2.7313432835820897,
      "grad_norm": 0.21017423272132874,
      "learning_rate": 4.1814986017208013e-07,
      "loss": 0.0474,
      "step": 1281
    },
    {
      "epoch": 2.7334754797441363,
      "grad_norm": 0.22121572494506836,
      "learning_rate": 4.1158462959534187e-07,
      "loss": 0.0535,
      "step": 1282
    },
    {
      "epoch": 2.7356076759061834,
      "grad_norm": 0.2127065509557724,
      "learning_rate": 4.0507026385502747e-07,
      "loss": 0.0497,
      "step": 1283
    },
    {
      "epoch": 2.7377398720682304,
      "grad_norm": 0.226029634475708,
      "learning_rate": 3.986067975086838e-07,
      "loss": 0.0527,
      "step": 1284
    },
    {
      "epoch": 2.739872068230277,
      "grad_norm": 0.2262142300605774,
      "learning_rate": 3.921942648438526e-07,
      "loss": 0.0537,
      "step": 1285
    },
    {
      "epoch": 2.742004264392324,
      "grad_norm": 0.22182784974575043,
      "learning_rate": 3.8583269987787607e-07,
      "loss": 0.0504,
      "step": 1286
    },
    {
      "epoch": 2.7441364605543708,
      "grad_norm": 0.21209679543972015,
      "learning_rate": 3.7952213635772395e-07,
      "loss": 0.049,
      "step": 1287
    },
    {
      "epoch": 2.746268656716418,
      "grad_norm": 0.2022218406200409,
      "learning_rate": 3.7326260775981225e-07,
      "loss": 0.0491,
      "step": 1288
    },
    {
      "epoch": 2.748400852878465,
      "grad_norm": 0.21833233535289764,
      "learning_rate": 3.6705414728982704e-07,
      "loss": 0.0459,
      "step": 1289
    },
    {
      "epoch": 2.750533049040512,
      "grad_norm": 0.21601708233356476,
      "learning_rate": 3.608967878825442e-07,
      "loss": 0.049,
      "step": 1290
    },
    {
      "epoch": 2.7526652452025586,
      "grad_norm": 0.22206510603427887,
      "learning_rate": 3.5479056220166006e-07,
      "loss": 0.0531,
      "step": 1291
    },
    {
      "epoch": 2.7547974413646057,
      "grad_norm": 0.19920533895492554,
      "learning_rate": 3.487355026396133e-07,
      "loss": 0.0454,
      "step": 1292
    },
    {
      "epoch": 2.7569296375266523,
      "grad_norm": 0.19992780685424805,
      "learning_rate": 3.427316413174175e-07,
      "loss": 0.0447,
      "step": 1293
    },
    {
      "epoch": 2.7590618336886994,
      "grad_norm": 0.22265499830245972,
      "learning_rate": 3.367790100844892e-07,
      "loss": 0.0531,
      "step": 1294
    },
    {
      "epoch": 2.7611940298507465,
      "grad_norm": 0.2066531479358673,
      "learning_rate": 3.308776405184777e-07,
      "loss": 0.045,
      "step": 1295
    },
    {
      "epoch": 2.763326226012793,
      "grad_norm": 0.2019323706626892,
      "learning_rate": 3.250275639250955e-07,
      "loss": 0.0433,
      "step": 1296
    },
    {
      "epoch": 2.76545842217484,
      "grad_norm": 0.22989149391651154,
      "learning_rate": 3.1922881133795827e-07,
      "loss": 0.0537,
      "step": 1297
    },
    {
      "epoch": 2.767590618336887,
      "grad_norm": 0.22319699823856354,
      "learning_rate": 3.134814135184161e-07,
      "loss": 0.0498,
      "step": 1298
    },
    {
      "epoch": 2.769722814498934,
      "grad_norm": 0.21683676540851593,
      "learning_rate": 3.0778540095539156e-07,
      "loss": 0.0536,
      "step": 1299
    },
    {
      "epoch": 2.771855010660981,
      "grad_norm": 0.21997904777526855,
      "learning_rate": 3.021408038652163e-07,
      "loss": 0.045,
      "step": 1300
    },
    {
      "epoch": 2.7739872068230276,
      "grad_norm": 0.19602122902870178,
      "learning_rate": 2.965476521914756e-07,
      "loss": 0.0458,
      "step": 1301
    },
    {
      "epoch": 2.7761194029850746,
      "grad_norm": 0.19246046245098114,
      "learning_rate": 2.9100597560484e-07,
      "loss": 0.0443,
      "step": 1302
    },
    {
      "epoch": 2.7782515991471213,
      "grad_norm": 0.23308050632476807,
      "learning_rate": 2.855158035029182e-07,
      "loss": 0.0562,
      "step": 1303
    },
    {
      "epoch": 2.7803837953091683,
      "grad_norm": 0.20897649228572845,
      "learning_rate": 2.800771650100964e-07,
      "loss": 0.0485,
      "step": 1304
    },
    {
      "epoch": 2.7825159914712154,
      "grad_norm": 0.21761251986026764,
      "learning_rate": 2.7469008897738294e-07,
      "loss": 0.0478,
      "step": 1305
    },
    {
      "epoch": 2.7846481876332625,
      "grad_norm": 0.22069892287254333,
      "learning_rate": 2.69354603982257e-07,
      "loss": 0.0523,
      "step": 1306
    },
    {
      "epoch": 2.786780383795309,
      "grad_norm": 0.21422158181667328,
      "learning_rate": 2.6407073832851684e-07,
      "loss": 0.0482,
      "step": 1307
    },
    {
      "epoch": 2.788912579957356,
      "grad_norm": 0.20627018809318542,
      "learning_rate": 2.588385200461307e-07,
      "loss": 0.0471,
      "step": 1308
    },
    {
      "epoch": 2.791044776119403,
      "grad_norm": 0.22137808799743652,
      "learning_rate": 2.5365797689108186e-07,
      "loss": 0.0484,
      "step": 1309
    },
    {
      "epoch": 2.79317697228145,
      "grad_norm": 0.1914590448141098,
      "learning_rate": 2.4852913634523025e-07,
      "loss": 0.0452,
      "step": 1310
    },
    {
      "epoch": 2.795309168443497,
      "grad_norm": 0.2512189745903015,
      "learning_rate": 2.434520256161632e-07,
      "loss": 0.0518,
      "step": 1311
    },
    {
      "epoch": 2.7974413646055436,
      "grad_norm": 0.21777933835983276,
      "learning_rate": 2.384266716370476e-07,
      "loss": 0.0486,
      "step": 1312
    },
    {
      "epoch": 2.7995735607675907,
      "grad_norm": 0.19599969685077667,
      "learning_rate": 2.334531010664931e-07,
      "loss": 0.0439,
      "step": 1313
    },
    {
      "epoch": 2.8017057569296373,
      "grad_norm": 0.24324582517147064,
      "learning_rate": 2.2853134028840594e-07,
      "loss": 0.0609,
      "step": 1314
    },
    {
      "epoch": 2.8038379530916844,
      "grad_norm": 0.2101183384656906,
      "learning_rate": 2.2366141541184884e-07,
      "loss": 0.0451,
      "step": 1315
    },
    {
      "epoch": 2.8059701492537314,
      "grad_norm": 0.20824399590492249,
      "learning_rate": 2.188433522709088e-07,
      "loss": 0.0451,
      "step": 1316
    },
    {
      "epoch": 2.8081023454157785,
      "grad_norm": 0.21719160676002502,
      "learning_rate": 2.1407717642455083e-07,
      "loss": 0.0507,
      "step": 1317
    },
    {
      "epoch": 2.810234541577825,
      "grad_norm": 0.1969716101884842,
      "learning_rate": 2.0936291315649116e-07,
      "loss": 0.0428,
      "step": 1318
    },
    {
      "epoch": 2.8123667377398722,
      "grad_norm": 0.204051211476326,
      "learning_rate": 2.0470058747505516e-07,
      "loss": 0.0454,
      "step": 1319
    },
    {
      "epoch": 2.814498933901919,
      "grad_norm": 0.22160877287387848,
      "learning_rate": 2.0009022411305312e-07,
      "loss": 0.0501,
      "step": 1320
    },
    {
      "epoch": 2.816631130063966,
      "grad_norm": 0.22596639394760132,
      "learning_rate": 1.955318475276391e-07,
      "loss": 0.0539,
      "step": 1321
    },
    {
      "epoch": 2.818763326226013,
      "grad_norm": 0.20845884084701538,
      "learning_rate": 1.9102548190018887e-07,
      "loss": 0.0506,
      "step": 1322
    },
    {
      "epoch": 2.8208955223880596,
      "grad_norm": 0.22212746739387512,
      "learning_rate": 1.865711511361734e-07,
      "loss": 0.0498,
      "step": 1323
    },
    {
      "epoch": 2.8230277185501067,
      "grad_norm": 0.26390042901039124,
      "learning_rate": 1.821688788650211e-07,
      "loss": 0.0694,
      "step": 1324
    },
    {
      "epoch": 2.8251599147121533,
      "grad_norm": 0.21935440599918365,
      "learning_rate": 1.778186884400046e-07,
      "loss": 0.0532,
      "step": 1325
    },
    {
      "epoch": 2.8272921108742004,
      "grad_norm": 0.20886492729187012,
      "learning_rate": 1.7352060293810868e-07,
      "loss": 0.0503,
      "step": 1326
    },
    {
      "epoch": 2.8294243070362475,
      "grad_norm": 0.24884702265262604,
      "learning_rate": 1.6927464515991142e-07,
      "loss": 0.063,
      "step": 1327
    },
    {
      "epoch": 2.831556503198294,
      "grad_norm": 0.2068319022655487,
      "learning_rate": 1.6508083762946326e-07,
      "loss": 0.0476,
      "step": 1328
    },
    {
      "epoch": 2.833688699360341,
      "grad_norm": 0.20784145593643188,
      "learning_rate": 1.6093920259416696e-07,
      "loss": 0.0477,
      "step": 1329
    },
    {
      "epoch": 2.835820895522388,
      "grad_norm": 0.2075112760066986,
      "learning_rate": 1.5684976202465786e-07,
      "loss": 0.0481,
      "step": 1330
    },
    {
      "epoch": 2.837953091684435,
      "grad_norm": 0.2374710887670517,
      "learning_rate": 1.5281253761469162e-07,
      "loss": 0.06,
      "step": 1331
    },
    {
      "epoch": 2.840085287846482,
      "grad_norm": 0.2276395559310913,
      "learning_rate": 1.488275507810233e-07,
      "loss": 0.0529,
      "step": 1332
    },
    {
      "epoch": 2.842217484008529,
      "grad_norm": 0.22673624753952026,
      "learning_rate": 1.4489482266329958e-07,
      "loss": 0.0603,
      "step": 1333
    },
    {
      "epoch": 2.8443496801705757,
      "grad_norm": 0.22060392796993256,
      "learning_rate": 1.4101437412394337e-07,
      "loss": 0.0515,
      "step": 1334
    },
    {
      "epoch": 2.8464818763326227,
      "grad_norm": 0.22107240557670593,
      "learning_rate": 1.3718622574804163e-07,
      "loss": 0.0561,
      "step": 1335
    },
    {
      "epoch": 2.8486140724946694,
      "grad_norm": 0.23650814592838287,
      "learning_rate": 1.3341039784324106e-07,
      "loss": 0.0527,
      "step": 1336
    },
    {
      "epoch": 2.8507462686567164,
      "grad_norm": 0.23038268089294434,
      "learning_rate": 1.29686910439637e-07,
      "loss": 0.0602,
      "step": 1337
    },
    {
      "epoch": 2.8528784648187635,
      "grad_norm": 0.22536854445934296,
      "learning_rate": 1.260157832896658e-07,
      "loss": 0.0495,
      "step": 1338
    },
    {
      "epoch": 2.85501066098081,
      "grad_norm": 0.23616962134838104,
      "learning_rate": 1.2239703586800376e-07,
      "loss": 0.0552,
      "step": 1339
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.1927518993616104,
      "learning_rate": 1.1883068737146286e-07,
      "loss": 0.0445,
      "step": 1340
    },
    {
      "epoch": 2.859275053304904,
      "grad_norm": 0.22874420881271362,
      "learning_rate": 1.1531675671888621e-07,
      "loss": 0.0588,
      "step": 1341
    },
    {
      "epoch": 2.861407249466951,
      "grad_norm": 0.24320010840892792,
      "learning_rate": 1.118552625510494e-07,
      "loss": 0.0618,
      "step": 1342
    },
    {
      "epoch": 2.863539445628998,
      "grad_norm": 0.2200370579957962,
      "learning_rate": 1.0844622323056387e-07,
      "loss": 0.052,
      "step": 1343
    },
    {
      "epoch": 2.8656716417910446,
      "grad_norm": 0.2044890820980072,
      "learning_rate": 1.0508965684177586e-07,
      "loss": 0.0461,
      "step": 1344
    },
    {
      "epoch": 2.8678038379530917,
      "grad_norm": 0.23667345941066742,
      "learning_rate": 1.0178558119067316e-07,
      "loss": 0.0567,
      "step": 1345
    },
    {
      "epoch": 2.8699360341151388,
      "grad_norm": 0.2219439446926117,
      "learning_rate": 9.853401380478744e-08,
      "loss": 0.0573,
      "step": 1346
    },
    {
      "epoch": 2.8720682302771854,
      "grad_norm": 0.21719485521316528,
      "learning_rate": 9.533497193310537e-08,
      "loss": 0.0503,
      "step": 1347
    },
    {
      "epoch": 2.8742004264392325,
      "grad_norm": 0.2617097496986389,
      "learning_rate": 9.21884725459743e-08,
      "loss": 0.0686,
      "step": 1348
    },
    {
      "epoch": 2.8763326226012795,
      "grad_norm": 0.22892160713672638,
      "learning_rate": 8.909453233501453e-08,
      "loss": 0.0582,
      "step": 1349
    },
    {
      "epoch": 2.878464818763326,
      "grad_norm": 0.20402322709560394,
      "learning_rate": 8.605316771302718e-08,
      "loss": 0.0485,
      "step": 1350
    },
    {
      "epoch": 2.8805970149253732,
      "grad_norm": 0.24653643369674683,
      "learning_rate": 8.306439481390871e-08,
      "loss": 0.061,
      "step": 1351
    },
    {
      "epoch": 2.88272921108742,
      "grad_norm": 0.2071961760520935,
      "learning_rate": 8.012822949256981e-08,
      "loss": 0.0476,
      "step": 1352
    },
    {
      "epoch": 2.884861407249467,
      "grad_norm": 0.2120349258184433,
      "learning_rate": 7.724468732484336e-08,
      "loss": 0.0485,
      "step": 1353
    },
    {
      "epoch": 2.886993603411514,
      "grad_norm": 0.21226078271865845,
      "learning_rate": 7.441378360740659e-08,
      "loss": 0.0486,
      "step": 1354
    },
    {
      "epoch": 2.8891257995735606,
      "grad_norm": 0.21270999312400818,
      "learning_rate": 7.163553335770124e-08,
      "loss": 0.0519,
      "step": 1355
    },
    {
      "epoch": 2.8912579957356077,
      "grad_norm": 0.21885816752910614,
      "learning_rate": 6.890995131384914e-08,
      "loss": 0.0534,
      "step": 1356
    },
    {
      "epoch": 2.8933901918976543,
      "grad_norm": 0.24470317363739014,
      "learning_rate": 6.623705193457896e-08,
      "loss": 0.0616,
      "step": 1357
    },
    {
      "epoch": 2.8955223880597014,
      "grad_norm": 0.21374483406543732,
      "learning_rate": 6.361684939914403e-08,
      "loss": 0.0489,
      "step": 1358
    },
    {
      "epoch": 2.8976545842217485,
      "grad_norm": 0.22334742546081543,
      "learning_rate": 6.10493576072535e-08,
      "loss": 0.0547,
      "step": 1359
    },
    {
      "epoch": 2.8997867803837956,
      "grad_norm": 0.2304425835609436,
      "learning_rate": 5.8534590178994654e-08,
      "loss": 0.0564,
      "step": 1360
    },
    {
      "epoch": 2.901918976545842,
      "grad_norm": 0.20752888917922974,
      "learning_rate": 5.6072560454759615e-08,
      "loss": 0.0462,
      "step": 1361
    },
    {
      "epoch": 2.9040511727078893,
      "grad_norm": 0.24202556908130646,
      "learning_rate": 5.366328149517985e-08,
      "loss": 0.0553,
      "step": 1362
    },
    {
      "epoch": 2.906183368869936,
      "grad_norm": 0.2306012064218521,
      "learning_rate": 5.1306766081048456e-08,
      "loss": 0.0559,
      "step": 1363
    },
    {
      "epoch": 2.908315565031983,
      "grad_norm": 0.21877402067184448,
      "learning_rate": 4.9003026713262404e-08,
      "loss": 0.0524,
      "step": 1364
    },
    {
      "epoch": 2.91044776119403,
      "grad_norm": 0.2168978750705719,
      "learning_rate": 4.6752075612748195e-08,
      "loss": 0.0498,
      "step": 1365
    },
    {
      "epoch": 2.9125799573560767,
      "grad_norm": 0.22005273401737213,
      "learning_rate": 4.4553924720400766e-08,
      "loss": 0.0487,
      "step": 1366
    },
    {
      "epoch": 2.9147121535181237,
      "grad_norm": 0.20806394517421722,
      "learning_rate": 4.2408585697019114e-08,
      "loss": 0.0439,
      "step": 1367
    },
    {
      "epoch": 2.9168443496801704,
      "grad_norm": 0.2254108339548111,
      "learning_rate": 4.0316069923245214e-08,
      "loss": 0.056,
      "step": 1368
    },
    {
      "epoch": 2.9189765458422174,
      "grad_norm": 0.21361610293388367,
      "learning_rate": 3.827638849950077e-08,
      "loss": 0.049,
      "step": 1369
    },
    {
      "epoch": 2.9211087420042645,
      "grad_norm": 0.1977372169494629,
      "learning_rate": 3.6289552245935e-08,
      "loss": 0.043,
      "step": 1370
    },
    {
      "epoch": 2.923240938166311,
      "grad_norm": 0.18299199640750885,
      "learning_rate": 3.4355571702360255e-08,
      "loss": 0.0409,
      "step": 1371
    },
    {
      "epoch": 2.925373134328358,
      "grad_norm": 0.19928361475467682,
      "learning_rate": 3.2474457128197636e-08,
      "loss": 0.044,
      "step": 1372
    },
    {
      "epoch": 2.927505330490405,
      "grad_norm": 0.22263868153095245,
      "learning_rate": 3.064621850242588e-08,
      "loss": 0.0514,
      "step": 1373
    },
    {
      "epoch": 2.929637526652452,
      "grad_norm": 0.23579540848731995,
      "learning_rate": 2.8870865523525916e-08,
      "loss": 0.0603,
      "step": 1374
    },
    {
      "epoch": 2.931769722814499,
      "grad_norm": 0.20664481818675995,
      "learning_rate": 2.7148407609427497e-08,
      "loss": 0.0486,
      "step": 1375
    },
    {
      "epoch": 2.933901918976546,
      "grad_norm": 0.21964173018932343,
      "learning_rate": 2.547885389746485e-08,
      "loss": 0.0507,
      "step": 1376
    },
    {
      "epoch": 2.9360341151385927,
      "grad_norm": 0.2711028456687927,
      "learning_rate": 2.3862213244322254e-08,
      "loss": 0.0574,
      "step": 1377
    },
    {
      "epoch": 2.9381663113006398,
      "grad_norm": 0.25799331068992615,
      "learning_rate": 2.229849422599073e-08,
      "loss": 0.0642,
      "step": 1378
    },
    {
      "epoch": 2.9402985074626864,
      "grad_norm": 0.19971029460430145,
      "learning_rate": 2.0787705137721435e-08,
      "loss": 0.0481,
      "step": 1379
    },
    {
      "epoch": 2.9424307036247335,
      "grad_norm": 0.2210427224636078,
      "learning_rate": 1.9329853993982352e-08,
      "loss": 0.0565,
      "step": 1380
    },
    {
      "epoch": 2.9445628997867805,
      "grad_norm": 0.21087656915187836,
      "learning_rate": 1.7924948528412756e-08,
      "loss": 0.0537,
      "step": 1381
    },
    {
      "epoch": 2.946695095948827,
      "grad_norm": 0.24034781754016876,
      "learning_rate": 1.6572996193786607e-08,
      "loss": 0.0599,
      "step": 1382
    },
    {
      "epoch": 2.9488272921108742,
      "grad_norm": 0.23303087055683136,
      "learning_rate": 1.5274004161970335e-08,
      "loss": 0.0558,
      "step": 1383
    },
    {
      "epoch": 2.950959488272921,
      "grad_norm": 0.23368124663829803,
      "learning_rate": 1.402797932388511e-08,
      "loss": 0.0566,
      "step": 1384
    },
    {
      "epoch": 2.953091684434968,
      "grad_norm": 0.20842128992080688,
      "learning_rate": 1.2834928289472415e-08,
      "loss": 0.0462,
      "step": 1385
    },
    {
      "epoch": 2.955223880597015,
      "grad_norm": 0.2384853959083557,
      "learning_rate": 1.1694857387652969e-08,
      "loss": 0.0533,
      "step": 1386
    },
    {
      "epoch": 2.957356076759062,
      "grad_norm": 0.18345409631729126,
      "learning_rate": 1.0607772666302308e-08,
      "loss": 0.0402,
      "step": 1387
    },
    {
      "epoch": 2.9594882729211087,
      "grad_norm": 0.21332323551177979,
      "learning_rate": 9.573679892209698e-09,
      "loss": 0.0481,
      "step": 1388
    },
    {
      "epoch": 2.961620469083156,
      "grad_norm": 0.21122866868972778,
      "learning_rate": 8.592584551053718e-09,
      "loss": 0.0493,
      "step": 1389
    },
    {
      "epoch": 2.9637526652452024,
      "grad_norm": 0.19657829403877258,
      "learning_rate": 7.664491847370059e-09,
      "loss": 0.0428,
      "step": 1390
    },
    {
      "epoch": 2.9658848614072495,
      "grad_norm": 0.20239536464214325,
      "learning_rate": 6.789406704527102e-09,
      "loss": 0.0487,
      "step": 1391
    },
    {
      "epoch": 2.9680170575692966,
      "grad_norm": 0.219105064868927,
      "learning_rate": 5.9673337646937166e-09,
      "loss": 0.0511,
      "step": 1392
    },
    {
      "epoch": 2.970149253731343,
      "grad_norm": 0.23137681186199188,
      "learning_rate": 5.198277388821505e-09,
      "loss": 0.0552,
      "step": 1393
    },
    {
      "epoch": 2.9722814498933903,
      "grad_norm": 0.21117311716079712,
      "learning_rate": 4.482241656617036e-09,
      "loss": 0.0506,
      "step": 1394
    },
    {
      "epoch": 2.974413646055437,
      "grad_norm": 0.24182537198066711,
      "learning_rate": 3.8192303665218756e-09,
      "loss": 0.0597,
      "step": 1395
    },
    {
      "epoch": 2.976545842217484,
      "grad_norm": 0.2366107851266861,
      "learning_rate": 3.209247035694807e-09,
      "loss": 0.0526,
      "step": 1396
    },
    {
      "epoch": 2.978678038379531,
      "grad_norm": 0.201553076505661,
      "learning_rate": 2.652294899987418e-09,
      "loss": 0.0469,
      "step": 1397
    },
    {
      "epoch": 2.9808102345415777,
      "grad_norm": 0.19226601719856262,
      "learning_rate": 2.1483769139318823e-09,
      "loss": 0.0429,
      "step": 1398
    },
    {
      "epoch": 2.9829424307036247,
      "grad_norm": 0.21840554475784302,
      "learning_rate": 1.6974957507231993e-09,
      "loss": 0.0508,
      "step": 1399
    },
    {
      "epoch": 2.9850746268656714,
      "grad_norm": 0.24508555233478546,
      "learning_rate": 1.2996538022058691e-09,
      "loss": 0.0546,
      "step": 1400
    },
    {
      "epoch": 2.9872068230277184,
      "grad_norm": 0.23340924084186554,
      "learning_rate": 9.548531788605709e-10,
      "loss": 0.0604,
      "step": 1401
    },
    {
      "epoch": 2.9893390191897655,
      "grad_norm": 0.21431541442871094,
      "learning_rate": 6.630957097930601e-10,
      "loss": 0.0509,
      "step": 1402
    },
    {
      "epoch": 2.9914712153518126,
      "grad_norm": 0.2145167738199234,
      "learning_rate": 4.2438294272528767e-10,
      "loss": 0.0508,
      "step": 1403
    },
    {
      "epoch": 2.9936034115138592,
      "grad_norm": 0.2249670773744583,
      "learning_rate": 2.3871614398540685e-10,
      "loss": 0.0551,
      "step": 1404
    },
    {
      "epoch": 2.9957356076759063,
      "grad_norm": 0.20449316501617432,
      "learning_rate": 1.0609629850222291e-10,
      "loss": 0.0444,
      "step": 1405
    },
    {
      "epoch": 2.997867803837953,
      "grad_norm": 0.21091869473457336,
      "learning_rate": 2.6524109801862042e-11,
      "loss": 0.0486,
      "step": 1406
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.20385971665382385,
      "learning_rate": 0.0,
      "loss": 0.0485,
      "step": 1407
    },
    {
      "epoch": 3.0,
      "step": 1407,
      "total_flos": 1.827772655411921e+18,
      "train_loss": 0.2279017355078573,
      "train_runtime": 50547.5084,
      "train_samples_per_second": 3.561,
      "train_steps_per_second": 0.028
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 1407,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.827772655411921e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
