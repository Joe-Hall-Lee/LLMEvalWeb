{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "global_step": 2337,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 2.8169014084507043e-07,
      "loss": 1.1033,
      "step": 1
    },
    {
      "epoch": 0.0,
      "learning_rate": 5.633802816901409e-07,
      "loss": 1.1038,
      "step": 2
    },
    {
      "epoch": 0.0,
      "learning_rate": 8.450704225352114e-07,
      "loss": 1.1073,
      "step": 3
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.1267605633802817e-06,
      "loss": 1.1221,
      "step": 4
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.4084507042253523e-06,
      "loss": 1.1053,
      "step": 5
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.6901408450704227e-06,
      "loss": 1.1106,
      "step": 6
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.971830985915493e-06,
      "loss": 1.0976,
      "step": 7
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.2535211267605635e-06,
      "loss": 1.1087,
      "step": 8
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.535211267605634e-06,
      "loss": 1.0827,
      "step": 9
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.8169014084507046e-06,
      "loss": 1.0504,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 3.0985915492957746e-06,
      "loss": 1.0569,
      "step": 11
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.3802816901408454e-06,
      "loss": 1.0547,
      "step": 12
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.6619718309859158e-06,
      "loss": 1.0506,
      "step": 13
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.943661971830986e-06,
      "loss": 1.0035,
      "step": 14
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.225352112676057e-06,
      "loss": 0.9916,
      "step": 15
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.507042253521127e-06,
      "loss": 0.9706,
      "step": 16
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.788732394366197e-06,
      "loss": 0.9491,
      "step": 17
    },
    {
      "epoch": 0.02,
      "learning_rate": 5.070422535211268e-06,
      "loss": 0.9505,
      "step": 18
    },
    {
      "epoch": 0.02,
      "learning_rate": 5.352112676056338e-06,
      "loss": 0.9173,
      "step": 19
    },
    {
      "epoch": 0.03,
      "learning_rate": 5.633802816901409e-06,
      "loss": 0.8968,
      "step": 20
    },
    {
      "epoch": 0.03,
      "learning_rate": 5.915492957746479e-06,
      "loss": 0.88,
      "step": 21
    },
    {
      "epoch": 0.03,
      "learning_rate": 6.197183098591549e-06,
      "loss": 0.8751,
      "step": 22
    },
    {
      "epoch": 0.03,
      "learning_rate": 6.478873239436621e-06,
      "loss": 0.8665,
      "step": 23
    },
    {
      "epoch": 0.03,
      "learning_rate": 6.760563380281691e-06,
      "loss": 0.8444,
      "step": 24
    },
    {
      "epoch": 0.03,
      "learning_rate": 7.042253521126761e-06,
      "loss": 0.8356,
      "step": 25
    },
    {
      "epoch": 0.03,
      "learning_rate": 7.3239436619718316e-06,
      "loss": 0.8215,
      "step": 26
    },
    {
      "epoch": 0.03,
      "learning_rate": 7.6056338028169015e-06,
      "loss": 0.8059,
      "step": 27
    },
    {
      "epoch": 0.04,
      "learning_rate": 7.887323943661972e-06,
      "loss": 0.8233,
      "step": 28
    },
    {
      "epoch": 0.04,
      "learning_rate": 8.169014084507043e-06,
      "loss": 0.7909,
      "step": 29
    },
    {
      "epoch": 0.04,
      "learning_rate": 8.450704225352114e-06,
      "loss": 0.8007,
      "step": 30
    },
    {
      "epoch": 0.04,
      "learning_rate": 8.732394366197183e-06,
      "loss": 0.8084,
      "step": 31
    },
    {
      "epoch": 0.04,
      "learning_rate": 9.014084507042254e-06,
      "loss": 0.7786,
      "step": 32
    },
    {
      "epoch": 0.04,
      "learning_rate": 9.295774647887325e-06,
      "loss": 0.7776,
      "step": 33
    },
    {
      "epoch": 0.04,
      "learning_rate": 9.577464788732394e-06,
      "loss": 0.7667,
      "step": 34
    },
    {
      "epoch": 0.04,
      "learning_rate": 9.859154929577466e-06,
      "loss": 0.7635,
      "step": 35
    },
    {
      "epoch": 0.05,
      "learning_rate": 1.0140845070422535e-05,
      "loss": 0.747,
      "step": 36
    },
    {
      "epoch": 0.05,
      "learning_rate": 1.0422535211267606e-05,
      "loss": 0.7282,
      "step": 37
    },
    {
      "epoch": 0.05,
      "learning_rate": 1.0704225352112675e-05,
      "loss": 0.7272,
      "step": 38
    },
    {
      "epoch": 0.05,
      "learning_rate": 1.0985915492957748e-05,
      "loss": 0.7025,
      "step": 39
    },
    {
      "epoch": 0.05,
      "learning_rate": 1.1267605633802819e-05,
      "loss": 0.7023,
      "step": 40
    },
    {
      "epoch": 0.05,
      "learning_rate": 1.1549295774647888e-05,
      "loss": 0.702,
      "step": 41
    },
    {
      "epoch": 0.05,
      "learning_rate": 1.1830985915492958e-05,
      "loss": 0.7109,
      "step": 42
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.211267605633803e-05,
      "loss": 0.6884,
      "step": 43
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.2394366197183098e-05,
      "loss": 0.7041,
      "step": 44
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.2676056338028171e-05,
      "loss": 0.6714,
      "step": 45
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.2957746478873242e-05,
      "loss": 0.6829,
      "step": 46
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.323943661971831e-05,
      "loss": 0.7008,
      "step": 47
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.3521126760563382e-05,
      "loss": 0.675,
      "step": 48
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.380281690140845e-05,
      "loss": 0.6646,
      "step": 49
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.4084507042253522e-05,
      "loss": 0.6561,
      "step": 50
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.4366197183098594e-05,
      "loss": 0.6508,
      "step": 51
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.4647887323943663e-05,
      "loss": 0.6579,
      "step": 52
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.4929577464788734e-05,
      "loss": 0.6596,
      "step": 53
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.5211267605633803e-05,
      "loss": 0.6581,
      "step": 54
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.5492957746478872e-05,
      "loss": 0.6406,
      "step": 55
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.5774647887323945e-05,
      "loss": 0.622,
      "step": 56
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.6056338028169017e-05,
      "loss": 0.6356,
      "step": 57
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.6338028169014086e-05,
      "loss": 0.6555,
      "step": 58
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.6619718309859155e-05,
      "loss": 0.6172,
      "step": 59
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.6901408450704228e-05,
      "loss": 0.6437,
      "step": 60
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.7183098591549297e-05,
      "loss": 0.6394,
      "step": 61
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.7464788732394366e-05,
      "loss": 0.65,
      "step": 62
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.774647887323944e-05,
      "loss": 0.6336,
      "step": 63
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.8028169014084508e-05,
      "loss": 0.6124,
      "step": 64
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.830985915492958e-05,
      "loss": 0.6195,
      "step": 65
    },
    {
      "epoch": 0.08,
      "learning_rate": 1.859154929577465e-05,
      "loss": 0.6445,
      "step": 66
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.887323943661972e-05,
      "loss": 0.5972,
      "step": 67
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.9154929577464788e-05,
      "loss": 0.6166,
      "step": 68
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.943661971830986e-05,
      "loss": 0.649,
      "step": 69
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.9718309859154933e-05,
      "loss": 0.6138,
      "step": 70
    },
    {
      "epoch": 0.09,
      "learning_rate": 2e-05,
      "loss": 0.6212,
      "step": 71
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.9999990389414007e-05,
      "loss": 0.5942,
      "step": 72
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.9999961557674493e-05,
      "loss": 0.608,
      "step": 73
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.999991350483688e-05,
      "loss": 0.6112,
      "step": 74
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.9999846230993535e-05,
      "loss": 0.6302,
      "step": 75
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.999975973627376e-05,
      "loss": 0.6149,
      "step": 76
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.999965402084381e-05,
      "loss": 0.6054,
      "step": 77
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.999952908490688e-05,
      "loss": 0.6031,
      "step": 78
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.9999384928703122e-05,
      "loss": 0.5993,
      "step": 79
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.9999221552509604e-05,
      "loss": 0.5934,
      "step": 80
    },
    {
      "epoch": 0.1,
      "learning_rate": 1.999903895664037e-05,
      "loss": 0.6011,
      "step": 81
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.9998837141446378e-05,
      "loss": 0.5909,
      "step": 82
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.9998616107315553e-05,
      "loss": 0.5959,
      "step": 83
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.9998375854672737e-05,
      "loss": 0.5865,
      "step": 84
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.999811638397973e-05,
      "loss": 0.5849,
      "step": 85
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.9997837695735266e-05,
      "loss": 0.5837,
      "step": 86
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.9997539790475012e-05,
      "loss": 0.5784,
      "step": 87
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.999722266877158e-05,
      "loss": 0.5932,
      "step": 88
    },
    {
      "epoch": 0.11,
      "learning_rate": 1.9996886331234514e-05,
      "loss": 0.5749,
      "step": 89
    },
    {
      "epoch": 0.12,
      "learning_rate": 1.9996530778510295e-05,
      "loss": 0.5889,
      "step": 90
    },
    {
      "epoch": 0.12,
      "learning_rate": 1.9996156011282336e-05,
      "loss": 0.6069,
      "step": 91
    },
    {
      "epoch": 0.12,
      "learning_rate": 1.9995762030270984e-05,
      "loss": 0.5873,
      "step": 92
    },
    {
      "epoch": 0.12,
      "learning_rate": 1.9995348836233517e-05,
      "loss": 0.5869,
      "step": 93
    },
    {
      "epoch": 0.12,
      "learning_rate": 1.999491642996414e-05,
      "loss": 0.5911,
      "step": 94
    },
    {
      "epoch": 0.12,
      "learning_rate": 1.9994464812293993e-05,
      "loss": 0.5952,
      "step": 95
    },
    {
      "epoch": 0.12,
      "learning_rate": 1.9993993984091135e-05,
      "loss": 0.6033,
      "step": 96
    },
    {
      "epoch": 0.12,
      "learning_rate": 1.9993503946260552e-05,
      "loss": 0.5875,
      "step": 97
    },
    {
      "epoch": 0.13,
      "learning_rate": 1.999299469974416e-05,
      "loss": 0.5908,
      "step": 98
    },
    {
      "epoch": 0.13,
      "learning_rate": 1.999246624552078e-05,
      "loss": 0.6163,
      "step": 99
    },
    {
      "epoch": 0.13,
      "learning_rate": 1.9991918584606175e-05,
      "loss": 0.565,
      "step": 100
    },
    {
      "epoch": 0.13,
      "learning_rate": 1.9991351718053003e-05,
      "loss": 0.59,
      "step": 101
    },
    {
      "epoch": 0.13,
      "learning_rate": 1.9990765646950856e-05,
      "loss": 0.585,
      "step": 102
    },
    {
      "epoch": 0.13,
      "learning_rate": 1.9990160372426226e-05,
      "loss": 0.578,
      "step": 103
    },
    {
      "epoch": 0.13,
      "learning_rate": 1.9989535895642523e-05,
      "loss": 0.5563,
      "step": 104
    },
    {
      "epoch": 0.13,
      "learning_rate": 1.9988892217800068e-05,
      "loss": 0.5916,
      "step": 105
    },
    {
      "epoch": 0.14,
      "learning_rate": 1.998822934013608e-05,
      "loss": 0.5689,
      "step": 106
    },
    {
      "epoch": 0.14,
      "learning_rate": 1.998754726392469e-05,
      "loss": 0.5575,
      "step": 107
    },
    {
      "epoch": 0.14,
      "learning_rate": 1.998684599047693e-05,
      "loss": 0.5865,
      "step": 108
    },
    {
      "epoch": 0.14,
      "learning_rate": 1.9986125521140724e-05,
      "loss": 0.5586,
      "step": 109
    },
    {
      "epoch": 0.14,
      "learning_rate": 1.9985385857300907e-05,
      "loss": 0.58,
      "step": 110
    },
    {
      "epoch": 0.14,
      "learning_rate": 1.9984627000379192e-05,
      "loss": 0.5688,
      "step": 111
    },
    {
      "epoch": 0.14,
      "learning_rate": 1.9983848951834197e-05,
      "loss": 0.5657,
      "step": 112
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.9983051713161417e-05,
      "loss": 0.5566,
      "step": 113
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.9982235285893243e-05,
      "loss": 0.5595,
      "step": 114
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.998139967159894e-05,
      "loss": 0.5706,
      "step": 115
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.998054487188466e-05,
      "loss": 0.5741,
      "step": 116
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.9979670888393423e-05,
      "loss": 0.5711,
      "step": 117
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.9978777722805133e-05,
      "loss": 0.5563,
      "step": 118
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.9977865376836557e-05,
      "loss": 0.563,
      "step": 119
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.997693385224133e-05,
      "loss": 0.5655,
      "step": 120
    },
    {
      "epoch": 0.16,
      "learning_rate": 1.9975983150809957e-05,
      "loss": 0.5626,
      "step": 121
    },
    {
      "epoch": 0.16,
      "learning_rate": 1.9975013274369787e-05,
      "loss": 0.5599,
      "step": 122
    },
    {
      "epoch": 0.16,
      "learning_rate": 1.9974024224785046e-05,
      "loss": 0.56,
      "step": 123
    },
    {
      "epoch": 0.16,
      "learning_rate": 1.99730160039568e-05,
      "loss": 0.5555,
      "step": 124
    },
    {
      "epoch": 0.16,
      "learning_rate": 1.9971988613822962e-05,
      "loss": 0.5405,
      "step": 125
    },
    {
      "epoch": 0.16,
      "learning_rate": 1.997094205635831e-05,
      "loss": 0.5732,
      "step": 126
    },
    {
      "epoch": 0.16,
      "learning_rate": 1.9969876333574434e-05,
      "loss": 0.5513,
      "step": 127
    },
    {
      "epoch": 0.16,
      "learning_rate": 1.9968791447519788e-05,
      "loss": 0.5631,
      "step": 128
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.9967687400279646e-05,
      "loss": 0.5723,
      "step": 129
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.996656419397612e-05,
      "loss": 0.5741,
      "step": 130
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.996542183076814e-05,
      "loss": 0.5794,
      "step": 131
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.9964260312851465e-05,
      "loss": 0.5724,
      "step": 132
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.9963079642458666e-05,
      "loss": 0.5496,
      "step": 133
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.996187982185913e-05,
      "loss": 0.5598,
      "step": 134
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.996066085335906e-05,
      "loss": 0.571,
      "step": 135
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.995942273930145e-05,
      "loss": 0.5687,
      "step": 136
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.9958165482066094e-05,
      "loss": 0.5707,
      "step": 137
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.99568890840696e-05,
      "loss": 0.5564,
      "step": 138
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.9955593547765345e-05,
      "loss": 0.5435,
      "step": 139
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.995427887564351e-05,
      "loss": 0.5677,
      "step": 140
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.9952945070231042e-05,
      "loss": 0.5411,
      "step": 141
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.9951592134091674e-05,
      "loss": 0.5296,
      "step": 142
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.995022006982591e-05,
      "loss": 0.5366,
      "step": 143
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.9948828880071014e-05,
      "loss": 0.5464,
      "step": 144
    },
    {
      "epoch": 0.19,
      "learning_rate": 1.9947418567501017e-05,
      "loss": 0.5689,
      "step": 145
    },
    {
      "epoch": 0.19,
      "learning_rate": 1.9945989134826708e-05,
      "loss": 0.5429,
      "step": 146
    },
    {
      "epoch": 0.19,
      "learning_rate": 1.994454058479562e-05,
      "loss": 0.5568,
      "step": 147
    },
    {
      "epoch": 0.19,
      "learning_rate": 1.9943072920192042e-05,
      "loss": 0.5392,
      "step": 148
    },
    {
      "epoch": 0.19,
      "learning_rate": 1.994158614383699e-05,
      "loss": 0.5406,
      "step": 149
    },
    {
      "epoch": 0.19,
      "learning_rate": 1.9940080258588223e-05,
      "loss": 0.5426,
      "step": 150
    },
    {
      "epoch": 0.19,
      "learning_rate": 1.9938555267340237e-05,
      "loss": 0.5472,
      "step": 151
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.9937011173024236e-05,
      "loss": 0.5594,
      "step": 152
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.9935447978608153e-05,
      "loss": 0.5599,
      "step": 153
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.9933865687096633e-05,
      "loss": 0.5586,
      "step": 154
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.993226430153102e-05,
      "loss": 0.5295,
      "step": 155
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.993064382498937e-05,
      "loss": 0.5655,
      "step": 156
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.9929004260586423e-05,
      "loss": 0.5406,
      "step": 157
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.9927345611473625e-05,
      "loss": 0.5361,
      "step": 158
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.992566788083908e-05,
      "loss": 0.5277,
      "step": 159
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.9923971071907593e-05,
      "loss": 0.5413,
      "step": 160
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.9922255187940627e-05,
      "loss": 0.5352,
      "step": 161
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.992052023223631e-05,
      "loss": 0.5445,
      "step": 162
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.9918766208129433e-05,
      "loss": 0.5353,
      "step": 163
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.9916993118991432e-05,
      "loss": 0.5464,
      "step": 164
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.9915200968230398e-05,
      "loss": 0.5529,
      "step": 165
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.9913389759291052e-05,
      "loss": 0.5433,
      "step": 166
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.9911559495654745e-05,
      "loss": 0.5433,
      "step": 167
    },
    {
      "epoch": 0.22,
      "learning_rate": 1.9909710180839465e-05,
      "loss": 0.5445,
      "step": 168
    },
    {
      "epoch": 0.22,
      "learning_rate": 1.990784181839981e-05,
      "loss": 0.5426,
      "step": 169
    },
    {
      "epoch": 0.22,
      "learning_rate": 1.9905954411926992e-05,
      "loss": 0.5394,
      "step": 170
    },
    {
      "epoch": 0.22,
      "learning_rate": 1.9904047965048824e-05,
      "loss": 0.5375,
      "step": 171
    },
    {
      "epoch": 0.22,
      "learning_rate": 1.9902122481429723e-05,
      "loss": 0.5248,
      "step": 172
    },
    {
      "epoch": 0.22,
      "learning_rate": 1.9900177964770696e-05,
      "loss": 0.5364,
      "step": 173
    },
    {
      "epoch": 0.22,
      "learning_rate": 1.989821441880933e-05,
      "loss": 0.5397,
      "step": 174
    },
    {
      "epoch": 0.22,
      "learning_rate": 1.9896231847319786e-05,
      "loss": 0.5441,
      "step": 175
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.9894230254112807e-05,
      "loss": 0.5354,
      "step": 176
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.9892209643035687e-05,
      "loss": 0.5406,
      "step": 177
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.9890170017972273e-05,
      "loss": 0.5334,
      "step": 178
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.9888111382842968e-05,
      "loss": 0.5345,
      "step": 179
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.9886033741604707e-05,
      "loss": 0.5336,
      "step": 180
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.9883937098250962e-05,
      "loss": 0.54,
      "step": 181
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.9881821456811727e-05,
      "loss": 0.5246,
      "step": 182
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.9879686821353514e-05,
      "loss": 0.5253,
      "step": 183
    },
    {
      "epoch": 0.24,
      "learning_rate": 1.987753319597934e-05,
      "loss": 0.5343,
      "step": 184
    },
    {
      "epoch": 0.24,
      "learning_rate": 1.9875360584828725e-05,
      "loss": 0.5512,
      "step": 185
    },
    {
      "epoch": 0.24,
      "learning_rate": 1.9873168992077687e-05,
      "loss": 0.5505,
      "step": 186
    },
    {
      "epoch": 0.24,
      "learning_rate": 1.9870958421938717e-05,
      "loss": 0.54,
      "step": 187
    },
    {
      "epoch": 0.24,
      "learning_rate": 1.9868728878660797e-05,
      "loss": 0.5501,
      "step": 188
    },
    {
      "epoch": 0.24,
      "learning_rate": 1.9866480366529366e-05,
      "loss": 0.5448,
      "step": 189
    },
    {
      "epoch": 0.24,
      "learning_rate": 1.9864212889866327e-05,
      "loss": 0.5386,
      "step": 190
    },
    {
      "epoch": 0.25,
      "learning_rate": 1.986192645303004e-05,
      "loss": 0.5161,
      "step": 191
    },
    {
      "epoch": 0.25,
      "learning_rate": 1.9859621060415302e-05,
      "loss": 0.5405,
      "step": 192
    },
    {
      "epoch": 0.25,
      "learning_rate": 1.9857296716453348e-05,
      "loss": 0.5351,
      "step": 193
    },
    {
      "epoch": 0.25,
      "learning_rate": 1.985495342561184e-05,
      "loss": 0.5315,
      "step": 194
    },
    {
      "epoch": 0.25,
      "learning_rate": 1.9852591192394856e-05,
      "loss": 0.5322,
      "step": 195
    },
    {
      "epoch": 0.25,
      "learning_rate": 1.985021002134289e-05,
      "loss": 0.5239,
      "step": 196
    },
    {
      "epoch": 0.25,
      "learning_rate": 1.9847809917032825e-05,
      "loss": 0.5353,
      "step": 197
    },
    {
      "epoch": 0.25,
      "learning_rate": 1.9845390884077948e-05,
      "loss": 0.5143,
      "step": 198
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.984295292712792e-05,
      "loss": 0.522,
      "step": 199
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.9840496050868784e-05,
      "loss": 0.5375,
      "step": 200
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.983802026002294e-05,
      "loss": 0.5233,
      "step": 201
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.9835525559349152e-05,
      "loss": 0.5251,
      "step": 202
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.9833011953642525e-05,
      "loss": 0.5349,
      "step": 203
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.9830479447734503e-05,
      "loss": 0.5237,
      "step": 204
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.9827928046492863e-05,
      "loss": 0.5134,
      "step": 205
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.9825357754821692e-05,
      "loss": 0.5448,
      "step": 206
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.9822768577661395e-05,
      "loss": 0.5115,
      "step": 207
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.9820160519988672e-05,
      "loss": 0.5374,
      "step": 208
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.9817533586816516e-05,
      "loss": 0.54,
      "step": 209
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.9814887783194202e-05,
      "loss": 0.5276,
      "step": 210
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.9812223114207278e-05,
      "loss": 0.5445,
      "step": 211
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.9809539584977542e-05,
      "loss": 0.5219,
      "step": 212
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.9806837200663053e-05,
      "loss": 0.5248,
      "step": 213
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.9804115966458118e-05,
      "loss": 0.5346,
      "step": 214
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.980137588759326e-05,
      "loss": 0.5155,
      "step": 215
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.9798616969335236e-05,
      "loss": 0.5195,
      "step": 216
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.979583921698701e-05,
      "loss": 0.5397,
      "step": 217
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.9793042635887745e-05,
      "loss": 0.5283,
      "step": 218
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.97902272314128e-05,
      "loss": 0.534,
      "step": 219
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.9787393008973708e-05,
      "loss": 0.5313,
      "step": 220
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.9784539974018182e-05,
      "loss": 0.5258,
      "step": 221
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.9781668132030088e-05,
      "loss": 0.5522,
      "step": 222
    },
    {
      "epoch": 0.29,
      "learning_rate": 1.9778777488529445e-05,
      "loss": 0.5201,
      "step": 223
    },
    {
      "epoch": 0.29,
      "learning_rate": 1.97758680490724e-05,
      "loss": 0.5243,
      "step": 224
    },
    {
      "epoch": 0.29,
      "learning_rate": 1.9772939819251247e-05,
      "loss": 0.5211,
      "step": 225
    },
    {
      "epoch": 0.29,
      "learning_rate": 1.9769992804694385e-05,
      "loss": 0.5143,
      "step": 226
    },
    {
      "epoch": 0.29,
      "learning_rate": 1.976702701106632e-05,
      "loss": 0.5283,
      "step": 227
    },
    {
      "epoch": 0.29,
      "learning_rate": 1.976404244406765e-05,
      "loss": 0.5012,
      "step": 228
    },
    {
      "epoch": 0.29,
      "learning_rate": 1.9761039109435067e-05,
      "loss": 0.5422,
      "step": 229
    },
    {
      "epoch": 0.3,
      "learning_rate": 1.975801701294133e-05,
      "loss": 0.5146,
      "step": 230
    },
    {
      "epoch": 0.3,
      "learning_rate": 1.975497616039527e-05,
      "loss": 0.5273,
      "step": 231
    },
    {
      "epoch": 0.3,
      "learning_rate": 1.9751916557641752e-05,
      "loss": 0.522,
      "step": 232
    },
    {
      "epoch": 0.3,
      "learning_rate": 1.9748838210561695e-05,
      "loss": 0.5243,
      "step": 233
    },
    {
      "epoch": 0.3,
      "learning_rate": 1.9745741125072047e-05,
      "loss": 0.5218,
      "step": 234
    },
    {
      "epoch": 0.3,
      "learning_rate": 1.9742625307125762e-05,
      "loss": 0.5073,
      "step": 235
    },
    {
      "epoch": 0.3,
      "learning_rate": 1.9739490762711812e-05,
      "loss": 0.5174,
      "step": 236
    },
    {
      "epoch": 0.3,
      "learning_rate": 1.973633749785516e-05,
      "loss": 0.5157,
      "step": 237
    },
    {
      "epoch": 0.31,
      "learning_rate": 1.9733165518616746e-05,
      "loss": 0.526,
      "step": 238
    },
    {
      "epoch": 0.31,
      "learning_rate": 1.972997483109349e-05,
      "loss": 0.5129,
      "step": 239
    },
    {
      "epoch": 0.31,
      "learning_rate": 1.9726765441418264e-05,
      "loss": 0.5264,
      "step": 240
    },
    {
      "epoch": 0.31,
      "learning_rate": 1.972353735575989e-05,
      "loss": 0.5232,
      "step": 241
    },
    {
      "epoch": 0.31,
      "learning_rate": 1.972029058032313e-05,
      "loss": 0.5325,
      "step": 242
    },
    {
      "epoch": 0.31,
      "learning_rate": 1.971702512134867e-05,
      "loss": 0.5249,
      "step": 243
    },
    {
      "epoch": 0.31,
      "learning_rate": 1.97137409851131e-05,
      "loss": 0.5279,
      "step": 244
    },
    {
      "epoch": 0.31,
      "learning_rate": 1.9710438177928914e-05,
      "loss": 0.5184,
      "step": 245
    },
    {
      "epoch": 0.32,
      "learning_rate": 1.9707116706144497e-05,
      "loss": 0.5215,
      "step": 246
    },
    {
      "epoch": 0.32,
      "learning_rate": 1.9703776576144106e-05,
      "loss": 0.5506,
      "step": 247
    },
    {
      "epoch": 0.32,
      "learning_rate": 1.9700417794347866e-05,
      "loss": 0.5193,
      "step": 248
    },
    {
      "epoch": 0.32,
      "learning_rate": 1.9697040367211745e-05,
      "loss": 0.5286,
      "step": 249
    },
    {
      "epoch": 0.32,
      "learning_rate": 1.9693644301227553e-05,
      "loss": 0.5499,
      "step": 250
    },
    {
      "epoch": 0.32,
      "learning_rate": 1.9690229602922933e-05,
      "loss": 0.5327,
      "step": 251
    },
    {
      "epoch": 0.32,
      "learning_rate": 1.9686796278861324e-05,
      "loss": 0.4914,
      "step": 252
    },
    {
      "epoch": 0.32,
      "learning_rate": 1.9683344335641988e-05,
      "loss": 0.4979,
      "step": 253
    },
    {
      "epoch": 0.33,
      "learning_rate": 1.9679873779899962e-05,
      "loss": 0.5211,
      "step": 254
    },
    {
      "epoch": 0.33,
      "learning_rate": 1.967638461830606e-05,
      "loss": 0.5146,
      "step": 255
    },
    {
      "epoch": 0.33,
      "learning_rate": 1.9672876857566856e-05,
      "loss": 0.527,
      "step": 256
    },
    {
      "epoch": 0.33,
      "learning_rate": 1.9669350504424683e-05,
      "loss": 0.5142,
      "step": 257
    },
    {
      "epoch": 0.33,
      "learning_rate": 1.9665805565657602e-05,
      "loss": 0.5267,
      "step": 258
    },
    {
      "epoch": 0.33,
      "learning_rate": 1.96622420480794e-05,
      "loss": 0.5222,
      "step": 259
    },
    {
      "epoch": 0.33,
      "learning_rate": 1.9658659958539576e-05,
      "loss": 0.5156,
      "step": 260
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.9655059303923328e-05,
      "loss": 0.519,
      "step": 261
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.9651440091151535e-05,
      "loss": 0.5038,
      "step": 262
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.964780232718075e-05,
      "loss": 0.5249,
      "step": 263
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.9644146019003174e-05,
      "loss": 0.5084,
      "step": 264
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.964047117364667e-05,
      "loss": 0.5167,
      "step": 265
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.9636777798174713e-05,
      "loss": 0.5325,
      "step": 266
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.963306589968641e-05,
      "loss": 0.4981,
      "step": 267
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.962933548531646e-05,
      "loss": 0.5352,
      "step": 268
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.962558656223516e-05,
      "loss": 0.5122,
      "step": 269
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.9621819137648378e-05,
      "loss": 0.5141,
      "step": 270
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.9618033218797546e-05,
      "loss": 0.5206,
      "step": 271
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.9614228812959647e-05,
      "loss": 0.4967,
      "step": 272
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.961040592744719e-05,
      "loss": 0.5209,
      "step": 273
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.9606564569608208e-05,
      "loss": 0.5243,
      "step": 274
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.9602704746826245e-05,
      "loss": 0.5239,
      "step": 275
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.959882646652033e-05,
      "loss": 0.5121,
      "step": 276
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.9594929736144978e-05,
      "loss": 0.5158,
      "step": 277
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.959101456319015e-05,
      "loss": 0.5184,
      "step": 278
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.958708095518128e-05,
      "loss": 0.5358,
      "step": 279
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.9583128919679218e-05,
      "loss": 0.4913,
      "step": 280
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.9579158464280238e-05,
      "loss": 0.5255,
      "step": 281
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.957516959661602e-05,
      "loss": 0.5074,
      "step": 282
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.9571162324353638e-05,
      "loss": 0.5186,
      "step": 283
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.956713665519554e-05,
      "loss": 0.5071,
      "step": 284
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.956309259687953e-05,
      "loss": 0.4967,
      "step": 285
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.9559030157178763e-05,
      "loss": 0.5225,
      "step": 286
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.9554949343901728e-05,
      "loss": 0.5198,
      "step": 287
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.955085016489222e-05,
      "loss": 0.5422,
      "step": 288
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.954673262802935e-05,
      "loss": 0.5097,
      "step": 289
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.9542596741227498e-05,
      "loss": 0.5057,
      "step": 290
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.953844251243633e-05,
      "loss": 0.5183,
      "step": 291
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.9534269949640755e-05,
      "loss": 0.5036,
      "step": 292
    },
    {
      "epoch": 0.38,
      "learning_rate": 1.953007906086093e-05,
      "loss": 0.5044,
      "step": 293
    },
    {
      "epoch": 0.38,
      "learning_rate": 1.9525869854152233e-05,
      "loss": 0.5222,
      "step": 294
    },
    {
      "epoch": 0.38,
      "learning_rate": 1.9521642337605257e-05,
      "loss": 0.5025,
      "step": 295
    },
    {
      "epoch": 0.38,
      "learning_rate": 1.951739651934578e-05,
      "loss": 0.4989,
      "step": 296
    },
    {
      "epoch": 0.38,
      "learning_rate": 1.9513132407534763e-05,
      "loss": 0.5225,
      "step": 297
    },
    {
      "epoch": 0.38,
      "learning_rate": 1.950885001036833e-05,
      "loss": 0.5022,
      "step": 298
    },
    {
      "epoch": 0.38,
      "learning_rate": 1.9504549336077747e-05,
      "loss": 0.5099,
      "step": 299
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.9500230392929418e-05,
      "loss": 0.5222,
      "step": 300
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.9495893189224858e-05,
      "loss": 0.5227,
      "step": 301
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.9491537733300677e-05,
      "loss": 0.5189,
      "step": 302
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.9487164033528576e-05,
      "loss": 0.5263,
      "step": 303
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.9482772098315313e-05,
      "loss": 0.5243,
      "step": 304
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.9478361936102713e-05,
      "loss": 0.4892,
      "step": 305
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.947393355536761e-05,
      "loss": 0.5054,
      "step": 306
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.9469486964621878e-05,
      "loss": 0.5024,
      "step": 307
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.9465022172412392e-05,
      "loss": 0.5241,
      "step": 308
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.9460539187320995e-05,
      "loss": 0.5129,
      "step": 309
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.9456038017964517e-05,
      "loss": 0.5111,
      "step": 310
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.945151867299473e-05,
      "loss": 0.5096,
      "step": 311
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.944698116109834e-05,
      "loss": 0.5084,
      "step": 312
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.9442425490996987e-05,
      "loss": 0.4973,
      "step": 313
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.9437851671447197e-05,
      "loss": 0.5234,
      "step": 314
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.943325971124039e-05,
      "loss": 0.529,
      "step": 315
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.9428649619202843e-05,
      "loss": 0.5026,
      "step": 316
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.9424021404195703e-05,
      "loss": 0.4974,
      "step": 317
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.941937507511494e-05,
      "loss": 0.503,
      "step": 318
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.941471064089134e-05,
      "loss": 0.4946,
      "step": 319
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.9410028110490493e-05,
      "loss": 0.5166,
      "step": 320
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.9405327492912774e-05,
      "loss": 0.5054,
      "step": 321
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.9400608797193316e-05,
      "loss": 0.5274,
      "step": 322
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.9395872032402007e-05,
      "loss": 0.5101,
      "step": 323
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.939111720764347e-05,
      "loss": 0.5052,
      "step": 324
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.9386344332057025e-05,
      "loss": 0.5288,
      "step": 325
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.9381553414816706e-05,
      "loss": 0.4916,
      "step": 326
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.9376744465131217e-05,
      "loss": 0.4979,
      "step": 327
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.937191749224392e-05,
      "loss": 0.4926,
      "step": 328
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.9367072505432823e-05,
      "loss": 0.4975,
      "step": 329
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.936220951401056e-05,
      "loss": 0.5024,
      "step": 330
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.935732852732437e-05,
      "loss": 0.5208,
      "step": 331
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.9352429554756078e-05,
      "loss": 0.5072,
      "step": 332
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.934751260572209e-05,
      "loss": 0.4941,
      "step": 333
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.9342577689673356e-05,
      "loss": 0.5107,
      "step": 334
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.933762481609536e-05,
      "loss": 0.5133,
      "step": 335
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.9332653994508102e-05,
      "loss": 0.5078,
      "step": 336
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.9327665234466095e-05,
      "loss": 0.5126,
      "step": 337
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.932265854555831e-05,
      "loss": 0.512,
      "step": 338
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.9317633937408198e-05,
      "loss": 0.5107,
      "step": 339
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.9312591419673642e-05,
      "loss": 0.5071,
      "step": 340
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.9307531002046946e-05,
      "loss": 0.5039,
      "step": 341
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.9302452694254837e-05,
      "loss": 0.5083,
      "step": 342
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.9297356506058407e-05,
      "loss": 0.5058,
      "step": 343
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.9292242447253135e-05,
      "loss": 0.5126,
      "step": 344
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.9287110527668832e-05,
      "loss": 0.4922,
      "step": 345
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.928196075716966e-05,
      "loss": 0.5055,
      "step": 346
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.9276793145654077e-05,
      "loss": 0.5083,
      "step": 347
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.9271607703054832e-05,
      "loss": 0.5185,
      "step": 348
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.9266404439338964e-05,
      "loss": 0.5237,
      "step": 349
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.926118336450775e-05,
      "loss": 0.4988,
      "step": 350
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.925594448859671e-05,
      "loss": 0.5002,
      "step": 351
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.925068782167557e-05,
      "loss": 0.5056,
      "step": 352
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.9245413373848267e-05,
      "loss": 0.496,
      "step": 353
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.9240121155252906e-05,
      "loss": 0.5026,
      "step": 354
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.9234811176061755e-05,
      "loss": 0.4782,
      "step": 355
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.9229483446481207e-05,
      "loss": 0.4926,
      "step": 356
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.9224137976751797e-05,
      "loss": 0.5003,
      "step": 357
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.921877477714813e-05,
      "loss": 0.5114,
      "step": 358
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.9213393857978912e-05,
      "loss": 0.4882,
      "step": 359
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.9207995229586897e-05,
      "loss": 0.4996,
      "step": 360
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.9202578902348886e-05,
      "loss": 0.4837,
      "step": 361
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.9197144886675688e-05,
      "loss": 0.498,
      "step": 362
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.9191693193012126e-05,
      "loss": 0.5063,
      "step": 363
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.918622383183699e-05,
      "loss": 0.4838,
      "step": 364
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.9180736813663027e-05,
      "loss": 0.4808,
      "step": 365
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.917523214903694e-05,
      "loss": 0.4899,
      "step": 366
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.9169709848539333e-05,
      "loss": 0.4913,
      "step": 367
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.9164169922784717e-05,
      "loss": 0.49,
      "step": 368
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.9158612382421477e-05,
      "loss": 0.5055,
      "step": 369
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.915303723813186e-05,
      "loss": 0.5107,
      "step": 370
    },
    {
      "epoch": 0.48,
      "learning_rate": 1.914744450063194e-05,
      "loss": 0.5288,
      "step": 371
    },
    {
      "epoch": 0.48,
      "learning_rate": 1.9141834180671623e-05,
      "loss": 0.5021,
      "step": 372
    },
    {
      "epoch": 0.48,
      "learning_rate": 1.91362062890346e-05,
      "loss": 0.5068,
      "step": 373
    },
    {
      "epoch": 0.48,
      "learning_rate": 1.913056083653833e-05,
      "loss": 0.4972,
      "step": 374
    },
    {
      "epoch": 0.48,
      "learning_rate": 1.912489783403404e-05,
      "loss": 0.5046,
      "step": 375
    },
    {
      "epoch": 0.48,
      "learning_rate": 1.9119217292406685e-05,
      "loss": 0.5038,
      "step": 376
    },
    {
      "epoch": 0.48,
      "learning_rate": 1.911351922257493e-05,
      "loss": 0.4917,
      "step": 377
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.9107803635491136e-05,
      "loss": 0.4881,
      "step": 378
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.910207054214133e-05,
      "loss": 0.4924,
      "step": 379
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.9096319953545186e-05,
      "loss": 0.5094,
      "step": 380
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.909055188075601e-05,
      "loss": 0.5019,
      "step": 381
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.908476633486072e-05,
      "loss": 0.48,
      "step": 382
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.9078963326979807e-05,
      "loss": 0.5021,
      "step": 383
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.9073142868267335e-05,
      "loss": 0.4983,
      "step": 384
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.9067304969910906e-05,
      "loss": 0.499,
      "step": 385
    },
    {
      "epoch": 0.5,
      "learning_rate": 1.9061449643131647e-05,
      "loss": 0.5033,
      "step": 386
    },
    {
      "epoch": 0.5,
      "learning_rate": 1.905557689918418e-05,
      "loss": 0.4994,
      "step": 387
    },
    {
      "epoch": 0.5,
      "learning_rate": 1.904968674935661e-05,
      "loss": 0.5174,
      "step": 388
    },
    {
      "epoch": 0.5,
      "learning_rate": 1.9043779204970492e-05,
      "loss": 0.5001,
      "step": 389
    },
    {
      "epoch": 0.5,
      "learning_rate": 1.903785427738082e-05,
      "loss": 0.4976,
      "step": 390
    },
    {
      "epoch": 0.5,
      "learning_rate": 1.9031911977976e-05,
      "loss": 0.4918,
      "step": 391
    },
    {
      "epoch": 0.5,
      "learning_rate": 1.9025952318177826e-05,
      "loss": 0.5007,
      "step": 392
    },
    {
      "epoch": 0.5,
      "learning_rate": 1.9019975309441467e-05,
      "loss": 0.494,
      "step": 393
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.9013980963255432e-05,
      "loss": 0.4985,
      "step": 394
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.900796929114155e-05,
      "loss": 0.4968,
      "step": 395
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.9001940304654974e-05,
      "loss": 0.4859,
      "step": 396
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.899589401538411e-05,
      "loss": 0.493,
      "step": 397
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.8989830434950637e-05,
      "loss": 0.5033,
      "step": 398
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.8983749575009468e-05,
      "loss": 0.4823,
      "step": 399
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.8977651447248733e-05,
      "loss": 0.4996,
      "step": 400
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.8971536063389745e-05,
      "loss": 0.4975,
      "step": 401
    },
    {
      "epoch": 0.52,
      "learning_rate": 1.8965403435186983e-05,
      "loss": 0.4829,
      "step": 402
    },
    {
      "epoch": 0.52,
      "learning_rate": 1.895925357442809e-05,
      "loss": 0.4839,
      "step": 403
    },
    {
      "epoch": 0.52,
      "learning_rate": 1.8953086492933807e-05,
      "loss": 0.4944,
      "step": 404
    },
    {
      "epoch": 0.52,
      "learning_rate": 1.8946902202557994e-05,
      "loss": 0.4976,
      "step": 405
    },
    {
      "epoch": 0.52,
      "learning_rate": 1.8940700715187576e-05,
      "loss": 0.5077,
      "step": 406
    },
    {
      "epoch": 0.52,
      "learning_rate": 1.8934482042742543e-05,
      "loss": 0.5008,
      "step": 407
    },
    {
      "epoch": 0.52,
      "learning_rate": 1.8928246197175916e-05,
      "loss": 0.4805,
      "step": 408
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.8921993190473712e-05,
      "loss": 0.484,
      "step": 409
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.8915723034654952e-05,
      "loss": 0.5044,
      "step": 410
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.8909435741771602e-05,
      "loss": 0.4966,
      "step": 411
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.890313132390858e-05,
      "loss": 0.4956,
      "step": 412
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.8896809793183715e-05,
      "loss": 0.5006,
      "step": 413
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.8890471161747733e-05,
      "loss": 0.5065,
      "step": 414
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.8884115441784222e-05,
      "loss": 0.4928,
      "step": 415
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.8877742645509622e-05,
      "loss": 0.5241,
      "step": 416
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.8871352785173195e-05,
      "loss": 0.502,
      "step": 417
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.8864945873057e-05,
      "loss": 0.5014,
      "step": 418
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.8858521921475878e-05,
      "loss": 0.5017,
      "step": 419
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.885208094277741e-05,
      "loss": 0.5124,
      "step": 420
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.8845622949341918e-05,
      "loss": 0.4822,
      "step": 421
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.8839147953582413e-05,
      "loss": 0.4884,
      "step": 422
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.8832655967944607e-05,
      "loss": 0.5034,
      "step": 423
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.8826147004906853e-05,
      "loss": 0.4912,
      "step": 424
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.881962107698014e-05,
      "loss": 0.4949,
      "step": 425
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.8813078196708065e-05,
      "loss": 0.5007,
      "step": 426
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.8806518376666813e-05,
      "loss": 0.5118,
      "step": 427
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.8799941629465123e-05,
      "loss": 0.4946,
      "step": 428
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.879334796774428e-05,
      "loss": 0.5034,
      "step": 429
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.8786737404178073e-05,
      "loss": 0.4982,
      "step": 430
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.8780109951472775e-05,
      "loss": 0.5108,
      "step": 431
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.877346562236713e-05,
      "loss": 0.5074,
      "step": 432
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.8766804429632318e-05,
      "loss": 0.4904,
      "step": 433
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.8760126386071937e-05,
      "loss": 0.4992,
      "step": 434
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.875343150452196e-05,
      "loss": 0.5077,
      "step": 435
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.8746719797850735e-05,
      "loss": 0.4728,
      "step": 436
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.8739991278958953e-05,
      "loss": 0.5002,
      "step": 437
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.8733245960779615e-05,
      "loss": 0.4873,
      "step": 438
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.872648385627802e-05,
      "loss": 0.5054,
      "step": 439
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.8719704978451705e-05,
      "loss": 0.5051,
      "step": 440
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.871290934033049e-05,
      "loss": 0.5236,
      "step": 441
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.870609695497638e-05,
      "loss": 0.4967,
      "step": 442
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.869926783548357e-05,
      "loss": 0.4911,
      "step": 443
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.869242199497844e-05,
      "loss": 0.4927,
      "step": 444
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.868555944661949e-05,
      "loss": 0.4927,
      "step": 445
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.8678680203597345e-05,
      "loss": 0.4829,
      "step": 446
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.8671784279134716e-05,
      "loss": 0.4916,
      "step": 447
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.8664871686486382e-05,
      "loss": 0.4898,
      "step": 448
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.8657942438939146e-05,
      "loss": 0.5076,
      "step": 449
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.8650996549811845e-05,
      "loss": 0.5088,
      "step": 450
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.8644034032455286e-05,
      "loss": 0.507,
      "step": 451
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.8637054900252243e-05,
      "loss": 0.4793,
      "step": 452
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.863005916661743e-05,
      "loss": 0.4869,
      "step": 453
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.8623046844997463e-05,
      "loss": 0.4887,
      "step": 454
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.8616017948870847e-05,
      "loss": 0.496,
      "step": 455
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.8608972491747946e-05,
      "loss": 0.4927,
      "step": 456
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.8601910487170952e-05,
      "loss": 0.5057,
      "step": 457
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.8594831948713867e-05,
      "loss": 0.5004,
      "step": 458
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.858773688998247e-05,
      "loss": 0.4886,
      "step": 459
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.8580625324614303e-05,
      "loss": 0.4966,
      "step": 460
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.8573497266278613e-05,
      "loss": 0.4904,
      "step": 461
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.8566352728676374e-05,
      "loss": 0.4956,
      "step": 462
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.8559191725540225e-05,
      "loss": 0.4793,
      "step": 463
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.855201427063445e-05,
      "loss": 0.4964,
      "step": 464
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.8544820377754957e-05,
      "loss": 0.4815,
      "step": 465
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.8537610060729255e-05,
      "loss": 0.4832,
      "step": 466
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.853038333341642e-05,
      "loss": 0.4893,
      "step": 467
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.852314020970706e-05,
      "loss": 0.5042,
      "step": 468
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.8515880703523318e-05,
      "loss": 0.4868,
      "step": 469
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.8508604828818807e-05,
      "loss": 0.485,
      "step": 470
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.850131259957862e-05,
      "loss": 0.4872,
      "step": 471
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.8494004029819267e-05,
      "loss": 0.4966,
      "step": 472
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.8486679133588686e-05,
      "loss": 0.501,
      "step": 473
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.8479337924966178e-05,
      "loss": 0.4996,
      "step": 474
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.8471980418062405e-05,
      "loss": 0.5061,
      "step": 475
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.8464606627019364e-05,
      "loss": 0.4945,
      "step": 476
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.845721656601034e-05,
      "loss": 0.4908,
      "step": 477
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.84498102492399e-05,
      "loss": 0.509,
      "step": 478
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.8442387690943853e-05,
      "loss": 0.489,
      "step": 479
    },
    {
      "epoch": 0.62,
      "learning_rate": 1.8434948905389224e-05,
      "loss": 0.4971,
      "step": 480
    },
    {
      "epoch": 0.62,
      "learning_rate": 1.842749390687423e-05,
      "loss": 0.4929,
      "step": 481
    },
    {
      "epoch": 0.62,
      "learning_rate": 1.8420022709728256e-05,
      "loss": 0.4938,
      "step": 482
    },
    {
      "epoch": 0.62,
      "learning_rate": 1.8412535328311813e-05,
      "loss": 0.4906,
      "step": 483
    },
    {
      "epoch": 0.62,
      "learning_rate": 1.8405031777016532e-05,
      "loss": 0.4876,
      "step": 484
    },
    {
      "epoch": 0.62,
      "learning_rate": 1.8397512070265107e-05,
      "loss": 0.4896,
      "step": 485
    },
    {
      "epoch": 0.62,
      "learning_rate": 1.8389976222511313e-05,
      "loss": 0.478,
      "step": 486
    },
    {
      "epoch": 0.63,
      "learning_rate": 1.8382424248239913e-05,
      "loss": 0.4793,
      "step": 487
    },
    {
      "epoch": 0.63,
      "learning_rate": 1.8374856161966705e-05,
      "loss": 0.4994,
      "step": 488
    },
    {
      "epoch": 0.63,
      "learning_rate": 1.8367271978238422e-05,
      "loss": 0.51,
      "step": 489
    },
    {
      "epoch": 0.63,
      "learning_rate": 1.8359671711632763e-05,
      "loss": 0.4854,
      "step": 490
    },
    {
      "epoch": 0.63,
      "learning_rate": 1.835205537675833e-05,
      "loss": 0.4732,
      "step": 491
    },
    {
      "epoch": 0.63,
      "learning_rate": 1.834442298825461e-05,
      "loss": 0.4972,
      "step": 492
    },
    {
      "epoch": 0.63,
      "learning_rate": 1.833677456079195e-05,
      "loss": 0.4908,
      "step": 493
    },
    {
      "epoch": 0.63,
      "learning_rate": 1.8329110109071522e-05,
      "loss": 0.4843,
      "step": 494
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.8321429647825302e-05,
      "loss": 0.4855,
      "step": 495
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.8313733191816033e-05,
      "loss": 0.4797,
      "step": 496
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.830602075583721e-05,
      "loss": 0.4803,
      "step": 497
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.8298292354713036e-05,
      "loss": 0.4745,
      "step": 498
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.8290548003298406e-05,
      "loss": 0.4884,
      "step": 499
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.828278771647887e-05,
      "loss": 0.4677,
      "step": 500
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.8275011509170607e-05,
      "loss": 0.4868,
      "step": 501
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.8267219396320403e-05,
      "loss": 0.4961,
      "step": 502
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.8259411392905604e-05,
      "loss": 0.4912,
      "step": 503
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.8251587513934118e-05,
      "loss": 0.4773,
      "step": 504
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.8243747774444353e-05,
      "loss": 0.4864,
      "step": 505
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.8235892189505205e-05,
      "loss": 0.5076,
      "step": 506
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.822802077421603e-05,
      "loss": 0.511,
      "step": 507
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.8220133543706612e-05,
      "loss": 0.4823,
      "step": 508
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.821223051313713e-05,
      "loss": 0.4998,
      "step": 509
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.820431169769814e-05,
      "loss": 0.4907,
      "step": 510
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.8196377112610524e-05,
      "loss": 0.491,
      "step": 511
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.81884267731255e-05,
      "loss": 0.489,
      "step": 512
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.8180460694524537e-05,
      "loss": 0.476,
      "step": 513
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.8172478892119375e-05,
      "loss": 0.4818,
      "step": 514
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.816448138125198e-05,
      "loss": 0.4886,
      "step": 515
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.81564681772945e-05,
      "loss": 0.4709,
      "step": 516
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.8148439295649255e-05,
      "loss": 0.4817,
      "step": 517
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.814039475174869e-05,
      "loss": 0.4953,
      "step": 518
    },
    {
      "epoch": 0.67,
      "learning_rate": 1.813233456105537e-05,
      "loss": 0.4679,
      "step": 519
    },
    {
      "epoch": 0.67,
      "learning_rate": 1.8124258739061922e-05,
      "loss": 0.4673,
      "step": 520
    },
    {
      "epoch": 0.67,
      "learning_rate": 1.811616730129102e-05,
      "loss": 0.5133,
      "step": 521
    },
    {
      "epoch": 0.67,
      "learning_rate": 1.8108060263295364e-05,
      "loss": 0.4872,
      "step": 522
    },
    {
      "epoch": 0.67,
      "learning_rate": 1.8099937640657622e-05,
      "loss": 0.4739,
      "step": 523
    },
    {
      "epoch": 0.67,
      "learning_rate": 1.809179944899043e-05,
      "loss": 0.4964,
      "step": 524
    },
    {
      "epoch": 0.67,
      "learning_rate": 1.8083645703936347e-05,
      "loss": 0.4806,
      "step": 525
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.8075476421167825e-05,
      "loss": 0.496,
      "step": 526
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.8067291616387185e-05,
      "loss": 0.4933,
      "step": 527
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.805909130532658e-05,
      "loss": 0.4841,
      "step": 528
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.8050875503747968e-05,
      "loss": 0.4869,
      "step": 529
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.804264422744308e-05,
      "loss": 0.4935,
      "step": 530
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.8034397492233404e-05,
      "loss": 0.4896,
      "step": 531
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.802613531397012e-05,
      "loss": 0.4815,
      "step": 532
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.8017857708534107e-05,
      "loss": 0.4879,
      "step": 533
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.8009564691835897e-05,
      "loss": 0.4824,
      "step": 534
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.8001256279815633e-05,
      "loss": 0.4621,
      "step": 535
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.7992932488443063e-05,
      "loss": 0.4703,
      "step": 536
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.7984593333717484e-05,
      "loss": 0.4909,
      "step": 537
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.7976238831667735e-05,
      "loss": 0.4806,
      "step": 538
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.796786899835214e-05,
      "loss": 0.4806,
      "step": 539
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.7959483849858507e-05,
      "loss": 0.501,
      "step": 540
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.795108340230407e-05,
      "loss": 0.4958,
      "step": 541
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.7942667671835475e-05,
      "loss": 0.472,
      "step": 542
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.7934236674628742e-05,
      "loss": 0.4839,
      "step": 543
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.7925790426889237e-05,
      "loss": 0.4754,
      "step": 544
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.7917328944851634e-05,
      "loss": 0.4943,
      "step": 545
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.7908852244779897e-05,
      "loss": 0.4776,
      "step": 546
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.7900360342967235e-05,
      "loss": 0.4868,
      "step": 547
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.7891853255736084e-05,
      "loss": 0.5131,
      "step": 548
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.7883330999438055e-05,
      "loss": 0.4899,
      "step": 549
    },
    {
      "epoch": 0.71,
      "learning_rate": 1.787479359045393e-05,
      "loss": 0.4829,
      "step": 550
    },
    {
      "epoch": 0.71,
      "learning_rate": 1.7866241045193603e-05,
      "loss": 0.4867,
      "step": 551
    },
    {
      "epoch": 0.71,
      "learning_rate": 1.785767338009607e-05,
      "loss": 0.4912,
      "step": 552
    },
    {
      "epoch": 0.71,
      "learning_rate": 1.784909061162939e-05,
      "loss": 0.4934,
      "step": 553
    },
    {
      "epoch": 0.71,
      "learning_rate": 1.7840492756290654e-05,
      "loss": 0.4814,
      "step": 554
    },
    {
      "epoch": 0.71,
      "learning_rate": 1.783187983060594e-05,
      "loss": 0.4771,
      "step": 555
    },
    {
      "epoch": 0.71,
      "learning_rate": 1.7823251851130298e-05,
      "loss": 0.468,
      "step": 556
    },
    {
      "epoch": 0.72,
      "learning_rate": 1.7814608834447727e-05,
      "loss": 0.4899,
      "step": 557
    },
    {
      "epoch": 0.72,
      "learning_rate": 1.7805950797171108e-05,
      "loss": 0.4722,
      "step": 558
    },
    {
      "epoch": 0.72,
      "learning_rate": 1.7797277755942208e-05,
      "loss": 0.4755,
      "step": 559
    },
    {
      "epoch": 0.72,
      "learning_rate": 1.7788589727431632e-05,
      "loss": 0.4907,
      "step": 560
    },
    {
      "epoch": 0.72,
      "learning_rate": 1.7779886728338783e-05,
      "loss": 0.4837,
      "step": 561
    },
    {
      "epoch": 0.72,
      "learning_rate": 1.7771168775391845e-05,
      "loss": 0.4751,
      "step": 562
    },
    {
      "epoch": 0.72,
      "learning_rate": 1.7762435885347748e-05,
      "loss": 0.5006,
      "step": 563
    },
    {
      "epoch": 0.72,
      "learning_rate": 1.7753688074992133e-05,
      "loss": 0.4694,
      "step": 564
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.7744925361139312e-05,
      "loss": 0.495,
      "step": 565
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.773614776063225e-05,
      "loss": 0.4751,
      "step": 566
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.7727355290342517e-05,
      "loss": 0.466,
      "step": 567
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.771854796717028e-05,
      "loss": 0.4955,
      "step": 568
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.770972580804425e-05,
      "loss": 0.4669,
      "step": 569
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.7700888829921644e-05,
      "loss": 0.4911,
      "step": 570
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.769203704978817e-05,
      "loss": 0.4794,
      "step": 571
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.7683170484657983e-05,
      "loss": 0.4956,
      "step": 572
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.7674289151573667e-05,
      "loss": 0.499,
      "step": 573
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.766539306760618e-05,
      "loss": 0.4913,
      "step": 574
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.7656482249854848e-05,
      "loss": 0.4915,
      "step": 575
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.7647556715447297e-05,
      "loss": 0.4723,
      "step": 576
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.763861648153945e-05,
      "loss": 0.4764,
      "step": 577
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.762966156531549e-05,
      "loss": 0.5026,
      "step": 578
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.762069198398781e-05,
      "loss": 0.4992,
      "step": 579
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.7611707754797004e-05,
      "loss": 0.4684,
      "step": 580
    },
    {
      "epoch": 0.75,
      "learning_rate": 1.7602708895011806e-05,
      "loss": 0.4808,
      "step": 581
    },
    {
      "epoch": 0.75,
      "learning_rate": 1.759369542192908e-05,
      "loss": 0.4642,
      "step": 582
    },
    {
      "epoch": 0.75,
      "learning_rate": 1.758466735287378e-05,
      "loss": 0.4982,
      "step": 583
    },
    {
      "epoch": 0.75,
      "learning_rate": 1.7575624705198917e-05,
      "loss": 0.4743,
      "step": 584
    },
    {
      "epoch": 0.75,
      "learning_rate": 1.7566567496285513e-05,
      "loss": 0.4644,
      "step": 585
    },
    {
      "epoch": 0.75,
      "learning_rate": 1.7557495743542586e-05,
      "loss": 0.4783,
      "step": 586
    },
    {
      "epoch": 0.75,
      "learning_rate": 1.754840946440711e-05,
      "loss": 0.4818,
      "step": 587
    },
    {
      "epoch": 0.75,
      "learning_rate": 1.7539308676343972e-05,
      "loss": 0.4888,
      "step": 588
    },
    {
      "epoch": 0.76,
      "learning_rate": 1.7530193396845965e-05,
      "loss": 0.4913,
      "step": 589
    },
    {
      "epoch": 0.76,
      "learning_rate": 1.7521063643433717e-05,
      "loss": 0.4822,
      "step": 590
    },
    {
      "epoch": 0.76,
      "learning_rate": 1.7511919433655684e-05,
      "loss": 0.4617,
      "step": 591
    },
    {
      "epoch": 0.76,
      "learning_rate": 1.750276078508811e-05,
      "loss": 0.469,
      "step": 592
    },
    {
      "epoch": 0.76,
      "learning_rate": 1.7493587715334993e-05,
      "loss": 0.4805,
      "step": 593
    },
    {
      "epoch": 0.76,
      "learning_rate": 1.7484400242028048e-05,
      "loss": 0.4953,
      "step": 594
    },
    {
      "epoch": 0.76,
      "learning_rate": 1.747519838282667e-05,
      "loss": 0.489,
      "step": 595
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.7465982155417914e-05,
      "loss": 0.4695,
      "step": 596
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.7456751577516453e-05,
      "loss": 0.4726,
      "step": 597
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.7447506666864535e-05,
      "loss": 0.4757,
      "step": 598
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.743824744123196e-05,
      "loss": 0.4856,
      "step": 599
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.742897391841605e-05,
      "loss": 0.4698,
      "step": 600
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.7419686116241605e-05,
      "loss": 0.4901,
      "step": 601
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.741038405256086e-05,
      "loss": 0.4951,
      "step": 602
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.7401067745253477e-05,
      "loss": 0.4878,
      "step": 603
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.739173721222649e-05,
      "loss": 0.4837,
      "step": 604
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.738239247141428e-05,
      "loss": 0.4894,
      "step": 605
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.7373033540778527e-05,
      "loss": 0.4922,
      "step": 606
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.7363660438308198e-05,
      "loss": 0.4834,
      "step": 607
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.7354273182019493e-05,
      "loss": 0.475,
      "step": 608
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.7344871789955816e-05,
      "loss": 0.482,
      "step": 609
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.7335456280187752e-05,
      "loss": 0.4858,
      "step": 610
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.7326026670813005e-05,
      "loss": 0.4678,
      "step": 611
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.7316582979956398e-05,
      "loss": 0.4913,
      "step": 612
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.7307125225769806e-05,
      "loss": 0.4952,
      "step": 613
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.729765342643214e-05,
      "loss": 0.4684,
      "step": 614
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.7288167600149313e-05,
      "loss": 0.4779,
      "step": 615
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.7278667765154193e-05,
      "loss": 0.4812,
      "step": 616
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.7269153939706577e-05,
      "loss": 0.4825,
      "step": 617
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.7259626142093146e-05,
      "loss": 0.4878,
      "step": 618
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.7250084390627454e-05,
      "loss": 0.4779,
      "step": 619
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.7240528703649858e-05,
      "loss": 0.486,
      "step": 620
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.7230959099527512e-05,
      "loss": 0.4735,
      "step": 621
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.7221375596654317e-05,
      "loss": 0.47,
      "step": 622
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.7211778213450886e-05,
      "loss": 0.4828,
      "step": 623
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.7202166968364515e-05,
      "loss": 0.4677,
      "step": 624
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.7192541879869146e-05,
      "loss": 0.4782,
      "step": 625
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.7182902966465325e-05,
      "loss": 0.4779,
      "step": 626
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.7173250246680172e-05,
      "loss": 0.4944,
      "step": 627
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.7163583739067346e-05,
      "loss": 0.4774,
      "step": 628
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.7153903462207014e-05,
      "loss": 0.4811,
      "step": 629
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.714420943470579e-05,
      "loss": 0.4588,
      "step": 630
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.713450167519674e-05,
      "loss": 0.4705,
      "step": 631
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.712478020233932e-05,
      "loss": 0.4766,
      "step": 632
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.711504503481933e-05,
      "loss": 0.4931,
      "step": 633
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.710529619134891e-05,
      "loss": 0.4783,
      "step": 634
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.7095533690666474e-05,
      "loss": 0.4945,
      "step": 635
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.7085757551536692e-05,
      "loss": 0.4862,
      "step": 636
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.7075967792750455e-05,
      "loss": 0.462,
      "step": 637
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.7066164433124823e-05,
      "loss": 0.4943,
      "step": 638
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.7056347491503007e-05,
      "loss": 0.4946,
      "step": 639
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.7046516986754312e-05,
      "loss": 0.4624,
      "step": 640
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.7036672937774126e-05,
      "loss": 0.4652,
      "step": 641
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.7026815363483863e-05,
      "loss": 0.4831,
      "step": 642
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.7016944282830935e-05,
      "loss": 0.4776,
      "step": 643
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.7007059714788715e-05,
      "loss": 0.4815,
      "step": 644
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.6997161678356504e-05,
      "loss": 0.4888,
      "step": 645
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.6987250192559485e-05,
      "loss": 0.494,
      "step": 646
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.69773252764487e-05,
      "loss": 0.4698,
      "step": 647
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.6967386949100998e-05,
      "loss": 0.4755,
      "step": 648
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.6957435229619008e-05,
      "loss": 0.488,
      "step": 649
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.6947470137131105e-05,
      "loss": 0.4849,
      "step": 650
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.6937491690791358e-05,
      "loss": 0.4851,
      "step": 651
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.6927499909779516e-05,
      "loss": 0.4731,
      "step": 652
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.6917494813300953e-05,
      "loss": 0.487,
      "step": 653
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.6907476420586632e-05,
      "loss": 0.4922,
      "step": 654
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.689744475089308e-05,
      "loss": 0.4875,
      "step": 655
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.688739982350235e-05,
      "loss": 0.4883,
      "step": 656
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.687734165772196e-05,
      "loss": 0.4815,
      "step": 657
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.6867270272884883e-05,
      "loss": 0.4845,
      "step": 658
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.6857185688349508e-05,
      "loss": 0.4636,
      "step": 659
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.6847087923499583e-05,
      "loss": 0.4744,
      "step": 660
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.6836976997744197e-05,
      "loss": 0.4812,
      "step": 661
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.682685293051774e-05,
      "loss": 0.5003,
      "step": 662
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.6816715741279842e-05,
      "loss": 0.4691,
      "step": 663
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.680656544951538e-05,
      "loss": 0.4774,
      "step": 664
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.6796402074734404e-05,
      "loss": 0.4713,
      "step": 665
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.678622563647211e-05,
      "loss": 0.4943,
      "step": 666
    },
    {
      "epoch": 0.86,
      "learning_rate": 1.6776036154288798e-05,
      "loss": 0.4882,
      "step": 667
    },
    {
      "epoch": 0.86,
      "learning_rate": 1.6765833647769857e-05,
      "loss": 0.4697,
      "step": 668
    },
    {
      "epoch": 0.86,
      "learning_rate": 1.6755618136525694e-05,
      "loss": 0.4982,
      "step": 669
    },
    {
      "epoch": 0.86,
      "learning_rate": 1.6745389640191724e-05,
      "loss": 0.4679,
      "step": 670
    },
    {
      "epoch": 0.86,
      "learning_rate": 1.673514817842831e-05,
      "loss": 0.4665,
      "step": 671
    },
    {
      "epoch": 0.86,
      "learning_rate": 1.6724893770920746e-05,
      "loss": 0.4778,
      "step": 672
    },
    {
      "epoch": 0.86,
      "learning_rate": 1.6714626437379203e-05,
      "loss": 0.4592,
      "step": 673
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.67043461975387e-05,
      "loss": 0.4618,
      "step": 674
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.6694053071159063e-05,
      "loss": 0.4858,
      "step": 675
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.6683747078024887e-05,
      "loss": 0.4868,
      "step": 676
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.66734282379455e-05,
      "loss": 0.4659,
      "step": 677
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.666309657075492e-05,
      "loss": 0.4722,
      "step": 678
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.665275209631182e-05,
      "loss": 0.4728,
      "step": 679
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.6642394834499494e-05,
      "loss": 0.4797,
      "step": 680
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.663202480522582e-05,
      "loss": 0.4556,
      "step": 681
    },
    {
      "epoch": 0.88,
      "learning_rate": 1.66216420284232e-05,
      "loss": 0.4759,
      "step": 682
    },
    {
      "epoch": 0.88,
      "learning_rate": 1.661124652404855e-05,
      "loss": 0.4887,
      "step": 683
    },
    {
      "epoch": 0.88,
      "learning_rate": 1.6600838312083254e-05,
      "loss": 0.4927,
      "step": 684
    },
    {
      "epoch": 0.88,
      "learning_rate": 1.6590417412533105e-05,
      "loss": 0.4844,
      "step": 685
    },
    {
      "epoch": 0.88,
      "learning_rate": 1.6579983845428305e-05,
      "loss": 0.4874,
      "step": 686
    },
    {
      "epoch": 0.88,
      "learning_rate": 1.6569537630823385e-05,
      "loss": 0.4834,
      "step": 687
    },
    {
      "epoch": 0.88,
      "learning_rate": 1.6559078788797194e-05,
      "loss": 0.4826,
      "step": 688
    },
    {
      "epoch": 0.88,
      "learning_rate": 1.6548607339452853e-05,
      "loss": 0.4928,
      "step": 689
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.6538123302917718e-05,
      "loss": 0.4634,
      "step": 690
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.6527626699343326e-05,
      "loss": 0.4642,
      "step": 691
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.651711754890539e-05,
      "loss": 0.4744,
      "step": 692
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.6506595871803733e-05,
      "loss": 0.4841,
      "step": 693
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.6496061688262238e-05,
      "loss": 0.4681,
      "step": 694
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.6485515018528847e-05,
      "loss": 0.4739,
      "step": 695
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.6474955882875493e-05,
      "loss": 0.4805,
      "step": 696
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.646438430159808e-05,
      "loss": 0.4778,
      "step": 697
    },
    {
      "epoch": 0.9,
      "learning_rate": 1.645380029501641e-05,
      "loss": 0.4668,
      "step": 698
    },
    {
      "epoch": 0.9,
      "learning_rate": 1.6443203883474202e-05,
      "loss": 0.4795,
      "step": 699
    },
    {
      "epoch": 0.9,
      "learning_rate": 1.643259508733899e-05,
      "loss": 0.4736,
      "step": 700
    },
    {
      "epoch": 0.9,
      "learning_rate": 1.6421973927002127e-05,
      "loss": 0.4799,
      "step": 701
    },
    {
      "epoch": 0.9,
      "learning_rate": 1.6411340422878725e-05,
      "loss": 0.5018,
      "step": 702
    },
    {
      "epoch": 0.9,
      "learning_rate": 1.6400694595407628e-05,
      "loss": 0.4744,
      "step": 703
    },
    {
      "epoch": 0.9,
      "learning_rate": 1.639003646505137e-05,
      "loss": 0.4706,
      "step": 704
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.6379366052296114e-05,
      "loss": 0.4677,
      "step": 705
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.636868337765165e-05,
      "loss": 0.4863,
      "step": 706
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.6357988461651336e-05,
      "loss": 0.4827,
      "step": 707
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.6347281324852046e-05,
      "loss": 0.4741,
      "step": 708
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.6336561987834155e-05,
      "loss": 0.474,
      "step": 709
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.6325830471201482e-05,
      "loss": 0.4734,
      "step": 710
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.6315086795581267e-05,
      "loss": 0.4736,
      "step": 711
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.6304330981624102e-05,
      "loss": 0.4747,
      "step": 712
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.6293563050003934e-05,
      "loss": 0.4682,
      "step": 713
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.6282783021417987e-05,
      "loss": 0.4758,
      "step": 714
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.6271990916586735e-05,
      "loss": 0.463,
      "step": 715
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.626118675625387e-05,
      "loss": 0.4919,
      "step": 716
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.6250370561186254e-05,
      "loss": 0.4857,
      "step": 717
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.623954235217388e-05,
      "loss": 0.4511,
      "step": 718
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.622870215002984e-05,
      "loss": 0.4709,
      "step": 719
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.6217849975590275e-05,
      "loss": 0.4687,
      "step": 720
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.6206985849714326e-05,
      "loss": 0.4814,
      "step": 721
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.619610979328412e-05,
      "loss": 0.4746,
      "step": 722
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.6185221827204712e-05,
      "loss": 0.4519,
      "step": 723
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.617432197240406e-05,
      "loss": 0.4856,
      "step": 724
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.6163410249832943e-05,
      "loss": 0.4705,
      "step": 725
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.6152486680464985e-05,
      "loss": 0.4673,
      "step": 726
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.614155128529656e-05,
      "loss": 0.474,
      "step": 727
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.613060408534678e-05,
      "loss": 0.4856,
      "step": 728
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.611964510165745e-05,
      "loss": 0.4706,
      "step": 729
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.610867435529302e-05,
      "loss": 0.4787,
      "step": 730
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.6097691867340547e-05,
      "loss": 0.4748,
      "step": 731
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.608669765890966e-05,
      "loss": 0.474,
      "step": 732
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.6075691751132515e-05,
      "loss": 0.4685,
      "step": 733
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.6064674165163762e-05,
      "loss": 0.4687,
      "step": 734
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.6053644922180493e-05,
      "loss": 0.4779,
      "step": 735
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.60426040433822e-05,
      "loss": 0.4786,
      "step": 736
    },
    {
      "epoch": 0.95,
      "learning_rate": 1.6031551549990748e-05,
      "loss": 0.4806,
      "step": 737
    },
    {
      "epoch": 0.95,
      "learning_rate": 1.6020487463250326e-05,
      "loss": 0.4641,
      "step": 738
    },
    {
      "epoch": 0.95,
      "learning_rate": 1.6009411804427406e-05,
      "loss": 0.4796,
      "step": 739
    },
    {
      "epoch": 0.95,
      "learning_rate": 1.5998324594810698e-05,
      "loss": 0.4783,
      "step": 740
    },
    {
      "epoch": 0.95,
      "learning_rate": 1.5987225855711125e-05,
      "loss": 0.4626,
      "step": 741
    },
    {
      "epoch": 0.95,
      "learning_rate": 1.5976115608461756e-05,
      "loss": 0.4527,
      "step": 742
    },
    {
      "epoch": 0.95,
      "learning_rate": 1.5964993874417795e-05,
      "loss": 0.4733,
      "step": 743
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.5953860674956517e-05,
      "loss": 0.4622,
      "step": 744
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.5942716031477235e-05,
      "loss": 0.4674,
      "step": 745
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.5931559965401258e-05,
      "loss": 0.4701,
      "step": 746
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.5920392498171856e-05,
      "loss": 0.4627,
      "step": 747
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.590921365125421e-05,
      "loss": 0.4731,
      "step": 748
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.5898023446135373e-05,
      "loss": 0.4854,
      "step": 749
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.5886821904324226e-05,
      "loss": 0.4482,
      "step": 750
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.587560904735145e-05,
      "loss": 0.4665,
      "step": 751
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.5864384896769475e-05,
      "loss": 0.459,
      "step": 752
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.585314947415242e-05,
      "loss": 0.4732,
      "step": 753
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.5841902801096098e-05,
      "loss": 0.4608,
      "step": 754
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.5830644899217926e-05,
      "loss": 0.4757,
      "step": 755
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.5819375790156912e-05,
      "loss": 0.472,
      "step": 756
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.5808095495573605e-05,
      "loss": 0.4695,
      "step": 757
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.5796804037150054e-05,
      "loss": 0.4816,
      "step": 758
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.5785501436589762e-05,
      "loss": 0.4945,
      "step": 759
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.5774187715617656e-05,
      "loss": 0.4743,
      "step": 760
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.5762862895980027e-05,
      "loss": 0.488,
      "step": 761
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.5751526999444516e-05,
      "loss": 0.4662,
      "step": 762
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.5740180047800032e-05,
      "loss": 0.4848,
      "step": 763
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.5728822062856758e-05,
      "loss": 0.465,
      "step": 764
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.5717453066446067e-05,
      "loss": 0.4893,
      "step": 765
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.57060730804205e-05,
      "loss": 0.477,
      "step": 766
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.5694682126653728e-05,
      "loss": 0.4625,
      "step": 767
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.5683280227040498e-05,
      "loss": 0.4831,
      "step": 768
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.5671867403496597e-05,
      "loss": 0.4755,
      "step": 769
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.566044367795881e-05,
      "loss": 0.4622,
      "step": 770
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.5649009072384874e-05,
      "loss": 0.4765,
      "step": 771
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.563756360875344e-05,
      "loss": 0.4767,
      "step": 772
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.562610730906404e-05,
      "loss": 0.4806,
      "step": 773
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.5614640195337013e-05,
      "loss": 0.4602,
      "step": 774
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.5603162289613503e-05,
      "loss": 0.479,
      "step": 775
    },
    {
      "epoch": 1.0,
      "learning_rate": 1.5591673613955384e-05,
      "loss": 0.4763,
      "step": 776
    },
    {
      "epoch": 1.0,
      "learning_rate": 1.558017419044524e-05,
      "loss": 0.4958,
      "step": 777
    },
    {
      "epoch": 1.0,
      "learning_rate": 1.5568664041186317e-05,
      "loss": 0.4472,
      "step": 778
    },
    {
      "epoch": 1.0,
      "learning_rate": 1.5557143188302463e-05,
      "loss": 0.4662,
      "step": 779
    },
    {
      "epoch": 1.0,
      "learning_rate": 1.5545611653938105e-05,
      "loss": 0.458,
      "step": 780
    },
    {
      "epoch": 1.0,
      "learning_rate": 1.553406946025821e-05,
      "loss": 0.4549,
      "step": 781
    },
    {
      "epoch": 1.0,
      "learning_rate": 1.5522516629448228e-05,
      "loss": 0.4754,
      "step": 782
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.551095318371405e-05,
      "loss": 0.462,
      "step": 783
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.5499379145281975e-05,
      "loss": 0.4527,
      "step": 784
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.548779453639866e-05,
      "loss": 0.4688,
      "step": 785
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.547619937933108e-05,
      "loss": 0.4809,
      "step": 786
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.546459369636649e-05,
      "loss": 0.4676,
      "step": 787
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.545297750981237e-05,
      "loss": 0.4691,
      "step": 788
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.5441350841996395e-05,
      "loss": 0.4845,
      "step": 789
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.5429713715266382e-05,
      "loss": 0.4897,
      "step": 790
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.5418066151990245e-05,
      "loss": 0.4689,
      "step": 791
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.5406408174555978e-05,
      "loss": 0.4609,
      "step": 792
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.539473980537157e-05,
      "loss": 0.4701,
      "step": 793
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.5383061066865003e-05,
      "loss": 0.4578,
      "step": 794
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.5371371981484168e-05,
      "loss": 0.4705,
      "step": 795
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.5359672571696873e-05,
      "loss": 0.4776,
      "step": 796
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.5347962859990744e-05,
      "loss": 0.4775,
      "step": 797
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.533624286887322e-05,
      "loss": 0.4717,
      "step": 798
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.5324512620871503e-05,
      "loss": 0.4697,
      "step": 799
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.53127721385325e-05,
      "loss": 0.4469,
      "step": 800
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.5301021444422794e-05,
      "loss": 0.47,
      "step": 801
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.52892605611286e-05,
      "loss": 0.4762,
      "step": 802
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.527748951125571e-05,
      "loss": 0.4684,
      "step": 803
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.5265708317429463e-05,
      "loss": 0.4597,
      "step": 804
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.5253917002294697e-05,
      "loss": 0.4477,
      "step": 805
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.5242115588515695e-05,
      "loss": 0.4637,
      "step": 806
    },
    {
      "epoch": 1.04,
      "learning_rate": 1.5230304098776162e-05,
      "loss": 0.4745,
      "step": 807
    },
    {
      "epoch": 1.04,
      "learning_rate": 1.5218482555779167e-05,
      "loss": 0.4777,
      "step": 808
    },
    {
      "epoch": 1.04,
      "learning_rate": 1.5206650982247095e-05,
      "loss": 0.4664,
      "step": 809
    },
    {
      "epoch": 1.04,
      "learning_rate": 1.5194809400921624e-05,
      "loss": 0.4937,
      "step": 810
    },
    {
      "epoch": 1.04,
      "learning_rate": 1.518295783456366e-05,
      "loss": 0.4663,
      "step": 811
    },
    {
      "epoch": 1.04,
      "learning_rate": 1.5171096305953295e-05,
      "loss": 0.4873,
      "step": 812
    },
    {
      "epoch": 1.04,
      "learning_rate": 1.5159224837889785e-05,
      "loss": 0.4465,
      "step": 813
    },
    {
      "epoch": 1.04,
      "learning_rate": 1.5147343453191483e-05,
      "loss": 0.4747,
      "step": 814
    },
    {
      "epoch": 1.05,
      "learning_rate": 1.51354521746958e-05,
      "loss": 0.4737,
      "step": 815
    },
    {
      "epoch": 1.05,
      "learning_rate": 1.5123551025259164e-05,
      "loss": 0.4642,
      "step": 816
    },
    {
      "epoch": 1.05,
      "learning_rate": 1.5111640027756984e-05,
      "loss": 0.4693,
      "step": 817
    },
    {
      "epoch": 1.05,
      "learning_rate": 1.5099719205083591e-05,
      "loss": 0.4681,
      "step": 818
    },
    {
      "epoch": 1.05,
      "learning_rate": 1.5087788580152207e-05,
      "loss": 0.4763,
      "step": 819
    },
    {
      "epoch": 1.05,
      "learning_rate": 1.5075848175894886e-05,
      "loss": 0.4715,
      "step": 820
    },
    {
      "epoch": 1.05,
      "learning_rate": 1.5063898015262486e-05,
      "loss": 0.4679,
      "step": 821
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.5051938121224619e-05,
      "loss": 0.4784,
      "step": 822
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.5039968516769601e-05,
      "loss": 0.4505,
      "step": 823
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.5027989224904414e-05,
      "loss": 0.4719,
      "step": 824
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.5016000268654658e-05,
      "loss": 0.4446,
      "step": 825
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.5004001671064519e-05,
      "loss": 0.4598,
      "step": 826
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.4991993455196704e-05,
      "loss": 0.4656,
      "step": 827
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.4979975644132412e-05,
      "loss": 0.4659,
      "step": 828
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.496794826097128e-05,
      "loss": 0.4683,
      "step": 829
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.4955911328831357e-05,
      "loss": 0.4544,
      "step": 830
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.494386487084903e-05,
      "loss": 0.4768,
      "step": 831
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.4931808910179006e-05,
      "loss": 0.4851,
      "step": 832
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.4919743469994252e-05,
      "loss": 0.449,
      "step": 833
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.4907668573485961e-05,
      "loss": 0.4593,
      "step": 834
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.4895584243863499e-05,
      "loss": 0.4394,
      "step": 835
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.488349050435436e-05,
      "loss": 0.4566,
      "step": 836
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.4871387378204133e-05,
      "loss": 0.4554,
      "step": 837
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.4859274888676445e-05,
      "loss": 0.4627,
      "step": 838
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.4847153059052915e-05,
      "loss": 0.4791,
      "step": 839
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.4835021912633127e-05,
      "loss": 0.4707,
      "step": 840
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.4822881472734563e-05,
      "loss": 0.4773,
      "step": 841
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.4810731762692572e-05,
      "loss": 0.4693,
      "step": 842
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.4798572805860318e-05,
      "loss": 0.4668,
      "step": 843
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.4786404625608745e-05,
      "loss": 0.4601,
      "step": 844
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.477422724532652e-05,
      "loss": 0.4592,
      "step": 845
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.4762040688419993e-05,
      "loss": 0.4665,
      "step": 846
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.474984497831316e-05,
      "loss": 0.4629,
      "step": 847
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.47376401384476e-05,
      "loss": 0.475,
      "step": 848
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.4725426192282446e-05,
      "loss": 0.4852,
      "step": 849
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.4713203163294334e-05,
      "loss": 0.4603,
      "step": 850
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.4700971074977362e-05,
      "loss": 0.4509,
      "step": 851
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.4688729950843035e-05,
      "loss": 0.4627,
      "step": 852
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.4676479814420226e-05,
      "loss": 0.4518,
      "step": 853
    },
    {
      "epoch": 1.1,
      "learning_rate": 1.4664220689255138e-05,
      "loss": 0.4705,
      "step": 854
    },
    {
      "epoch": 1.1,
      "learning_rate": 1.465195259891124e-05,
      "loss": 0.4679,
      "step": 855
    },
    {
      "epoch": 1.1,
      "learning_rate": 1.4639675566969245e-05,
      "loss": 0.464,
      "step": 856
    },
    {
      "epoch": 1.1,
      "learning_rate": 1.4627389617027044e-05,
      "loss": 0.4611,
      "step": 857
    },
    {
      "epoch": 1.1,
      "learning_rate": 1.4615094772699674e-05,
      "loss": 0.4427,
      "step": 858
    },
    {
      "epoch": 1.1,
      "learning_rate": 1.4602791057619266e-05,
      "loss": 0.4599,
      "step": 859
    },
    {
      "epoch": 1.1,
      "learning_rate": 1.4590478495435004e-05,
      "loss": 0.4535,
      "step": 860
    },
    {
      "epoch": 1.11,
      "learning_rate": 1.4578157109813074e-05,
      "loss": 0.4588,
      "step": 861
    },
    {
      "epoch": 1.11,
      "learning_rate": 1.4565826924436622e-05,
      "loss": 0.4711,
      "step": 862
    },
    {
      "epoch": 1.11,
      "learning_rate": 1.4553487963005712e-05,
      "loss": 0.4569,
      "step": 863
    },
    {
      "epoch": 1.11,
      "learning_rate": 1.4541140249237273e-05,
      "loss": 0.4675,
      "step": 864
    },
    {
      "epoch": 1.11,
      "learning_rate": 1.4528783806865057e-05,
      "loss": 0.4507,
      "step": 865
    },
    {
      "epoch": 1.11,
      "learning_rate": 1.4516418659639598e-05,
      "loss": 0.4808,
      "step": 866
    },
    {
      "epoch": 1.11,
      "learning_rate": 1.4504044831328152e-05,
      "loss": 0.4668,
      "step": 867
    },
    {
      "epoch": 1.11,
      "learning_rate": 1.4491662345714675e-05,
      "loss": 0.4655,
      "step": 868
    },
    {
      "epoch": 1.12,
      "learning_rate": 1.4479271226599748e-05,
      "loss": 0.4462,
      "step": 869
    },
    {
      "epoch": 1.12,
      "learning_rate": 1.446687149780056e-05,
      "loss": 0.4618,
      "step": 870
    },
    {
      "epoch": 1.12,
      "learning_rate": 1.4454463183150835e-05,
      "loss": 0.4591,
      "step": 871
    },
    {
      "epoch": 1.12,
      "learning_rate": 1.4442046306500816e-05,
      "loss": 0.4775,
      "step": 872
    },
    {
      "epoch": 1.12,
      "learning_rate": 1.4429620891717196e-05,
      "loss": 0.4357,
      "step": 873
    },
    {
      "epoch": 1.12,
      "learning_rate": 1.4417186962683072e-05,
      "loss": 0.4593,
      "step": 874
    },
    {
      "epoch": 1.12,
      "learning_rate": 1.4404744543297915e-05,
      "loss": 0.4763,
      "step": 875
    },
    {
      "epoch": 1.12,
      "learning_rate": 1.4392293657477516e-05,
      "loss": 0.4353,
      "step": 876
    },
    {
      "epoch": 1.13,
      "learning_rate": 1.4379834329153934e-05,
      "loss": 0.4724,
      "step": 877
    },
    {
      "epoch": 1.13,
      "learning_rate": 1.4367366582275462e-05,
      "loss": 0.4733,
      "step": 878
    },
    {
      "epoch": 1.13,
      "learning_rate": 1.4354890440806566e-05,
      "loss": 0.4495,
      "step": 879
    },
    {
      "epoch": 1.13,
      "learning_rate": 1.4342405928727852e-05,
      "loss": 0.4458,
      "step": 880
    },
    {
      "epoch": 1.13,
      "learning_rate": 1.4329913070036022e-05,
      "loss": 0.4628,
      "step": 881
    },
    {
      "epoch": 1.13,
      "learning_rate": 1.4317411888743804e-05,
      "loss": 0.478,
      "step": 882
    },
    {
      "epoch": 1.13,
      "learning_rate": 1.4304902408879942e-05,
      "loss": 0.4463,
      "step": 883
    },
    {
      "epoch": 1.13,
      "learning_rate": 1.4292384654489123e-05,
      "loss": 0.4707,
      "step": 884
    },
    {
      "epoch": 1.14,
      "learning_rate": 1.427985864963193e-05,
      "loss": 0.4439,
      "step": 885
    },
    {
      "epoch": 1.14,
      "learning_rate": 1.426732441838482e-05,
      "loss": 0.4501,
      "step": 886
    },
    {
      "epoch": 1.14,
      "learning_rate": 1.4254781984840052e-05,
      "loss": 0.4694,
      "step": 887
    },
    {
      "epoch": 1.14,
      "learning_rate": 1.4242231373105652e-05,
      "loss": 0.4529,
      "step": 888
    },
    {
      "epoch": 1.14,
      "learning_rate": 1.422967260730537e-05,
      "loss": 0.4512,
      "step": 889
    },
    {
      "epoch": 1.14,
      "learning_rate": 1.421710571157862e-05,
      "loss": 0.4838,
      "step": 890
    },
    {
      "epoch": 1.14,
      "learning_rate": 1.4204530710080455e-05,
      "loss": 0.4621,
      "step": 891
    },
    {
      "epoch": 1.15,
      "learning_rate": 1.4191947626981495e-05,
      "loss": 0.4686,
      "step": 892
    },
    {
      "epoch": 1.15,
      "learning_rate": 1.4179356486467906e-05,
      "loss": 0.4685,
      "step": 893
    },
    {
      "epoch": 1.15,
      "learning_rate": 1.4166757312741332e-05,
      "loss": 0.4852,
      "step": 894
    },
    {
      "epoch": 1.15,
      "learning_rate": 1.4154150130018867e-05,
      "loss": 0.455,
      "step": 895
    },
    {
      "epoch": 1.15,
      "learning_rate": 1.4141534962532986e-05,
      "loss": 0.4508,
      "step": 896
    },
    {
      "epoch": 1.15,
      "learning_rate": 1.4128911834531525e-05,
      "loss": 0.4484,
      "step": 897
    },
    {
      "epoch": 1.15,
      "learning_rate": 1.4116280770277614e-05,
      "loss": 0.4587,
      "step": 898
    },
    {
      "epoch": 1.15,
      "learning_rate": 1.410364179404964e-05,
      "loss": 0.4688,
      "step": 899
    },
    {
      "epoch": 1.16,
      "learning_rate": 1.4090994930141192e-05,
      "loss": 0.4502,
      "step": 900
    },
    {
      "epoch": 1.16,
      "learning_rate": 1.407834020286103e-05,
      "loss": 0.4797,
      "step": 901
    },
    {
      "epoch": 1.16,
      "learning_rate": 1.4065677636533019e-05,
      "loss": 0.4822,
      "step": 902
    },
    {
      "epoch": 1.16,
      "learning_rate": 1.4053007255496096e-05,
      "loss": 0.461,
      "step": 903
    },
    {
      "epoch": 1.16,
      "learning_rate": 1.4040329084104223e-05,
      "loss": 0.4505,
      "step": 904
    },
    {
      "epoch": 1.16,
      "learning_rate": 1.4027643146726327e-05,
      "loss": 0.4739,
      "step": 905
    },
    {
      "epoch": 1.16,
      "learning_rate": 1.4014949467746267e-05,
      "loss": 0.4476,
      "step": 906
    },
    {
      "epoch": 1.16,
      "learning_rate": 1.400224807156278e-05,
      "loss": 0.4665,
      "step": 907
    },
    {
      "epoch": 1.17,
      "learning_rate": 1.3989538982589443e-05,
      "loss": 0.4651,
      "step": 908
    },
    {
      "epoch": 1.17,
      "learning_rate": 1.3976822225254609e-05,
      "loss": 0.4498,
      "step": 909
    },
    {
      "epoch": 1.17,
      "learning_rate": 1.3964097824001382e-05,
      "loss": 0.4785,
      "step": 910
    },
    {
      "epoch": 1.17,
      "learning_rate": 1.3951365803287547e-05,
      "loss": 0.4591,
      "step": 911
    },
    {
      "epoch": 1.17,
      "learning_rate": 1.3938626187585543e-05,
      "loss": 0.4653,
      "step": 912
    },
    {
      "epoch": 1.17,
      "learning_rate": 1.39258790013824e-05,
      "loss": 0.469,
      "step": 913
    },
    {
      "epoch": 1.17,
      "learning_rate": 1.391312426917971e-05,
      "loss": 0.4492,
      "step": 914
    },
    {
      "epoch": 1.17,
      "learning_rate": 1.390036201549356e-05,
      "loss": 0.4664,
      "step": 915
    },
    {
      "epoch": 1.18,
      "learning_rate": 1.3887592264854498e-05,
      "loss": 0.458,
      "step": 916
    },
    {
      "epoch": 1.18,
      "learning_rate": 1.3874815041807482e-05,
      "loss": 0.4465,
      "step": 917
    },
    {
      "epoch": 1.18,
      "learning_rate": 1.386203037091183e-05,
      "loss": 0.4583,
      "step": 918
    },
    {
      "epoch": 1.18,
      "learning_rate": 1.384923827674118e-05,
      "loss": 0.4499,
      "step": 919
    },
    {
      "epoch": 1.18,
      "learning_rate": 1.383643878388343e-05,
      "loss": 0.4504,
      "step": 920
    },
    {
      "epoch": 1.18,
      "learning_rate": 1.3823631916940717e-05,
      "loss": 0.4625,
      "step": 921
    },
    {
      "epoch": 1.18,
      "learning_rate": 1.381081770052933e-05,
      "loss": 0.4474,
      "step": 922
    },
    {
      "epoch": 1.18,
      "learning_rate": 1.3797996159279702e-05,
      "loss": 0.4526,
      "step": 923
    },
    {
      "epoch": 1.19,
      "learning_rate": 1.3785167317836333e-05,
      "loss": 0.4635,
      "step": 924
    },
    {
      "epoch": 1.19,
      "learning_rate": 1.3772331200857763e-05,
      "loss": 0.4829,
      "step": 925
    },
    {
      "epoch": 1.19,
      "learning_rate": 1.3759487833016507e-05,
      "loss": 0.4758,
      "step": 926
    },
    {
      "epoch": 1.19,
      "learning_rate": 1.3746637238999033e-05,
      "loss": 0.4566,
      "step": 927
    },
    {
      "epoch": 1.19,
      "learning_rate": 1.3733779443505678e-05,
      "loss": 0.4673,
      "step": 928
    },
    {
      "epoch": 1.19,
      "learning_rate": 1.3720914471250644e-05,
      "loss": 0.4536,
      "step": 929
    },
    {
      "epoch": 1.19,
      "learning_rate": 1.3708042346961903e-05,
      "loss": 0.4595,
      "step": 930
    },
    {
      "epoch": 1.2,
      "learning_rate": 1.3695163095381196e-05,
      "loss": 0.4582,
      "step": 931
    },
    {
      "epoch": 1.2,
      "learning_rate": 1.3682276741263949e-05,
      "loss": 0.4725,
      "step": 932
    },
    {
      "epoch": 1.2,
      "learning_rate": 1.3669383309379247e-05,
      "loss": 0.4801,
      "step": 933
    },
    {
      "epoch": 1.2,
      "learning_rate": 1.3656482824509773e-05,
      "loss": 0.4581,
      "step": 934
    },
    {
      "epoch": 1.2,
      "learning_rate": 1.3643575311451778e-05,
      "loss": 0.4495,
      "step": 935
    },
    {
      "epoch": 1.2,
      "learning_rate": 1.363066079501501e-05,
      "loss": 0.4514,
      "step": 936
    },
    {
      "epoch": 1.2,
      "learning_rate": 1.3617739300022685e-05,
      "loss": 0.4796,
      "step": 937
    },
    {
      "epoch": 1.2,
      "learning_rate": 1.3604810851311429e-05,
      "loss": 0.4634,
      "step": 938
    },
    {
      "epoch": 1.21,
      "learning_rate": 1.3591875473731237e-05,
      "loss": 0.4468,
      "step": 939
    },
    {
      "epoch": 1.21,
      "learning_rate": 1.3578933192145421e-05,
      "loss": 0.4589,
      "step": 940
    },
    {
      "epoch": 1.21,
      "learning_rate": 1.3565984031430562e-05,
      "loss": 0.4714,
      "step": 941
    },
    {
      "epoch": 1.21,
      "learning_rate": 1.3553028016476463e-05,
      "loss": 0.4622,
      "step": 942
    },
    {
      "epoch": 1.21,
      "learning_rate": 1.3540065172186108e-05,
      "loss": 0.4607,
      "step": 943
    },
    {
      "epoch": 1.21,
      "learning_rate": 1.3527095523475597e-05,
      "loss": 0.4602,
      "step": 944
    },
    {
      "epoch": 1.21,
      "learning_rate": 1.3514119095274119e-05,
      "loss": 0.4639,
      "step": 945
    },
    {
      "epoch": 1.21,
      "learning_rate": 1.3501135912523889e-05,
      "loss": 0.45,
      "step": 946
    },
    {
      "epoch": 1.22,
      "learning_rate": 1.3488146000180104e-05,
      "loss": 0.4505,
      "step": 947
    },
    {
      "epoch": 1.22,
      "learning_rate": 1.3475149383210902e-05,
      "loss": 0.421,
      "step": 948
    },
    {
      "epoch": 1.22,
      "learning_rate": 1.3462146086597301e-05,
      "loss": 0.4497,
      "step": 949
    },
    {
      "epoch": 1.22,
      "learning_rate": 1.344913613533316e-05,
      "loss": 0.4509,
      "step": 950
    },
    {
      "epoch": 1.22,
      "learning_rate": 1.3436119554425133e-05,
      "loss": 0.446,
      "step": 951
    },
    {
      "epoch": 1.22,
      "learning_rate": 1.3423096368892612e-05,
      "loss": 0.4583,
      "step": 952
    },
    {
      "epoch": 1.22,
      "learning_rate": 1.3410066603767686e-05,
      "loss": 0.4533,
      "step": 953
    },
    {
      "epoch": 1.22,
      "learning_rate": 1.3397030284095092e-05,
      "loss": 0.4625,
      "step": 954
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.3383987434932164e-05,
      "loss": 0.456,
      "step": 955
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.3370938081348783e-05,
      "loss": 0.4538,
      "step": 956
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.3357882248427342e-05,
      "loss": 0.4579,
      "step": 957
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.334481996126268e-05,
      "loss": 0.4567,
      "step": 958
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.3331751244962041e-05,
      "loss": 0.4652,
      "step": 959
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.3318676124645031e-05,
      "loss": 0.4566,
      "step": 960
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.3305594625443567e-05,
      "loss": 0.4706,
      "step": 961
    },
    {
      "epoch": 1.23,
      "learning_rate": 1.3292506772501819e-05,
      "loss": 0.4446,
      "step": 962
    },
    {
      "epoch": 1.24,
      "learning_rate": 1.3279412590976175e-05,
      "loss": 0.4509,
      "step": 963
    },
    {
      "epoch": 1.24,
      "learning_rate": 1.3266312106035186e-05,
      "loss": 0.4612,
      "step": 964
    },
    {
      "epoch": 1.24,
      "learning_rate": 1.3253205342859524e-05,
      "loss": 0.4593,
      "step": 965
    },
    {
      "epoch": 1.24,
      "learning_rate": 1.3240092326641917e-05,
      "loss": 0.4614,
      "step": 966
    },
    {
      "epoch": 1.24,
      "learning_rate": 1.3226973082587125e-05,
      "loss": 0.4699,
      "step": 967
    },
    {
      "epoch": 1.24,
      "learning_rate": 1.321384763591187e-05,
      "loss": 0.4582,
      "step": 968
    },
    {
      "epoch": 1.24,
      "learning_rate": 1.3200716011844798e-05,
      "loss": 0.4365,
      "step": 969
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.3187578235626433e-05,
      "loss": 0.4686,
      "step": 970
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.3174434332509116e-05,
      "loss": 0.4658,
      "step": 971
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.3161284327756971e-05,
      "loss": 0.4595,
      "step": 972
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.314812824664585e-05,
      "loss": 0.4637,
      "step": 973
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.3134966114463283e-05,
      "loss": 0.4616,
      "step": 974
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.3121797956508429e-05,
      "loss": 0.448,
      "step": 975
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.3108623798092029e-05,
      "loss": 0.4502,
      "step": 976
    },
    {
      "epoch": 1.25,
      "learning_rate": 1.309544366453636e-05,
      "loss": 0.4501,
      "step": 977
    },
    {
      "epoch": 1.26,
      "learning_rate": 1.3082257581175186e-05,
      "loss": 0.466,
      "step": 978
    },
    {
      "epoch": 1.26,
      "learning_rate": 1.3069065573353706e-05,
      "loss": 0.4589,
      "step": 979
    },
    {
      "epoch": 1.26,
      "learning_rate": 1.30558676664285e-05,
      "loss": 0.4629,
      "step": 980
    },
    {
      "epoch": 1.26,
      "learning_rate": 1.3042663885767496e-05,
      "loss": 0.4606,
      "step": 981
    },
    {
      "epoch": 1.26,
      "learning_rate": 1.3029454256749907e-05,
      "loss": 0.4529,
      "step": 982
    },
    {
      "epoch": 1.26,
      "learning_rate": 1.3016238804766184e-05,
      "loss": 0.4594,
      "step": 983
    },
    {
      "epoch": 1.26,
      "learning_rate": 1.300301755521798e-05,
      "loss": 0.4548,
      "step": 984
    },
    {
      "epoch": 1.26,
      "learning_rate": 1.2989790533518086e-05,
      "loss": 0.4715,
      "step": 985
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.2976557765090385e-05,
      "loss": 0.4761,
      "step": 986
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.296331927536981e-05,
      "loss": 0.4687,
      "step": 987
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.295007508980229e-05,
      "loss": 0.4455,
      "step": 988
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.29368252338447e-05,
      "loss": 0.4497,
      "step": 989
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.2923569732964817e-05,
      "loss": 0.4613,
      "step": 990
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.2910308612641271e-05,
      "loss": 0.4502,
      "step": 991
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.2897041898363485e-05,
      "loss": 0.4585,
      "step": 992
    },
    {
      "epoch": 1.27,
      "learning_rate": 1.288376961563164e-05,
      "loss": 0.4614,
      "step": 993
    },
    {
      "epoch": 1.28,
      "learning_rate": 1.287049178995662e-05,
      "loss": 0.4547,
      "step": 994
    },
    {
      "epoch": 1.28,
      "learning_rate": 1.285720844685996e-05,
      "loss": 0.4556,
      "step": 995
    },
    {
      "epoch": 1.28,
      "learning_rate": 1.2843919611873803e-05,
      "loss": 0.4421,
      "step": 996
    },
    {
      "epoch": 1.28,
      "learning_rate": 1.2830625310540848e-05,
      "loss": 0.4831,
      "step": 997
    },
    {
      "epoch": 1.28,
      "learning_rate": 1.2817325568414299e-05,
      "loss": 0.4557,
      "step": 998
    },
    {
      "epoch": 1.28,
      "learning_rate": 1.2804020411057818e-05,
      "loss": 0.4604,
      "step": 999
    },
    {
      "epoch": 1.28,
      "learning_rate": 1.2790709864045481e-05,
      "loss": 0.4667,
      "step": 1000
    },
    {
      "epoch": 1.28,
      "learning_rate": 1.2777393952961717e-05,
      "loss": 0.4505,
      "step": 1001
    },
    {
      "epoch": 1.29,
      "learning_rate": 1.2764072703401268e-05,
      "loss": 0.4762,
      "step": 1002
    },
    {
      "epoch": 1.29,
      "learning_rate": 1.2750746140969134e-05,
      "loss": 0.4523,
      "step": 1003
    },
    {
      "epoch": 1.29,
      "learning_rate": 1.2737414291280534e-05,
      "loss": 0.435,
      "step": 1004
    },
    {
      "epoch": 1.29,
      "learning_rate": 1.2724077179960845e-05,
      "loss": 0.4614,
      "step": 1005
    },
    {
      "epoch": 1.29,
      "learning_rate": 1.2710734832645557e-05,
      "loss": 0.4401,
      "step": 1006
    },
    {
      "epoch": 1.29,
      "learning_rate": 1.2697387274980225e-05,
      "loss": 0.4491,
      "step": 1007
    },
    {
      "epoch": 1.29,
      "learning_rate": 1.2684034532620418e-05,
      "loss": 0.47,
      "step": 1008
    },
    {
      "epoch": 1.3,
      "learning_rate": 1.2670676631231671e-05,
      "loss": 0.4359,
      "step": 1009
    },
    {
      "epoch": 1.3,
      "learning_rate": 1.2657313596489442e-05,
      "loss": 0.4477,
      "step": 1010
    },
    {
      "epoch": 1.3,
      "learning_rate": 1.2643945454079044e-05,
      "loss": 0.4782,
      "step": 1011
    },
    {
      "epoch": 1.3,
      "learning_rate": 1.2630572229695619e-05,
      "loss": 0.4487,
      "step": 1012
    },
    {
      "epoch": 1.3,
      "learning_rate": 1.2617193949044064e-05,
      "loss": 0.4711,
      "step": 1013
    },
    {
      "epoch": 1.3,
      "learning_rate": 1.2603810637839011e-05,
      "loss": 0.4803,
      "step": 1014
    },
    {
      "epoch": 1.3,
      "learning_rate": 1.2590422321804745e-05,
      "loss": 0.4381,
      "step": 1015
    },
    {
      "epoch": 1.3,
      "learning_rate": 1.2577029026675183e-05,
      "loss": 0.4672,
      "step": 1016
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.2563630778193805e-05,
      "loss": 0.4561,
      "step": 1017
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.2550227602113616e-05,
      "loss": 0.4832,
      "step": 1018
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.2536819524197092e-05,
      "loss": 0.4425,
      "step": 1019
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.252340657021613e-05,
      "loss": 0.4512,
      "step": 1020
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.2509988765951998e-05,
      "loss": 0.4638,
      "step": 1021
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.2496566137195294e-05,
      "loss": 0.4408,
      "step": 1022
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.2483138709745877e-05,
      "loss": 0.4477,
      "step": 1023
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.2469706509412838e-05,
      "loss": 0.4518,
      "step": 1024
    },
    {
      "epoch": 1.32,
      "learning_rate": 1.2456269562014441e-05,
      "loss": 0.4594,
      "step": 1025
    },
    {
      "epoch": 1.32,
      "learning_rate": 1.2442827893378073e-05,
      "loss": 0.4551,
      "step": 1026
    },
    {
      "epoch": 1.32,
      "learning_rate": 1.2429381529340199e-05,
      "loss": 0.4516,
      "step": 1027
    },
    {
      "epoch": 1.32,
      "learning_rate": 1.2415930495746301e-05,
      "loss": 0.4543,
      "step": 1028
    },
    {
      "epoch": 1.32,
      "learning_rate": 1.240247481845085e-05,
      "loss": 0.449,
      "step": 1029
    },
    {
      "epoch": 1.32,
      "learning_rate": 1.2389014523317224e-05,
      "loss": 0.468,
      "step": 1030
    },
    {
      "epoch": 1.32,
      "learning_rate": 1.2375549636217698e-05,
      "loss": 0.4675,
      "step": 1031
    },
    {
      "epoch": 1.32,
      "learning_rate": 1.236208018303336e-05,
      "loss": 0.4457,
      "step": 1032
    },
    {
      "epoch": 1.33,
      "learning_rate": 1.2348606189654077e-05,
      "loss": 0.4531,
      "step": 1033
    },
    {
      "epoch": 1.33,
      "learning_rate": 1.2335127681978442e-05,
      "loss": 0.4729,
      "step": 1034
    },
    {
      "epoch": 1.33,
      "learning_rate": 1.232164468591373e-05,
      "loss": 0.4574,
      "step": 1035
    },
    {
      "epoch": 1.33,
      "learning_rate": 1.2308157227375835e-05,
      "loss": 0.4401,
      "step": 1036
    },
    {
      "epoch": 1.33,
      "learning_rate": 1.2294665332289235e-05,
      "loss": 0.4501,
      "step": 1037
    },
    {
      "epoch": 1.33,
      "learning_rate": 1.2281169026586935e-05,
      "loss": 0.452,
      "step": 1038
    },
    {
      "epoch": 1.33,
      "learning_rate": 1.2267668336210411e-05,
      "loss": 0.4556,
      "step": 1039
    },
    {
      "epoch": 1.34,
      "learning_rate": 1.2254163287109579e-05,
      "loss": 0.4813,
      "step": 1040
    },
    {
      "epoch": 1.34,
      "learning_rate": 1.2240653905242726e-05,
      "loss": 0.4849,
      "step": 1041
    },
    {
      "epoch": 1.34,
      "learning_rate": 1.2227140216576463e-05,
      "loss": 0.4766,
      "step": 1042
    },
    {
      "epoch": 1.34,
      "learning_rate": 1.2213622247085685e-05,
      "loss": 0.4611,
      "step": 1043
    },
    {
      "epoch": 1.34,
      "learning_rate": 1.2200100022753514e-05,
      "loss": 0.4549,
      "step": 1044
    },
    {
      "epoch": 1.34,
      "learning_rate": 1.2186573569571251e-05,
      "loss": 0.4514,
      "step": 1045
    },
    {
      "epoch": 1.34,
      "learning_rate": 1.217304291353832e-05,
      "loss": 0.4741,
      "step": 1046
    },
    {
      "epoch": 1.34,
      "learning_rate": 1.2159508080662232e-05,
      "loss": 0.4596,
      "step": 1047
    },
    {
      "epoch": 1.35,
      "learning_rate": 1.2145969096958524e-05,
      "loss": 0.4471,
      "step": 1048
    },
    {
      "epoch": 1.35,
      "learning_rate": 1.2132425988450703e-05,
      "loss": 0.4578,
      "step": 1049
    },
    {
      "epoch": 1.35,
      "learning_rate": 1.2118878781170213e-05,
      "loss": 0.4625,
      "step": 1050
    },
    {
      "epoch": 1.35,
      "learning_rate": 1.2105327501156379e-05,
      "loss": 0.4441,
      "step": 1051
    },
    {
      "epoch": 1.35,
      "learning_rate": 1.2091772174456339e-05,
      "loss": 0.4454,
      "step": 1052
    },
    {
      "epoch": 1.35,
      "learning_rate": 1.2078212827125034e-05,
      "loss": 0.4573,
      "step": 1053
    },
    {
      "epoch": 1.35,
      "learning_rate": 1.2064649485225106e-05,
      "loss": 0.4459,
      "step": 1054
    },
    {
      "epoch": 1.35,
      "learning_rate": 1.2051082174826894e-05,
      "loss": 0.4502,
      "step": 1055
    },
    {
      "epoch": 1.36,
      "learning_rate": 1.2037510922008357e-05,
      "loss": 0.4528,
      "step": 1056
    },
    {
      "epoch": 1.36,
      "learning_rate": 1.2023935752855034e-05,
      "loss": 0.4591,
      "step": 1057
    },
    {
      "epoch": 1.36,
      "learning_rate": 1.201035669345999e-05,
      "loss": 0.4623,
      "step": 1058
    },
    {
      "epoch": 1.36,
      "learning_rate": 1.199677376992377e-05,
      "loss": 0.44,
      "step": 1059
    },
    {
      "epoch": 1.36,
      "learning_rate": 1.1983187008354347e-05,
      "loss": 0.4673,
      "step": 1060
    },
    {
      "epoch": 1.36,
      "learning_rate": 1.1969596434867063e-05,
      "loss": 0.442,
      "step": 1061
    },
    {
      "epoch": 1.36,
      "learning_rate": 1.1956002075584595e-05,
      "loss": 0.4508,
      "step": 1062
    },
    {
      "epoch": 1.36,
      "learning_rate": 1.1942403956636899e-05,
      "loss": 0.4562,
      "step": 1063
    },
    {
      "epoch": 1.37,
      "learning_rate": 1.192880210416115e-05,
      "loss": 0.4502,
      "step": 1064
    },
    {
      "epoch": 1.37,
      "learning_rate": 1.1915196544301703e-05,
      "loss": 0.4615,
      "step": 1065
    },
    {
      "epoch": 1.37,
      "learning_rate": 1.190158730321004e-05,
      "loss": 0.462,
      "step": 1066
    },
    {
      "epoch": 1.37,
      "learning_rate": 1.1887974407044716e-05,
      "loss": 0.4671,
      "step": 1067
    },
    {
      "epoch": 1.37,
      "learning_rate": 1.187435788197131e-05,
      "loss": 0.4681,
      "step": 1068
    },
    {
      "epoch": 1.37,
      "learning_rate": 1.1860737754162386e-05,
      "loss": 0.4674,
      "step": 1069
    },
    {
      "epoch": 1.37,
      "learning_rate": 1.184711404979742e-05,
      "loss": 0.4611,
      "step": 1070
    },
    {
      "epoch": 1.37,
      "learning_rate": 1.183348679506277e-05,
      "loss": 0.4547,
      "step": 1071
    },
    {
      "epoch": 1.38,
      "learning_rate": 1.1819856016151617e-05,
      "loss": 0.4568,
      "step": 1072
    },
    {
      "epoch": 1.38,
      "learning_rate": 1.1806221739263915e-05,
      "loss": 0.4393,
      "step": 1073
    },
    {
      "epoch": 1.38,
      "learning_rate": 1.1792583990606343e-05,
      "loss": 0.4499,
      "step": 1074
    },
    {
      "epoch": 1.38,
      "learning_rate": 1.1778942796392254e-05,
      "loss": 0.4561,
      "step": 1075
    },
    {
      "epoch": 1.38,
      "learning_rate": 1.1765298182841618e-05,
      "loss": 0.4463,
      "step": 1076
    },
    {
      "epoch": 1.38,
      "learning_rate": 1.1751650176180986e-05,
      "loss": 0.4543,
      "step": 1077
    },
    {
      "epoch": 1.38,
      "learning_rate": 1.1737998802643423e-05,
      "loss": 0.455,
      "step": 1078
    },
    {
      "epoch": 1.39,
      "learning_rate": 1.1724344088468467e-05,
      "loss": 0.4587,
      "step": 1079
    },
    {
      "epoch": 1.39,
      "learning_rate": 1.1710686059902083e-05,
      "loss": 0.4727,
      "step": 1080
    },
    {
      "epoch": 1.39,
      "learning_rate": 1.1697024743196604e-05,
      "loss": 0.4558,
      "step": 1081
    },
    {
      "epoch": 1.39,
      "learning_rate": 1.1683360164610675e-05,
      "loss": 0.463,
      "step": 1082
    },
    {
      "epoch": 1.39,
      "learning_rate": 1.1669692350409223e-05,
      "loss": 0.4561,
      "step": 1083
    },
    {
      "epoch": 1.39,
      "learning_rate": 1.1656021326863388e-05,
      "loss": 0.4486,
      "step": 1084
    },
    {
      "epoch": 1.39,
      "learning_rate": 1.1642347120250476e-05,
      "loss": 0.4356,
      "step": 1085
    },
    {
      "epoch": 1.39,
      "learning_rate": 1.1628669756853921e-05,
      "loss": 0.4536,
      "step": 1086
    },
    {
      "epoch": 1.4,
      "learning_rate": 1.1614989262963213e-05,
      "loss": 0.4713,
      "step": 1087
    },
    {
      "epoch": 1.4,
      "learning_rate": 1.1601305664873867e-05,
      "loss": 0.4655,
      "step": 1088
    },
    {
      "epoch": 1.4,
      "learning_rate": 1.158761898888736e-05,
      "loss": 0.4622,
      "step": 1089
    },
    {
      "epoch": 1.4,
      "learning_rate": 1.1573929261311093e-05,
      "loss": 0.4526,
      "step": 1090
    },
    {
      "epoch": 1.4,
      "learning_rate": 1.156023650845832e-05,
      "loss": 0.4601,
      "step": 1091
    },
    {
      "epoch": 1.4,
      "learning_rate": 1.154654075664812e-05,
      "loss": 0.4523,
      "step": 1092
    },
    {
      "epoch": 1.4,
      "learning_rate": 1.1532842032205332e-05,
      "loss": 0.4639,
      "step": 1093
    },
    {
      "epoch": 1.4,
      "learning_rate": 1.151914036146051e-05,
      "loss": 0.4446,
      "step": 1094
    },
    {
      "epoch": 1.41,
      "learning_rate": 1.1505435770749874e-05,
      "loss": 0.4626,
      "step": 1095
    },
    {
      "epoch": 1.41,
      "learning_rate": 1.1491728286415249e-05,
      "loss": 0.4464,
      "step": 1096
    },
    {
      "epoch": 1.41,
      "learning_rate": 1.1478017934804032e-05,
      "loss": 0.4695,
      "step": 1097
    },
    {
      "epoch": 1.41,
      "learning_rate": 1.1464304742269116e-05,
      "loss": 0.4529,
      "step": 1098
    },
    {
      "epoch": 1.41,
      "learning_rate": 1.1450588735168874e-05,
      "loss": 0.4599,
      "step": 1099
    },
    {
      "epoch": 1.41,
      "learning_rate": 1.1436869939867076e-05,
      "loss": 0.4489,
      "step": 1100
    },
    {
      "epoch": 1.41,
      "learning_rate": 1.1423148382732854e-05,
      "loss": 0.464,
      "step": 1101
    },
    {
      "epoch": 1.41,
      "learning_rate": 1.1409424090140648e-05,
      "loss": 0.4704,
      "step": 1102
    },
    {
      "epoch": 1.42,
      "learning_rate": 1.1395697088470159e-05,
      "loss": 0.4464,
      "step": 1103
    },
    {
      "epoch": 1.42,
      "learning_rate": 1.1381967404106287e-05,
      "loss": 0.4369,
      "step": 1104
    },
    {
      "epoch": 1.42,
      "learning_rate": 1.1368235063439103e-05,
      "loss": 0.4606,
      "step": 1105
    },
    {
      "epoch": 1.42,
      "learning_rate": 1.1354500092863772e-05,
      "loss": 0.4593,
      "step": 1106
    },
    {
      "epoch": 1.42,
      "learning_rate": 1.1340762518780515e-05,
      "loss": 0.4624,
      "step": 1107
    },
    {
      "epoch": 1.42,
      "learning_rate": 1.1327022367594561e-05,
      "loss": 0.4697,
      "step": 1108
    },
    {
      "epoch": 1.42,
      "learning_rate": 1.131327966571609e-05,
      "loss": 0.4433,
      "step": 1109
    },
    {
      "epoch": 1.42,
      "learning_rate": 1.1299534439560186e-05,
      "loss": 0.4487,
      "step": 1110
    },
    {
      "epoch": 1.43,
      "learning_rate": 1.1285786715546788e-05,
      "loss": 0.4699,
      "step": 1111
    },
    {
      "epoch": 1.43,
      "learning_rate": 1.1272036520100627e-05,
      "loss": 0.4243,
      "step": 1112
    },
    {
      "epoch": 1.43,
      "learning_rate": 1.1258283879651195e-05,
      "loss": 0.4553,
      "step": 1113
    },
    {
      "epoch": 1.43,
      "learning_rate": 1.1244528820632676e-05,
      "loss": 0.4751,
      "step": 1114
    },
    {
      "epoch": 1.43,
      "learning_rate": 1.1230771369483906e-05,
      "loss": 0.4655,
      "step": 1115
    },
    {
      "epoch": 1.43,
      "learning_rate": 1.1217011552648316e-05,
      "loss": 0.4492,
      "step": 1116
    },
    {
      "epoch": 1.43,
      "learning_rate": 1.1203249396573894e-05,
      "loss": 0.4386,
      "step": 1117
    },
    {
      "epoch": 1.44,
      "learning_rate": 1.118948492771311e-05,
      "loss": 0.4509,
      "step": 1118
    },
    {
      "epoch": 1.44,
      "learning_rate": 1.117571817252289e-05,
      "loss": 0.4486,
      "step": 1119
    },
    {
      "epoch": 1.44,
      "learning_rate": 1.1161949157464546e-05,
      "loss": 0.4772,
      "step": 1120
    },
    {
      "epoch": 1.44,
      "learning_rate": 1.1148177909003746e-05,
      "loss": 0.4448,
      "step": 1121
    },
    {
      "epoch": 1.44,
      "learning_rate": 1.1134404453610437e-05,
      "loss": 0.4589,
      "step": 1122
    },
    {
      "epoch": 1.44,
      "learning_rate": 1.112062881775882e-05,
      "loss": 0.461,
      "step": 1123
    },
    {
      "epoch": 1.44,
      "learning_rate": 1.1106851027927277e-05,
      "loss": 0.4388,
      "step": 1124
    },
    {
      "epoch": 1.44,
      "learning_rate": 1.1093071110598333e-05,
      "loss": 0.4408,
      "step": 1125
    },
    {
      "epoch": 1.45,
      "learning_rate": 1.107928909225861e-05,
      "loss": 0.4676,
      "step": 1126
    },
    {
      "epoch": 1.45,
      "learning_rate": 1.1065504999398762e-05,
      "loss": 0.4677,
      "step": 1127
    },
    {
      "epoch": 1.45,
      "learning_rate": 1.1051718858513429e-05,
      "loss": 0.4531,
      "step": 1128
    },
    {
      "epoch": 1.45,
      "learning_rate": 1.1037930696101188e-05,
      "loss": 0.4465,
      "step": 1129
    },
    {
      "epoch": 1.45,
      "learning_rate": 1.1024140538664505e-05,
      "loss": 0.457,
      "step": 1130
    },
    {
      "epoch": 1.45,
      "learning_rate": 1.101034841270968e-05,
      "loss": 0.4673,
      "step": 1131
    },
    {
      "epoch": 1.45,
      "learning_rate": 1.0996554344746792e-05,
      "loss": 0.4584,
      "step": 1132
    },
    {
      "epoch": 1.45,
      "learning_rate": 1.0982758361289658e-05,
      "loss": 0.4509,
      "step": 1133
    },
    {
      "epoch": 1.46,
      "learning_rate": 1.0968960488855777e-05,
      "loss": 0.4608,
      "step": 1134
    },
    {
      "epoch": 1.46,
      "learning_rate": 1.0955160753966275e-05,
      "loss": 0.4345,
      "step": 1135
    },
    {
      "epoch": 1.46,
      "learning_rate": 1.0941359183145856e-05,
      "loss": 0.4412,
      "step": 1136
    },
    {
      "epoch": 1.46,
      "learning_rate": 1.0927555802922765e-05,
      "loss": 0.4434,
      "step": 1137
    },
    {
      "epoch": 1.46,
      "learning_rate": 1.091375063982871e-05,
      "loss": 0.4472,
      "step": 1138
    },
    {
      "epoch": 1.46,
      "learning_rate": 1.0899943720398838e-05,
      "loss": 0.4321,
      "step": 1139
    },
    {
      "epoch": 1.46,
      "learning_rate": 1.088613507117166e-05,
      "loss": 0.4455,
      "step": 1140
    },
    {
      "epoch": 1.46,
      "learning_rate": 1.0872324718689023e-05,
      "loss": 0.4694,
      "step": 1141
    },
    {
      "epoch": 1.47,
      "learning_rate": 1.085851268949604e-05,
      "loss": 0.4471,
      "step": 1142
    },
    {
      "epoch": 1.47,
      "learning_rate": 1.0844699010141051e-05,
      "loss": 0.4612,
      "step": 1143
    },
    {
      "epoch": 1.47,
      "learning_rate": 1.0830883707175566e-05,
      "loss": 0.4549,
      "step": 1144
    },
    {
      "epoch": 1.47,
      "learning_rate": 1.0817066807154216e-05,
      "loss": 0.4644,
      "step": 1145
    },
    {
      "epoch": 1.47,
      "learning_rate": 1.0803248336634705e-05,
      "loss": 0.4514,
      "step": 1146
    },
    {
      "epoch": 1.47,
      "learning_rate": 1.078942832217775e-05,
      "loss": 0.4422,
      "step": 1147
    },
    {
      "epoch": 1.47,
      "learning_rate": 1.0775606790347041e-05,
      "loss": 0.4537,
      "step": 1148
    },
    {
      "epoch": 1.47,
      "learning_rate": 1.0761783767709182e-05,
      "loss": 0.4394,
      "step": 1149
    },
    {
      "epoch": 1.48,
      "learning_rate": 1.0747959280833637e-05,
      "loss": 0.4518,
      "step": 1150
    },
    {
      "epoch": 1.48,
      "learning_rate": 1.0734133356292698e-05,
      "loss": 0.4428,
      "step": 1151
    },
    {
      "epoch": 1.48,
      "learning_rate": 1.0720306020661406e-05,
      "loss": 0.4485,
      "step": 1152
    },
    {
      "epoch": 1.48,
      "learning_rate": 1.0706477300517525e-05,
      "loss": 0.4662,
      "step": 1153
    },
    {
      "epoch": 1.48,
      "learning_rate": 1.0692647222441474e-05,
      "loss": 0.4556,
      "step": 1154
    },
    {
      "epoch": 1.48,
      "learning_rate": 1.0678815813016283e-05,
      "loss": 0.4567,
      "step": 1155
    },
    {
      "epoch": 1.48,
      "learning_rate": 1.0664983098827544e-05,
      "loss": 0.4494,
      "step": 1156
    },
    {
      "epoch": 1.49,
      "learning_rate": 1.065114910646335e-05,
      "loss": 0.4602,
      "step": 1157
    },
    {
      "epoch": 1.49,
      "learning_rate": 1.0637313862514263e-05,
      "loss": 0.4803,
      "step": 1158
    },
    {
      "epoch": 1.49,
      "learning_rate": 1.0623477393573239e-05,
      "loss": 0.4594,
      "step": 1159
    },
    {
      "epoch": 1.49,
      "learning_rate": 1.0609639726235592e-05,
      "loss": 0.4514,
      "step": 1160
    },
    {
      "epoch": 1.49,
      "learning_rate": 1.0595800887098943e-05,
      "loss": 0.4566,
      "step": 1161
    },
    {
      "epoch": 1.49,
      "learning_rate": 1.0581960902763162e-05,
      "loss": 0.4457,
      "step": 1162
    },
    {
      "epoch": 1.49,
      "learning_rate": 1.056811979983032e-05,
      "loss": 0.4546,
      "step": 1163
    },
    {
      "epoch": 1.49,
      "learning_rate": 1.0554277604904641e-05,
      "loss": 0.4623,
      "step": 1164
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.0540434344592445e-05,
      "loss": 0.4412,
      "step": 1165
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.05265900455021e-05,
      "loss": 0.4541,
      "step": 1166
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.051274473424397e-05,
      "loss": 0.438,
      "step": 1167
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.0498898437430367e-05,
      "loss": 0.4324,
      "step": 1168
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.0485051181675499e-05,
      "loss": 0.4463,
      "step": 1169
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.0471202993595413e-05,
      "loss": 0.425,
      "step": 1170
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.0457353899807947e-05,
      "loss": 0.4422,
      "step": 1171
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.0443503926932685e-05,
      "loss": 0.4459,
      "step": 1172
    },
    {
      "epoch": 1.51,
      "learning_rate": 1.0429653101590895e-05,
      "loss": 0.4594,
      "step": 1173
    },
    {
      "epoch": 1.51,
      "learning_rate": 1.041580145040549e-05,
      "loss": 0.4618,
      "step": 1174
    },
    {
      "epoch": 1.51,
      "learning_rate": 1.0401949000000967e-05,
      "loss": 0.4497,
      "step": 1175
    },
    {
      "epoch": 1.51,
      "learning_rate": 1.0388095777003358e-05,
      "loss": 0.4496,
      "step": 1176
    },
    {
      "epoch": 1.51,
      "learning_rate": 1.0374241808040182e-05,
      "loss": 0.4563,
      "step": 1177
    },
    {
      "epoch": 1.51,
      "learning_rate": 1.0360387119740387e-05,
      "loss": 0.448,
      "step": 1178
    },
    {
      "epoch": 1.51,
      "learning_rate": 1.0346531738734311e-05,
      "loss": 0.4493,
      "step": 1179
    },
    {
      "epoch": 1.51,
      "learning_rate": 1.0332675691653622e-05,
      "loss": 0.4613,
      "step": 1180
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.0318819005131263e-05,
      "loss": 0.4684,
      "step": 1181
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.0304961705801415e-05,
      "loss": 0.4516,
      "step": 1182
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.0291103820299424e-05,
      "loss": 0.4482,
      "step": 1183
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.0277245375261773e-05,
      "loss": 0.4572,
      "step": 1184
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.0263386397326019e-05,
      "loss": 0.451,
      "step": 1185
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.024952691313074e-05,
      "loss": 0.4457,
      "step": 1186
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.023566694931549e-05,
      "loss": 0.4441,
      "step": 1187
    },
    {
      "epoch": 1.53,
      "learning_rate": 1.0221806532520745e-05,
      "loss": 0.4313,
      "step": 1188
    },
    {
      "epoch": 1.53,
      "learning_rate": 1.0207945689387843e-05,
      "loss": 0.4616,
      "step": 1189
    },
    {
      "epoch": 1.53,
      "learning_rate": 1.019408444655896e-05,
      "loss": 0.4462,
      "step": 1190
    },
    {
      "epoch": 1.53,
      "learning_rate": 1.0180222830677025e-05,
      "loss": 0.4447,
      "step": 1191
    },
    {
      "epoch": 1.53,
      "learning_rate": 1.0166360868385686e-05,
      "loss": 0.4543,
      "step": 1192
    },
    {
      "epoch": 1.53,
      "learning_rate": 1.015249858632926e-05,
      "loss": 0.4394,
      "step": 1193
    },
    {
      "epoch": 1.53,
      "learning_rate": 1.0138636011152681e-05,
      "loss": 0.4481,
      "step": 1194
    },
    {
      "epoch": 1.53,
      "learning_rate": 1.0124773169501438e-05,
      "loss": 0.461,
      "step": 1195
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.0110910088021542e-05,
      "loss": 0.4375,
      "step": 1196
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.0097046793359455e-05,
      "loss": 0.4728,
      "step": 1197
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.0083183312162058e-05,
      "loss": 0.4537,
      "step": 1198
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.0069319671076588e-05,
      "loss": 0.4798,
      "step": 1199
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.0055455896750585e-05,
      "loss": 0.4525,
      "step": 1200
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.0041592015831849e-05,
      "loss": 0.4442,
      "step": 1201
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.0027728054968385e-05,
      "loss": 0.4575,
      "step": 1202
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.0013864040808347e-05,
      "loss": 0.4665,
      "step": 1203
    },
    {
      "epoch": 1.55,
      "learning_rate": 1e-05,
      "loss": 0.4642,
      "step": 1204
    },
    {
      "epoch": 1.55,
      "learning_rate": 9.986135959191651e-06,
      "loss": 0.4403,
      "step": 1205
    },
    {
      "epoch": 1.55,
      "learning_rate": 9.972271945031618e-06,
      "loss": 0.4572,
      "step": 1206
    },
    {
      "epoch": 1.55,
      "learning_rate": 9.95840798416815e-06,
      "loss": 0.4583,
      "step": 1207
    },
    {
      "epoch": 1.55,
      "learning_rate": 9.944544103249418e-06,
      "loss": 0.4765,
      "step": 1208
    },
    {
      "epoch": 1.55,
      "learning_rate": 9.930680328923414e-06,
      "loss": 0.4511,
      "step": 1209
    },
    {
      "epoch": 1.55,
      "learning_rate": 9.916816687837947e-06,
      "loss": 0.4774,
      "step": 1210
    },
    {
      "epoch": 1.55,
      "learning_rate": 9.902953206640548e-06,
      "loss": 0.4519,
      "step": 1211
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.889089911978465e-06,
      "loss": 0.4394,
      "step": 1212
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.875226830498565e-06,
      "loss": 0.4358,
      "step": 1213
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.861363988847326e-06,
      "loss": 0.4554,
      "step": 1214
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.847501413670742e-06,
      "loss": 0.4469,
      "step": 1215
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.833639131614314e-06,
      "loss": 0.4388,
      "step": 1216
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.819777169322978e-06,
      "loss": 0.4441,
      "step": 1217
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.80591555344104e-06,
      "loss": 0.4658,
      "step": 1218
    },
    {
      "epoch": 1.56,
      "learning_rate": 9.792054310612159e-06,
      "loss": 0.4505,
      "step": 1219
    },
    {
      "epoch": 1.57,
      "learning_rate": 9.778193467479259e-06,
      "loss": 0.4803,
      "step": 1220
    },
    {
      "epoch": 1.57,
      "learning_rate": 9.764333050684515e-06,
      "loss": 0.4742,
      "step": 1221
    },
    {
      "epoch": 1.57,
      "learning_rate": 9.750473086869262e-06,
      "loss": 0.4487,
      "step": 1222
    },
    {
      "epoch": 1.57,
      "learning_rate": 9.736613602673986e-06,
      "loss": 0.4647,
      "step": 1223
    },
    {
      "epoch": 1.57,
      "learning_rate": 9.722754624738229e-06,
      "loss": 0.4368,
      "step": 1224
    },
    {
      "epoch": 1.57,
      "learning_rate": 9.70889617970058e-06,
      "loss": 0.4473,
      "step": 1225
    },
    {
      "epoch": 1.57,
      "learning_rate": 9.695038294198588e-06,
      "loss": 0.4572,
      "step": 1226
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.681180994868735e-06,
      "loss": 0.441,
      "step": 1227
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.66732430834638e-06,
      "loss": 0.451,
      "step": 1228
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.653468261265689e-06,
      "loss": 0.4425,
      "step": 1229
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.639612880259615e-06,
      "loss": 0.4803,
      "step": 1230
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.625758191959821e-06,
      "loss": 0.434,
      "step": 1231
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.611904222996646e-06,
      "loss": 0.4453,
      "step": 1232
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.598050999999036e-06,
      "loss": 0.439,
      "step": 1233
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.584198549594512e-06,
      "loss": 0.448,
      "step": 1234
    },
    {
      "epoch": 1.59,
      "learning_rate": 9.570346898409109e-06,
      "loss": 0.4445,
      "step": 1235
    },
    {
      "epoch": 1.59,
      "learning_rate": 9.556496073067318e-06,
      "loss": 0.4638,
      "step": 1236
    },
    {
      "epoch": 1.59,
      "learning_rate": 9.542646100192056e-06,
      "loss": 0.4576,
      "step": 1237
    },
    {
      "epoch": 1.59,
      "learning_rate": 9.528797006404592e-06,
      "loss": 0.4441,
      "step": 1238
    },
    {
      "epoch": 1.59,
      "learning_rate": 9.514948818324504e-06,
      "loss": 0.4737,
      "step": 1239
    },
    {
      "epoch": 1.59,
      "learning_rate": 9.501101562569636e-06,
      "loss": 0.4765,
      "step": 1240
    },
    {
      "epoch": 1.59,
      "learning_rate": 9.487255265756035e-06,
      "loss": 0.47,
      "step": 1241
    },
    {
      "epoch": 1.59,
      "learning_rate": 9.473409954497902e-06,
      "loss": 0.4524,
      "step": 1242
    },
    {
      "epoch": 1.6,
      "learning_rate": 9.45956565540756e-06,
      "loss": 0.4401,
      "step": 1243
    },
    {
      "epoch": 1.6,
      "learning_rate": 9.44572239509536e-06,
      "loss": 0.4435,
      "step": 1244
    },
    {
      "epoch": 1.6,
      "learning_rate": 9.431880200169685e-06,
      "loss": 0.4527,
      "step": 1245
    },
    {
      "epoch": 1.6,
      "learning_rate": 9.418039097236842e-06,
      "loss": 0.4682,
      "step": 1246
    },
    {
      "epoch": 1.6,
      "learning_rate": 9.40419911290106e-06,
      "loss": 0.4647,
      "step": 1247
    },
    {
      "epoch": 1.6,
      "learning_rate": 9.390360273764411e-06,
      "loss": 0.448,
      "step": 1248
    },
    {
      "epoch": 1.6,
      "learning_rate": 9.376522606426763e-06,
      "loss": 0.4417,
      "step": 1249
    },
    {
      "epoch": 1.6,
      "learning_rate": 9.362686137485742e-06,
      "loss": 0.4454,
      "step": 1250
    },
    {
      "epoch": 1.61,
      "learning_rate": 9.348850893536651e-06,
      "loss": 0.4618,
      "step": 1251
    },
    {
      "epoch": 1.61,
      "learning_rate": 9.335016901172462e-06,
      "loss": 0.458,
      "step": 1252
    },
    {
      "epoch": 1.61,
      "learning_rate": 9.32118418698372e-06,
      "loss": 0.4661,
      "step": 1253
    },
    {
      "epoch": 1.61,
      "learning_rate": 9.307352777558531e-06,
      "loss": 0.448,
      "step": 1254
    },
    {
      "epoch": 1.61,
      "learning_rate": 9.293522699482478e-06,
      "loss": 0.4666,
      "step": 1255
    },
    {
      "epoch": 1.61,
      "learning_rate": 9.279693979338597e-06,
      "loss": 0.4566,
      "step": 1256
    },
    {
      "epoch": 1.61,
      "learning_rate": 9.265866643707305e-06,
      "loss": 0.4422,
      "step": 1257
    },
    {
      "epoch": 1.61,
      "learning_rate": 9.252040719166361e-06,
      "loss": 0.4357,
      "step": 1258
    },
    {
      "epoch": 1.62,
      "learning_rate": 9.238216232290821e-06,
      "loss": 0.466,
      "step": 1259
    },
    {
      "epoch": 1.62,
      "learning_rate": 9.224393209652959e-06,
      "loss": 0.4459,
      "step": 1260
    },
    {
      "epoch": 1.62,
      "learning_rate": 9.210571677822251e-06,
      "loss": 0.4308,
      "step": 1261
    },
    {
      "epoch": 1.62,
      "learning_rate": 9.196751663365295e-06,
      "loss": 0.4534,
      "step": 1262
    },
    {
      "epoch": 1.62,
      "learning_rate": 9.182933192845787e-06,
      "loss": 0.4549,
      "step": 1263
    },
    {
      "epoch": 1.62,
      "learning_rate": 9.169116292824435e-06,
      "loss": 0.4447,
      "step": 1264
    },
    {
      "epoch": 1.62,
      "learning_rate": 9.155300989858954e-06,
      "loss": 0.4702,
      "step": 1265
    },
    {
      "epoch": 1.63,
      "learning_rate": 9.141487310503964e-06,
      "loss": 0.4605,
      "step": 1266
    },
    {
      "epoch": 1.63,
      "learning_rate": 9.127675281310983e-06,
      "loss": 0.4302,
      "step": 1267
    },
    {
      "epoch": 1.63,
      "learning_rate": 9.113864928828341e-06,
      "loss": 0.4456,
      "step": 1268
    },
    {
      "epoch": 1.63,
      "learning_rate": 9.100056279601162e-06,
      "loss": 0.4447,
      "step": 1269
    },
    {
      "epoch": 1.63,
      "learning_rate": 9.086249360171291e-06,
      "loss": 0.4638,
      "step": 1270
    },
    {
      "epoch": 1.63,
      "learning_rate": 9.072444197077235e-06,
      "loss": 0.4531,
      "step": 1271
    },
    {
      "epoch": 1.63,
      "learning_rate": 9.058640816854147e-06,
      "loss": 0.437,
      "step": 1272
    },
    {
      "epoch": 1.63,
      "learning_rate": 9.044839246033727e-06,
      "loss": 0.4532,
      "step": 1273
    },
    {
      "epoch": 1.64,
      "learning_rate": 9.031039511144228e-06,
      "loss": 0.4468,
      "step": 1274
    },
    {
      "epoch": 1.64,
      "learning_rate": 9.017241638710343e-06,
      "loss": 0.4497,
      "step": 1275
    },
    {
      "epoch": 1.64,
      "learning_rate": 9.003445655253213e-06,
      "loss": 0.4467,
      "step": 1276
    },
    {
      "epoch": 1.64,
      "learning_rate": 8.989651587290323e-06,
      "loss": 0.4444,
      "step": 1277
    },
    {
      "epoch": 1.64,
      "learning_rate": 8.9758594613355e-06,
      "loss": 0.4437,
      "step": 1278
    },
    {
      "epoch": 1.64,
      "learning_rate": 8.962069303898815e-06,
      "loss": 0.455,
      "step": 1279
    },
    {
      "epoch": 1.64,
      "learning_rate": 8.948281141486573e-06,
      "loss": 0.4696,
      "step": 1280
    },
    {
      "epoch": 1.64,
      "learning_rate": 8.934495000601241e-06,
      "loss": 0.4628,
      "step": 1281
    },
    {
      "epoch": 1.65,
      "learning_rate": 8.92071090774139e-06,
      "loss": 0.4284,
      "step": 1282
    },
    {
      "epoch": 1.65,
      "learning_rate": 8.90692888940167e-06,
      "loss": 0.4488,
      "step": 1283
    },
    {
      "epoch": 1.65,
      "learning_rate": 8.893148972072728e-06,
      "loss": 0.4433,
      "step": 1284
    },
    {
      "epoch": 1.65,
      "learning_rate": 8.879371182241186e-06,
      "loss": 0.4511,
      "step": 1285
    },
    {
      "epoch": 1.65,
      "learning_rate": 8.865595546389565e-06,
      "loss": 0.4549,
      "step": 1286
    },
    {
      "epoch": 1.65,
      "learning_rate": 8.851822090996259e-06,
      "loss": 0.4511,
      "step": 1287
    },
    {
      "epoch": 1.65,
      "learning_rate": 8.838050842535456e-06,
      "loss": 0.4475,
      "step": 1288
    },
    {
      "epoch": 1.65,
      "learning_rate": 8.824281827477112e-06,
      "loss": 0.4566,
      "step": 1289
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.810515072286894e-06,
      "loss": 0.4468,
      "step": 1290
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.796750603426107e-06,
      "loss": 0.4755,
      "step": 1291
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.782988447351685e-06,
      "loss": 0.4552,
      "step": 1292
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.769228630516097e-06,
      "loss": 0.4418,
      "step": 1293
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.755471179367328e-06,
      "loss": 0.4452,
      "step": 1294
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.74171612034881e-06,
      "loss": 0.4364,
      "step": 1295
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.727963479899375e-06,
      "loss": 0.4359,
      "step": 1296
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.714213284453216e-06,
      "loss": 0.4408,
      "step": 1297
    },
    {
      "epoch": 1.67,
      "learning_rate": 8.700465560439817e-06,
      "loss": 0.4565,
      "step": 1298
    },
    {
      "epoch": 1.67,
      "learning_rate": 8.686720334283912e-06,
      "loss": 0.4648,
      "step": 1299
    },
    {
      "epoch": 1.67,
      "learning_rate": 8.67297763240544e-06,
      "loss": 0.451,
      "step": 1300
    },
    {
      "epoch": 1.67,
      "learning_rate": 8.659237481219488e-06,
      "loss": 0.4515,
      "step": 1301
    },
    {
      "epoch": 1.67,
      "learning_rate": 8.645499907136233e-06,
      "loss": 0.4387,
      "step": 1302
    },
    {
      "epoch": 1.67,
      "learning_rate": 8.6317649365609e-06,
      "loss": 0.4533,
      "step": 1303
    },
    {
      "epoch": 1.67,
      "learning_rate": 8.618032595893715e-06,
      "loss": 0.4509,
      "step": 1304
    },
    {
      "epoch": 1.68,
      "learning_rate": 8.604302911529848e-06,
      "loss": 0.4583,
      "step": 1305
    },
    {
      "epoch": 1.68,
      "learning_rate": 8.590575909859355e-06,
      "loss": 0.4464,
      "step": 1306
    },
    {
      "epoch": 1.68,
      "learning_rate": 8.576851617267151e-06,
      "loss": 0.4607,
      "step": 1307
    },
    {
      "epoch": 1.68,
      "learning_rate": 8.563130060132925e-06,
      "loss": 0.4511,
      "step": 1308
    },
    {
      "epoch": 1.68,
      "learning_rate": 8.549411264831129e-06,
      "loss": 0.4489,
      "step": 1309
    },
    {
      "epoch": 1.68,
      "learning_rate": 8.535695257730886e-06,
      "loss": 0.4513,
      "step": 1310
    },
    {
      "epoch": 1.68,
      "learning_rate": 8.52198206519597e-06,
      "loss": 0.4545,
      "step": 1311
    },
    {
      "epoch": 1.68,
      "learning_rate": 8.508271713584753e-06,
      "loss": 0.4617,
      "step": 1312
    },
    {
      "epoch": 1.69,
      "learning_rate": 8.494564229250128e-06,
      "loss": 0.4414,
      "step": 1313
    },
    {
      "epoch": 1.69,
      "learning_rate": 8.480859638539492e-06,
      "loss": 0.4519,
      "step": 1314
    },
    {
      "epoch": 1.69,
      "learning_rate": 8.46715796779467e-06,
      "loss": 0.4563,
      "step": 1315
    },
    {
      "epoch": 1.69,
      "learning_rate": 8.453459243351886e-06,
      "loss": 0.4554,
      "step": 1316
    },
    {
      "epoch": 1.69,
      "learning_rate": 8.439763491541683e-06,
      "loss": 0.4569,
      "step": 1317
    },
    {
      "epoch": 1.69,
      "learning_rate": 8.426070738688912e-06,
      "loss": 0.461,
      "step": 1318
    },
    {
      "epoch": 1.69,
      "learning_rate": 8.412381011112641e-06,
      "loss": 0.4504,
      "step": 1319
    },
    {
      "epoch": 1.69,
      "learning_rate": 8.39869433512614e-06,
      "loss": 0.4516,
      "step": 1320
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.385010737036789e-06,
      "loss": 0.4397,
      "step": 1321
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.37133024314608e-06,
      "loss": 0.4408,
      "step": 1322
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.357652879749525e-06,
      "loss": 0.4613,
      "step": 1323
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.343978673136614e-06,
      "loss": 0.4596,
      "step": 1324
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.330307649590782e-06,
      "loss": 0.4659,
      "step": 1325
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.316639835389327e-06,
      "loss": 0.4569,
      "step": 1326
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.302975256803401e-06,
      "loss": 0.4487,
      "step": 1327
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.289313940097918e-06,
      "loss": 0.4491,
      "step": 1328
    },
    {
      "epoch": 1.71,
      "learning_rate": 8.275655911531538e-06,
      "loss": 0.4575,
      "step": 1329
    },
    {
      "epoch": 1.71,
      "learning_rate": 8.26200119735658e-06,
      "loss": 0.4435,
      "step": 1330
    },
    {
      "epoch": 1.71,
      "learning_rate": 8.24834982381902e-06,
      "loss": 0.46,
      "step": 1331
    },
    {
      "epoch": 1.71,
      "learning_rate": 8.234701817158384e-06,
      "loss": 0.4635,
      "step": 1332
    },
    {
      "epoch": 1.71,
      "learning_rate": 8.221057203607748e-06,
      "loss": 0.462,
      "step": 1333
    },
    {
      "epoch": 1.71,
      "learning_rate": 8.207416009393659e-06,
      "loss": 0.4593,
      "step": 1334
    },
    {
      "epoch": 1.71,
      "learning_rate": 8.193778260736087e-06,
      "loss": 0.4448,
      "step": 1335
    },
    {
      "epoch": 1.72,
      "learning_rate": 8.180143983848388e-06,
      "loss": 0.4521,
      "step": 1336
    },
    {
      "epoch": 1.72,
      "learning_rate": 8.166513204937232e-06,
      "loss": 0.4625,
      "step": 1337
    },
    {
      "epoch": 1.72,
      "learning_rate": 8.152885950202585e-06,
      "loss": 0.4408,
      "step": 1338
    },
    {
      "epoch": 1.72,
      "learning_rate": 8.139262245837618e-06,
      "loss": 0.4409,
      "step": 1339
    },
    {
      "epoch": 1.72,
      "learning_rate": 8.125642118028694e-06,
      "loss": 0.4284,
      "step": 1340
    },
    {
      "epoch": 1.72,
      "learning_rate": 8.112025592955289e-06,
      "loss": 0.4288,
      "step": 1341
    },
    {
      "epoch": 1.72,
      "learning_rate": 8.098412696789961e-06,
      "loss": 0.4637,
      "step": 1342
    },
    {
      "epoch": 1.72,
      "learning_rate": 8.0848034556983e-06,
      "loss": 0.4547,
      "step": 1343
    },
    {
      "epoch": 1.73,
      "learning_rate": 8.071197895838852e-06,
      "loss": 0.4438,
      "step": 1344
    },
    {
      "epoch": 1.73,
      "learning_rate": 8.057596043363104e-06,
      "loss": 0.4518,
      "step": 1345
    },
    {
      "epoch": 1.73,
      "learning_rate": 8.043997924415405e-06,
      "loss": 0.4532,
      "step": 1346
    },
    {
      "epoch": 1.73,
      "learning_rate": 8.030403565132942e-06,
      "loss": 0.4645,
      "step": 1347
    },
    {
      "epoch": 1.73,
      "learning_rate": 8.016812991645658e-06,
      "loss": 0.4354,
      "step": 1348
    },
    {
      "epoch": 1.73,
      "learning_rate": 8.003226230076235e-06,
      "loss": 0.4672,
      "step": 1349
    },
    {
      "epoch": 1.73,
      "learning_rate": 7.989643306540012e-06,
      "loss": 0.4478,
      "step": 1350
    },
    {
      "epoch": 1.73,
      "learning_rate": 7.976064247144969e-06,
      "loss": 0.4551,
      "step": 1351
    },
    {
      "epoch": 1.74,
      "learning_rate": 7.962489077991645e-06,
      "loss": 0.4297,
      "step": 1352
    },
    {
      "epoch": 1.74,
      "learning_rate": 7.948917825173106e-06,
      "loss": 0.448,
      "step": 1353
    },
    {
      "epoch": 1.74,
      "learning_rate": 7.935350514774897e-06,
      "loss": 0.4461,
      "step": 1354
    },
    {
      "epoch": 1.74,
      "learning_rate": 7.921787172874968e-06,
      "loss": 0.4448,
      "step": 1355
    },
    {
      "epoch": 1.74,
      "learning_rate": 7.908227825543663e-06,
      "loss": 0.4615,
      "step": 1356
    },
    {
      "epoch": 1.74,
      "learning_rate": 7.894672498843624e-06,
      "loss": 0.462,
      "step": 1357
    },
    {
      "epoch": 1.74,
      "learning_rate": 7.881121218829789e-06,
      "loss": 0.4655,
      "step": 1358
    },
    {
      "epoch": 1.74,
      "learning_rate": 7.8675740115493e-06,
      "loss": 0.4523,
      "step": 1359
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.854030903041481e-06,
      "loss": 0.4468,
      "step": 1360
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.840491919337771e-06,
      "loss": 0.4524,
      "step": 1361
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.826957086461683e-06,
      "loss": 0.4465,
      "step": 1362
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.813426430428752e-06,
      "loss": 0.451,
      "step": 1363
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.799899977246487e-06,
      "loss": 0.4486,
      "step": 1364
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.786377752914316e-06,
      "loss": 0.4564,
      "step": 1365
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.77285978342354e-06,
      "loss": 0.4434,
      "step": 1366
    },
    {
      "epoch": 1.75,
      "learning_rate": 7.759346094757277e-06,
      "loss": 0.4389,
      "step": 1367
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.745836712890423e-06,
      "loss": 0.4389,
      "step": 1368
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.732331663789592e-06,
      "loss": 0.4472,
      "step": 1369
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.71883097341307e-06,
      "loss": 0.4428,
      "step": 1370
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.70533466771077e-06,
      "loss": 0.4428,
      "step": 1371
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.691842772624169e-06,
      "loss": 0.4412,
      "step": 1372
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.678355314086276e-06,
      "loss": 0.449,
      "step": 1373
    },
    {
      "epoch": 1.76,
      "learning_rate": 7.664872318021561e-06,
      "loss": 0.4389,
      "step": 1374
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.651393810345924e-06,
      "loss": 0.4361,
      "step": 1375
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.637919816966643e-06,
      "loss": 0.4478,
      "step": 1376
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.624450363782301e-06,
      "loss": 0.439,
      "step": 1377
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.610985476682777e-06,
      "loss": 0.4498,
      "step": 1378
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.597525181549154e-06,
      "loss": 0.4645,
      "step": 1379
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.584069504253703e-06,
      "loss": 0.4629,
      "step": 1380
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.570618470659805e-06,
      "loss": 0.4376,
      "step": 1381
    },
    {
      "epoch": 1.77,
      "learning_rate": 7.557172106621932e-06,
      "loss": 0.4457,
      "step": 1382
    },
    {
      "epoch": 1.78,
      "learning_rate": 7.5437304379855614e-06,
      "loss": 0.4397,
      "step": 1383
    },
    {
      "epoch": 1.78,
      "learning_rate": 7.530293490587167e-06,
      "loss": 0.4536,
      "step": 1384
    },
    {
      "epoch": 1.78,
      "learning_rate": 7.516861290254127e-06,
      "loss": 0.4418,
      "step": 1385
    },
    {
      "epoch": 1.78,
      "learning_rate": 7.503433862804708e-06,
      "loss": 0.4506,
      "step": 1386
    },
    {
      "epoch": 1.78,
      "learning_rate": 7.490011234048002e-06,
      "loss": 0.4375,
      "step": 1387
    },
    {
      "epoch": 1.78,
      "learning_rate": 7.476593429783872e-06,
      "loss": 0.4457,
      "step": 1388
    },
    {
      "epoch": 1.78,
      "learning_rate": 7.463180475802911e-06,
      "loss": 0.4509,
      "step": 1389
    },
    {
      "epoch": 1.78,
      "learning_rate": 7.449772397886386e-06,
      "loss": 0.4667,
      "step": 1390
    },
    {
      "epoch": 1.79,
      "learning_rate": 7.436369221806201e-06,
      "loss": 0.4429,
      "step": 1391
    },
    {
      "epoch": 1.79,
      "learning_rate": 7.4229709733248214e-06,
      "loss": 0.4707,
      "step": 1392
    },
    {
      "epoch": 1.79,
      "learning_rate": 7.409577678195261e-06,
      "loss": 0.4451,
      "step": 1393
    },
    {
      "epoch": 1.79,
      "learning_rate": 7.396189362160993e-06,
      "loss": 0.4483,
      "step": 1394
    },
    {
      "epoch": 1.79,
      "learning_rate": 7.3828060509559355e-06,
      "loss": 0.4476,
      "step": 1395
    },
    {
      "epoch": 1.79,
      "learning_rate": 7.3694277703043845e-06,
      "loss": 0.4633,
      "step": 1396
    },
    {
      "epoch": 1.79,
      "learning_rate": 7.356054545920954e-06,
      "loss": 0.4423,
      "step": 1397
    },
    {
      "epoch": 1.79,
      "learning_rate": 7.342686403510561e-06,
      "loss": 0.4498,
      "step": 1398
    },
    {
      "epoch": 1.8,
      "learning_rate": 7.329323368768329e-06,
      "loss": 0.4516,
      "step": 1399
    },
    {
      "epoch": 1.8,
      "learning_rate": 7.315965467379587e-06,
      "loss": 0.4714,
      "step": 1400
    },
    {
      "epoch": 1.8,
      "learning_rate": 7.302612725019779e-06,
      "loss": 0.4376,
      "step": 1401
    },
    {
      "epoch": 1.8,
      "learning_rate": 7.289265167354449e-06,
      "loss": 0.4532,
      "step": 1402
    },
    {
      "epoch": 1.8,
      "learning_rate": 7.275922820039158e-06,
      "loss": 0.4257,
      "step": 1403
    },
    {
      "epoch": 1.8,
      "learning_rate": 7.26258570871947e-06,
      "loss": 0.4359,
      "step": 1404
    },
    {
      "epoch": 1.8,
      "learning_rate": 7.249253859030868e-06,
      "loss": 0.4496,
      "step": 1405
    },
    {
      "epoch": 1.8,
      "learning_rate": 7.235927296598734e-06,
      "loss": 0.4626,
      "step": 1406
    },
    {
      "epoch": 1.81,
      "learning_rate": 7.2226060470382864e-06,
      "loss": 0.4494,
      "step": 1407
    },
    {
      "epoch": 1.81,
      "learning_rate": 7.20929013595452e-06,
      "loss": 0.4331,
      "step": 1408
    },
    {
      "epoch": 1.81,
      "learning_rate": 7.195979588942185e-06,
      "loss": 0.4755,
      "step": 1409
    },
    {
      "epoch": 1.81,
      "learning_rate": 7.182674431585703e-06,
      "loss": 0.4364,
      "step": 1410
    },
    {
      "epoch": 1.81,
      "learning_rate": 7.1693746894591566e-06,
      "loss": 0.4449,
      "step": 1411
    },
    {
      "epoch": 1.81,
      "learning_rate": 7.1560803881262e-06,
      "loss": 0.4483,
      "step": 1412
    },
    {
      "epoch": 1.81,
      "learning_rate": 7.142791553140045e-06,
      "loss": 0.4229,
      "step": 1413
    },
    {
      "epoch": 1.82,
      "learning_rate": 7.129508210043383e-06,
      "loss": 0.4489,
      "step": 1414
    },
    {
      "epoch": 1.82,
      "learning_rate": 7.116230384368361e-06,
      "loss": 0.4447,
      "step": 1415
    },
    {
      "epoch": 1.82,
      "learning_rate": 7.102958101636516e-06,
      "loss": 0.4498,
      "step": 1416
    },
    {
      "epoch": 1.82,
      "learning_rate": 7.089691387358729e-06,
      "loss": 0.4498,
      "step": 1417
    },
    {
      "epoch": 1.82,
      "learning_rate": 7.0764302670351835e-06,
      "loss": 0.455,
      "step": 1418
    },
    {
      "epoch": 1.82,
      "learning_rate": 7.063174766155301e-06,
      "loss": 0.4518,
      "step": 1419
    },
    {
      "epoch": 1.82,
      "learning_rate": 7.049924910197712e-06,
      "loss": 0.4548,
      "step": 1420
    },
    {
      "epoch": 1.82,
      "learning_rate": 7.0366807246301915e-06,
      "loss": 0.4462,
      "step": 1421
    },
    {
      "epoch": 1.83,
      "learning_rate": 7.023442234909618e-06,
      "loss": 0.4461,
      "step": 1422
    },
    {
      "epoch": 1.83,
      "learning_rate": 7.0102094664819165e-06,
      "loss": 0.4532,
      "step": 1423
    },
    {
      "epoch": 1.83,
      "learning_rate": 6.996982444782021e-06,
      "loss": 0.4508,
      "step": 1424
    },
    {
      "epoch": 1.83,
      "learning_rate": 6.983761195233818e-06,
      "loss": 0.4617,
      "step": 1425
    },
    {
      "epoch": 1.83,
      "learning_rate": 6.970545743250099e-06,
      "loss": 0.4551,
      "step": 1426
    },
    {
      "epoch": 1.83,
      "learning_rate": 6.957336114232507e-06,
      "loss": 0.4461,
      "step": 1427
    },
    {
      "epoch": 1.83,
      "learning_rate": 6.944132333571503e-06,
      "loss": 0.4396,
      "step": 1428
    },
    {
      "epoch": 1.83,
      "learning_rate": 6.930934426646297e-06,
      "loss": 0.4415,
      "step": 1429
    },
    {
      "epoch": 1.84,
      "learning_rate": 6.9177424188248155e-06,
      "loss": 0.4536,
      "step": 1430
    },
    {
      "epoch": 1.84,
      "learning_rate": 6.904556335463643e-06,
      "loss": 0.4427,
      "step": 1431
    },
    {
      "epoch": 1.84,
      "learning_rate": 6.891376201907975e-06,
      "loss": 0.4582,
      "step": 1432
    },
    {
      "epoch": 1.84,
      "learning_rate": 6.878202043491578e-06,
      "loss": 0.4382,
      "step": 1433
    },
    {
      "epoch": 1.84,
      "learning_rate": 6.865033885536719e-06,
      "loss": 0.4574,
      "step": 1434
    },
    {
      "epoch": 1.84,
      "learning_rate": 6.851871753354154e-06,
      "loss": 0.4542,
      "step": 1435
    },
    {
      "epoch": 1.84,
      "learning_rate": 6.83871567224303e-06,
      "loss": 0.4687,
      "step": 1436
    },
    {
      "epoch": 1.84,
      "learning_rate": 6.8255656674908865e-06,
      "loss": 0.4462,
      "step": 1437
    },
    {
      "epoch": 1.85,
      "learning_rate": 6.81242176437357e-06,
      "loss": 0.4499,
      "step": 1438
    },
    {
      "epoch": 1.85,
      "learning_rate": 6.799283988155202e-06,
      "loss": 0.4461,
      "step": 1439
    },
    {
      "epoch": 1.85,
      "learning_rate": 6.786152364088133e-06,
      "loss": 0.4543,
      "step": 1440
    },
    {
      "epoch": 1.85,
      "learning_rate": 6.773026917412876e-06,
      "loss": 0.4519,
      "step": 1441
    },
    {
      "epoch": 1.85,
      "learning_rate": 6.759907673358086e-06,
      "loss": 0.4583,
      "step": 1442
    },
    {
      "epoch": 1.85,
      "learning_rate": 6.746794657140479e-06,
      "loss": 0.4386,
      "step": 1443
    },
    {
      "epoch": 1.85,
      "learning_rate": 6.7336878939648176e-06,
      "loss": 0.4381,
      "step": 1444
    },
    {
      "epoch": 1.85,
      "learning_rate": 6.720587409023829e-06,
      "loss": 0.4545,
      "step": 1445
    },
    {
      "epoch": 1.86,
      "learning_rate": 6.707493227498187e-06,
      "loss": 0.4468,
      "step": 1446
    },
    {
      "epoch": 1.86,
      "learning_rate": 6.694405374556436e-06,
      "loss": 0.434,
      "step": 1447
    },
    {
      "epoch": 1.86,
      "learning_rate": 6.681323875354968e-06,
      "loss": 0.4715,
      "step": 1448
    },
    {
      "epoch": 1.86,
      "learning_rate": 6.668248755037961e-06,
      "loss": 0.4553,
      "step": 1449
    },
    {
      "epoch": 1.86,
      "learning_rate": 6.655180038737321e-06,
      "loss": 0.4522,
      "step": 1450
    },
    {
      "epoch": 1.86,
      "learning_rate": 6.642117751572661e-06,
      "loss": 0.4535,
      "step": 1451
    },
    {
      "epoch": 1.86,
      "learning_rate": 6.6290619186512175e-06,
      "loss": 0.4591,
      "step": 1452
    },
    {
      "epoch": 1.87,
      "learning_rate": 6.616012565067841e-06,
      "loss": 0.4667,
      "step": 1453
    },
    {
      "epoch": 1.87,
      "learning_rate": 6.60296971590491e-06,
      "loss": 0.4458,
      "step": 1454
    },
    {
      "epoch": 1.87,
      "learning_rate": 6.589933396232319e-06,
      "loss": 0.4463,
      "step": 1455
    },
    {
      "epoch": 1.87,
      "learning_rate": 6.576903631107392e-06,
      "loss": 0.4366,
      "step": 1456
    },
    {
      "epoch": 1.87,
      "learning_rate": 6.563880445574873e-06,
      "loss": 0.4527,
      "step": 1457
    },
    {
      "epoch": 1.87,
      "learning_rate": 6.550863864666843e-06,
      "loss": 0.4533,
      "step": 1458
    },
    {
      "epoch": 1.87,
      "learning_rate": 6.537853913402701e-06,
      "loss": 0.456,
      "step": 1459
    },
    {
      "epoch": 1.87,
      "learning_rate": 6.524850616789102e-06,
      "loss": 0.4544,
      "step": 1460
    },
    {
      "epoch": 1.88,
      "learning_rate": 6.511853999819897e-06,
      "loss": 0.4432,
      "step": 1461
    },
    {
      "epoch": 1.88,
      "learning_rate": 6.498864087476115e-06,
      "loss": 0.4575,
      "step": 1462
    },
    {
      "epoch": 1.88,
      "learning_rate": 6.485880904725883e-06,
      "loss": 0.4521,
      "step": 1463
    },
    {
      "epoch": 1.88,
      "learning_rate": 6.4729044765244075e-06,
      "loss": 0.4509,
      "step": 1464
    },
    {
      "epoch": 1.88,
      "learning_rate": 6.459934827813896e-06,
      "loss": 0.4596,
      "step": 1465
    },
    {
      "epoch": 1.88,
      "learning_rate": 6.4469719835235426e-06,
      "loss": 0.4301,
      "step": 1466
    },
    {
      "epoch": 1.88,
      "learning_rate": 6.4340159685694425e-06,
      "loss": 0.4233,
      "step": 1467
    },
    {
      "epoch": 1.88,
      "learning_rate": 6.421066807854585e-06,
      "loss": 0.4347,
      "step": 1468
    },
    {
      "epoch": 1.89,
      "learning_rate": 6.408124526268766e-06,
      "loss": 0.4483,
      "step": 1469
    },
    {
      "epoch": 1.89,
      "learning_rate": 6.395189148688572e-06,
      "loss": 0.4429,
      "step": 1470
    },
    {
      "epoch": 1.89,
      "learning_rate": 6.382260699977318e-06,
      "loss": 0.4361,
      "step": 1471
    },
    {
      "epoch": 1.89,
      "learning_rate": 6.36933920498499e-06,
      "loss": 0.4498,
      "step": 1472
    },
    {
      "epoch": 1.89,
      "learning_rate": 6.356424688548224e-06,
      "loss": 0.456,
      "step": 1473
    },
    {
      "epoch": 1.89,
      "learning_rate": 6.343517175490227e-06,
      "loss": 0.4431,
      "step": 1474
    },
    {
      "epoch": 1.89,
      "learning_rate": 6.330616690620758e-06,
      "loss": 0.4481,
      "step": 1475
    },
    {
      "epoch": 1.89,
      "learning_rate": 6.317723258736053e-06,
      "loss": 0.4455,
      "step": 1476
    },
    {
      "epoch": 1.9,
      "learning_rate": 6.304836904618806e-06,
      "loss": 0.4405,
      "step": 1477
    },
    {
      "epoch": 1.9,
      "learning_rate": 6.291957653038099e-06,
      "loss": 0.4426,
      "step": 1478
    },
    {
      "epoch": 1.9,
      "learning_rate": 6.2790855287493605e-06,
      "loss": 0.4446,
      "step": 1479
    },
    {
      "epoch": 1.9,
      "learning_rate": 6.266220556494322e-06,
      "loss": 0.4524,
      "step": 1480
    },
    {
      "epoch": 1.9,
      "learning_rate": 6.25336276100097e-06,
      "loss": 0.4531,
      "step": 1481
    },
    {
      "epoch": 1.9,
      "learning_rate": 6.240512166983496e-06,
      "loss": 0.4516,
      "step": 1482
    },
    {
      "epoch": 1.9,
      "learning_rate": 6.227668799142241e-06,
      "loss": 0.4497,
      "step": 1483
    },
    {
      "epoch": 1.91,
      "learning_rate": 6.21483268216367e-06,
      "loss": 0.4474,
      "step": 1484
    },
    {
      "epoch": 1.91,
      "learning_rate": 6.202003840720301e-06,
      "loss": 0.4514,
      "step": 1485
    },
    {
      "epoch": 1.91,
      "learning_rate": 6.189182299470671e-06,
      "loss": 0.4543,
      "step": 1486
    },
    {
      "epoch": 1.91,
      "learning_rate": 6.176368083059287e-06,
      "loss": 0.4408,
      "step": 1487
    },
    {
      "epoch": 1.91,
      "learning_rate": 6.163561216116572e-06,
      "loss": 0.4423,
      "step": 1488
    },
    {
      "epoch": 1.91,
      "learning_rate": 6.150761723258824e-06,
      "loss": 0.4491,
      "step": 1489
    },
    {
      "epoch": 1.91,
      "learning_rate": 6.137969629088174e-06,
      "loss": 0.4449,
      "step": 1490
    },
    {
      "epoch": 1.91,
      "learning_rate": 6.125184958192523e-06,
      "loss": 0.4663,
      "step": 1491
    },
    {
      "epoch": 1.92,
      "learning_rate": 6.112407735145505e-06,
      "loss": 0.4484,
      "step": 1492
    },
    {
      "epoch": 1.92,
      "learning_rate": 6.099637984506443e-06,
      "loss": 0.4818,
      "step": 1493
    },
    {
      "epoch": 1.92,
      "learning_rate": 6.086875730820294e-06,
      "loss": 0.4372,
      "step": 1494
    },
    {
      "epoch": 1.92,
      "learning_rate": 6.074120998617603e-06,
      "loss": 0.4331,
      "step": 1495
    },
    {
      "epoch": 1.92,
      "learning_rate": 6.061373812414461e-06,
      "loss": 0.4585,
      "step": 1496
    },
    {
      "epoch": 1.92,
      "learning_rate": 6.048634196712457e-06,
      "loss": 0.4579,
      "step": 1497
    },
    {
      "epoch": 1.92,
      "learning_rate": 6.0359021759986205e-06,
      "loss": 0.445,
      "step": 1498
    },
    {
      "epoch": 1.92,
      "learning_rate": 6.023177774745394e-06,
      "loss": 0.4635,
      "step": 1499
    },
    {
      "epoch": 1.93,
      "learning_rate": 6.01046101741056e-06,
      "loss": 0.4506,
      "step": 1500
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.99775192843722e-06,
      "loss": 0.425,
      "step": 1501
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.9850505322537366e-06,
      "loss": 0.4562,
      "step": 1502
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.972356853273675e-06,
      "loss": 0.4543,
      "step": 1503
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.959670915895781e-06,
      "loss": 0.4626,
      "step": 1504
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.946992744503904e-06,
      "loss": 0.4389,
      "step": 1505
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.934322363466985e-06,
      "loss": 0.4484,
      "step": 1506
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.9216597971389745e-06,
      "loss": 0.4416,
      "step": 1507
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.909005069858813e-06,
      "loss": 0.4473,
      "step": 1508
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.896358205950364e-06,
      "loss": 0.4533,
      "step": 1509
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.8837192297223915e-06,
      "loss": 0.4515,
      "step": 1510
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.871088165468477e-06,
      "loss": 0.4457,
      "step": 1511
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.858465037467014e-06,
      "loss": 0.4499,
      "step": 1512
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.845849869981137e-06,
      "loss": 0.4519,
      "step": 1513
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.83324268725867e-06,
      "loss": 0.4485,
      "step": 1514
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.820643513532096e-06,
      "loss": 0.4639,
      "step": 1515
    },
    {
      "epoch": 1.95,
      "learning_rate": 5.808052373018509e-06,
      "loss": 0.4626,
      "step": 1516
    },
    {
      "epoch": 1.95,
      "learning_rate": 5.795469289919549e-06,
      "loss": 0.4608,
      "step": 1517
    },
    {
      "epoch": 1.95,
      "learning_rate": 5.782894288421383e-06,
      "loss": 0.4333,
      "step": 1518
    },
    {
      "epoch": 1.95,
      "learning_rate": 5.770327392694634e-06,
      "loss": 0.4465,
      "step": 1519
    },
    {
      "epoch": 1.95,
      "learning_rate": 5.757768626894352e-06,
      "loss": 0.4479,
      "step": 1520
    },
    {
      "epoch": 1.95,
      "learning_rate": 5.74521801515995e-06,
      "loss": 0.4548,
      "step": 1521
    },
    {
      "epoch": 1.95,
      "learning_rate": 5.73267558161518e-06,
      "loss": 0.4455,
      "step": 1522
    },
    {
      "epoch": 1.96,
      "learning_rate": 5.720141350368072e-06,
      "loss": 0.4506,
      "step": 1523
    },
    {
      "epoch": 1.96,
      "learning_rate": 5.70761534551088e-06,
      "loss": 0.4512,
      "step": 1524
    },
    {
      "epoch": 1.96,
      "learning_rate": 5.69509759112006e-06,
      "loss": 0.4434,
      "step": 1525
    },
    {
      "epoch": 1.96,
      "learning_rate": 5.682588111256197e-06,
      "loss": 0.4657,
      "step": 1526
    },
    {
      "epoch": 1.96,
      "learning_rate": 5.670086929963981e-06,
      "loss": 0.4442,
      "step": 1527
    },
    {
      "epoch": 1.96,
      "learning_rate": 5.65759407127215e-06,
      "loss": 0.4734,
      "step": 1528
    },
    {
      "epoch": 1.96,
      "learning_rate": 5.645109559193436e-06,
      "loss": 0.4598,
      "step": 1529
    },
    {
      "epoch": 1.96,
      "learning_rate": 5.632633417724542e-06,
      "loss": 0.4519,
      "step": 1530
    },
    {
      "epoch": 1.97,
      "learning_rate": 5.620165670846065e-06,
      "loss": 0.4305,
      "step": 1531
    },
    {
      "epoch": 1.97,
      "learning_rate": 5.607706342522486e-06,
      "loss": 0.4352,
      "step": 1532
    },
    {
      "epoch": 1.97,
      "learning_rate": 5.595255456702084e-06,
      "loss": 0.4417,
      "step": 1533
    },
    {
      "epoch": 1.97,
      "learning_rate": 5.5828130373169274e-06,
      "loss": 0.4645,
      "step": 1534
    },
    {
      "epoch": 1.97,
      "learning_rate": 5.570379108282807e-06,
      "loss": 0.4479,
      "step": 1535
    },
    {
      "epoch": 1.97,
      "learning_rate": 5.5579536934991815e-06,
      "loss": 0.4633,
      "step": 1536
    },
    {
      "epoch": 1.97,
      "learning_rate": 5.545536816849166e-06,
      "loss": 0.4622,
      "step": 1537
    },
    {
      "epoch": 1.97,
      "learning_rate": 5.533128502199443e-06,
      "loss": 0.4647,
      "step": 1538
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.520728773400255e-06,
      "loss": 0.452,
      "step": 1539
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.508337654285327e-06,
      "loss": 0.4502,
      "step": 1540
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.495955168671849e-06,
      "loss": 0.449,
      "step": 1541
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.483581340360404e-06,
      "loss": 0.4504,
      "step": 1542
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.471216193134941e-06,
      "loss": 0.4358,
      "step": 1543
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.458859750762728e-06,
      "loss": 0.4636,
      "step": 1544
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.446512036994287e-06,
      "loss": 0.4658,
      "step": 1545
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.4341730755633805e-06,
      "loss": 0.4444,
      "step": 1546
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.421842890186928e-06,
      "loss": 0.4372,
      "step": 1547
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.409521504564999e-06,
      "loss": 0.453,
      "step": 1548
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.397208942380734e-06,
      "loss": 0.4437,
      "step": 1549
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.38490522730033e-06,
      "loss": 0.4584,
      "step": 1550
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.372610382972958e-06,
      "loss": 0.4421,
      "step": 1551
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.360324433030759e-06,
      "loss": 0.4515,
      "step": 1552
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.348047401088762e-06,
      "loss": 0.4464,
      "step": 1553
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.335779310744864e-06,
      "loss": 0.4472,
      "step": 1554
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.323520185579776e-06,
      "loss": 0.4483,
      "step": 1555
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.311270049156967e-06,
      "loss": 0.4855,
      "step": 1556
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.299028925022641e-06,
      "loss": 0.4592,
      "step": 1557
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.2867968367056664e-06,
      "loss": 0.4486,
      "step": 1558
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.274573807717559e-06,
      "loss": 0.4517,
      "step": 1559
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.262359861552404e-06,
      "loss": 0.455,
      "step": 1560
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.250155021686845e-06,
      "loss": 0.4387,
      "step": 1561
    },
    {
      "epoch": 2.01,
      "learning_rate": 5.2379593115800075e-06,
      "loss": 0.4392,
      "step": 1562
    },
    {
      "epoch": 2.01,
      "learning_rate": 5.225772754673485e-06,
      "loss": 0.454,
      "step": 1563
    },
    {
      "epoch": 2.01,
      "learning_rate": 5.213595374391257e-06,
      "loss": 0.4568,
      "step": 1564
    },
    {
      "epoch": 2.01,
      "learning_rate": 5.201427194139682e-06,
      "loss": 0.443,
      "step": 1565
    },
    {
      "epoch": 2.01,
      "learning_rate": 5.189268237307432e-06,
      "loss": 0.4527,
      "step": 1566
    },
    {
      "epoch": 2.01,
      "learning_rate": 5.177118527265438e-06,
      "loss": 0.4574,
      "step": 1567
    },
    {
      "epoch": 2.01,
      "learning_rate": 5.164978087366876e-06,
      "loss": 0.4635,
      "step": 1568
    },
    {
      "epoch": 2.01,
      "learning_rate": 5.152846940947085e-06,
      "loss": 0.4471,
      "step": 1569
    },
    {
      "epoch": 2.02,
      "learning_rate": 5.140725111323559e-06,
      "loss": 0.4444,
      "step": 1570
    },
    {
      "epoch": 2.02,
      "learning_rate": 5.128612621795867e-06,
      "loss": 0.4647,
      "step": 1571
    },
    {
      "epoch": 2.02,
      "learning_rate": 5.116509495645643e-06,
      "loss": 0.4538,
      "step": 1572
    },
    {
      "epoch": 2.02,
      "learning_rate": 5.104415756136503e-06,
      "loss": 0.4406,
      "step": 1573
    },
    {
      "epoch": 2.02,
      "learning_rate": 5.092331426514043e-06,
      "loss": 0.4386,
      "step": 1574
    },
    {
      "epoch": 2.02,
      "learning_rate": 5.08025653000575e-06,
      "loss": 0.4529,
      "step": 1575
    },
    {
      "epoch": 2.02,
      "learning_rate": 5.068191089820995e-06,
      "loss": 0.4563,
      "step": 1576
    },
    {
      "epoch": 2.02,
      "learning_rate": 5.056135129150972e-06,
      "loss": 0.441,
      "step": 1577
    },
    {
      "epoch": 2.03,
      "learning_rate": 5.044088671168644e-06,
      "loss": 0.441,
      "step": 1578
    },
    {
      "epoch": 2.03,
      "learning_rate": 5.03205173902872e-06,
      "loss": 0.4614,
      "step": 1579
    },
    {
      "epoch": 2.03,
      "learning_rate": 5.02002435586759e-06,
      "loss": 0.4489,
      "step": 1580
    },
    {
      "epoch": 2.03,
      "learning_rate": 5.0080065448033e-06,
      "loss": 0.4334,
      "step": 1581
    },
    {
      "epoch": 2.03,
      "learning_rate": 4.995998328935483e-06,
      "loss": 0.4582,
      "step": 1582
    },
    {
      "epoch": 2.03,
      "learning_rate": 4.983999731345345e-06,
      "loss": 0.4547,
      "step": 1583
    },
    {
      "epoch": 2.03,
      "learning_rate": 4.97201077509559e-06,
      "loss": 0.4501,
      "step": 1584
    },
    {
      "epoch": 2.03,
      "learning_rate": 4.9600314832304056e-06,
      "loss": 0.46,
      "step": 1585
    },
    {
      "epoch": 2.04,
      "learning_rate": 4.948061878775384e-06,
      "loss": 0.4536,
      "step": 1586
    },
    {
      "epoch": 2.04,
      "learning_rate": 4.936101984737515e-06,
      "loss": 0.459,
      "step": 1587
    },
    {
      "epoch": 2.04,
      "learning_rate": 4.924151824105117e-06,
      "loss": 0.4338,
      "step": 1588
    },
    {
      "epoch": 2.04,
      "learning_rate": 4.912211419847795e-06,
      "loss": 0.4498,
      "step": 1589
    },
    {
      "epoch": 2.04,
      "learning_rate": 4.900280794916411e-06,
      "loss": 0.4463,
      "step": 1590
    },
    {
      "epoch": 2.04,
      "learning_rate": 4.888359972243018e-06,
      "loss": 0.4414,
      "step": 1591
    },
    {
      "epoch": 2.04,
      "learning_rate": 4.876448974740839e-06,
      "loss": 0.4516,
      "step": 1592
    },
    {
      "epoch": 2.04,
      "learning_rate": 4.864547825304204e-06,
      "loss": 0.4423,
      "step": 1593
    },
    {
      "epoch": 2.05,
      "learning_rate": 4.852656546808522e-06,
      "loss": 0.452,
      "step": 1594
    },
    {
      "epoch": 2.05,
      "learning_rate": 4.8407751621102166e-06,
      "loss": 0.4519,
      "step": 1595
    },
    {
      "epoch": 2.05,
      "learning_rate": 4.828903694046705e-06,
      "loss": 0.4301,
      "step": 1596
    },
    {
      "epoch": 2.05,
      "learning_rate": 4.817042165436345e-06,
      "loss": 0.4604,
      "step": 1597
    },
    {
      "epoch": 2.05,
      "learning_rate": 4.8051905990783764e-06,
      "loss": 0.4524,
      "step": 1598
    },
    {
      "epoch": 2.05,
      "learning_rate": 4.793349017752907e-06,
      "loss": 0.4268,
      "step": 1599
    },
    {
      "epoch": 2.05,
      "learning_rate": 4.781517444220836e-06,
      "loss": 0.4437,
      "step": 1600
    },
    {
      "epoch": 2.06,
      "learning_rate": 4.769695901223841e-06,
      "loss": 0.4387,
      "step": 1601
    },
    {
      "epoch": 2.06,
      "learning_rate": 4.757884411484307e-06,
      "loss": 0.4543,
      "step": 1602
    },
    {
      "epoch": 2.06,
      "learning_rate": 4.746082997705308e-06,
      "loss": 0.4617,
      "step": 1603
    },
    {
      "epoch": 2.06,
      "learning_rate": 4.734291682570538e-06,
      "loss": 0.4484,
      "step": 1604
    },
    {
      "epoch": 2.06,
      "learning_rate": 4.722510488744294e-06,
      "loss": 0.4229,
      "step": 1605
    },
    {
      "epoch": 2.06,
      "learning_rate": 4.710739438871403e-06,
      "loss": 0.4415,
      "step": 1606
    },
    {
      "epoch": 2.06,
      "learning_rate": 4.698978555577206e-06,
      "loss": 0.4316,
      "step": 1607
    },
    {
      "epoch": 2.06,
      "learning_rate": 4.687227861467503e-06,
      "loss": 0.4572,
      "step": 1608
    },
    {
      "epoch": 2.07,
      "learning_rate": 4.675487379128498e-06,
      "loss": 0.4413,
      "step": 1609
    },
    {
      "epoch": 2.07,
      "learning_rate": 4.663757131126783e-06,
      "loss": 0.445,
      "step": 1610
    },
    {
      "epoch": 2.07,
      "learning_rate": 4.652037140009259e-06,
      "loss": 0.4442,
      "step": 1611
    },
    {
      "epoch": 2.07,
      "learning_rate": 4.640327428303132e-06,
      "loss": 0.4458,
      "step": 1612
    },
    {
      "epoch": 2.07,
      "learning_rate": 4.628628018515833e-06,
      "loss": 0.456,
      "step": 1613
    },
    {
      "epoch": 2.07,
      "learning_rate": 4.616938933135005e-06,
      "loss": 0.4313,
      "step": 1614
    },
    {
      "epoch": 2.07,
      "learning_rate": 4.605260194628432e-06,
      "loss": 0.4611,
      "step": 1615
    },
    {
      "epoch": 2.07,
      "learning_rate": 4.593591825444028e-06,
      "loss": 0.4359,
      "step": 1616
    },
    {
      "epoch": 2.08,
      "learning_rate": 4.581933848009758e-06,
      "loss": 0.4468,
      "step": 1617
    },
    {
      "epoch": 2.08,
      "learning_rate": 4.570286284733622e-06,
      "loss": 0.4429,
      "step": 1618
    },
    {
      "epoch": 2.08,
      "learning_rate": 4.558649158003609e-06,
      "loss": 0.4501,
      "step": 1619
    },
    {
      "epoch": 2.08,
      "learning_rate": 4.54702249018763e-06,
      "loss": 0.4441,
      "step": 1620
    },
    {
      "epoch": 2.08,
      "learning_rate": 4.535406303633512e-06,
      "loss": 0.4441,
      "step": 1621
    },
    {
      "epoch": 2.08,
      "learning_rate": 4.523800620668921e-06,
      "loss": 0.4619,
      "step": 1622
    },
    {
      "epoch": 2.08,
      "learning_rate": 4.512205463601346e-06,
      "loss": 0.4414,
      "step": 1623
    },
    {
      "epoch": 2.08,
      "learning_rate": 4.500620854718028e-06,
      "loss": 0.4348,
      "step": 1624
    },
    {
      "epoch": 2.09,
      "learning_rate": 4.489046816285954e-06,
      "loss": 0.4483,
      "step": 1625
    },
    {
      "epoch": 2.09,
      "learning_rate": 4.477483370551775e-06,
      "loss": 0.4441,
      "step": 1626
    },
    {
      "epoch": 2.09,
      "learning_rate": 4.465930539741793e-06,
      "loss": 0.442,
      "step": 1627
    },
    {
      "epoch": 2.09,
      "learning_rate": 4.454388346061898e-06,
      "loss": 0.4415,
      "step": 1628
    },
    {
      "epoch": 2.09,
      "learning_rate": 4.442856811697541e-06,
      "loss": 0.456,
      "step": 1629
    },
    {
      "epoch": 2.09,
      "learning_rate": 4.431335958813688e-06,
      "loss": 0.4732,
      "step": 1630
    },
    {
      "epoch": 2.09,
      "learning_rate": 4.419825809554761e-06,
      "loss": 0.4434,
      "step": 1631
    },
    {
      "epoch": 2.09,
      "learning_rate": 4.408326386044621e-06,
      "loss": 0.4505,
      "step": 1632
    },
    {
      "epoch": 2.1,
      "learning_rate": 4.396837710386503e-06,
      "loss": 0.4495,
      "step": 1633
    },
    {
      "epoch": 2.1,
      "learning_rate": 4.385359804662993e-06,
      "loss": 0.4404,
      "step": 1634
    },
    {
      "epoch": 2.1,
      "learning_rate": 4.373892690935966e-06,
      "loss": 0.4492,
      "step": 1635
    },
    {
      "epoch": 2.1,
      "learning_rate": 4.362436391246561e-06,
      "loss": 0.4549,
      "step": 1636
    },
    {
      "epoch": 2.1,
      "learning_rate": 4.350990927615132e-06,
      "loss": 0.4618,
      "step": 1637
    },
    {
      "epoch": 2.1,
      "learning_rate": 4.339556322041194e-06,
      "loss": 0.4557,
      "step": 1638
    },
    {
      "epoch": 2.1,
      "learning_rate": 4.328132596503408e-06,
      "loss": 0.4415,
      "step": 1639
    },
    {
      "epoch": 2.11,
      "learning_rate": 4.316719772959504e-06,
      "loss": 0.4499,
      "step": 1640
    },
    {
      "epoch": 2.11,
      "learning_rate": 4.305317873346273e-06,
      "loss": 0.459,
      "step": 1641
    },
    {
      "epoch": 2.11,
      "learning_rate": 4.293926919579502e-06,
      "loss": 0.4376,
      "step": 1642
    },
    {
      "epoch": 2.11,
      "learning_rate": 4.282546933553935e-06,
      "loss": 0.4485,
      "step": 1643
    },
    {
      "epoch": 2.11,
      "learning_rate": 4.271177937143245e-06,
      "loss": 0.4581,
      "step": 1644
    },
    {
      "epoch": 2.11,
      "learning_rate": 4.259819952199968e-06,
      "loss": 0.4386,
      "step": 1645
    },
    {
      "epoch": 2.11,
      "learning_rate": 4.24847300055549e-06,
      "loss": 0.4548,
      "step": 1646
    },
    {
      "epoch": 2.11,
      "learning_rate": 4.237137104019975e-06,
      "loss": 0.4462,
      "step": 1647
    },
    {
      "epoch": 2.12,
      "learning_rate": 4.225812284382347e-06,
      "loss": 0.4562,
      "step": 1648
    },
    {
      "epoch": 2.12,
      "learning_rate": 4.214498563410241e-06,
      "loss": 0.4408,
      "step": 1649
    },
    {
      "epoch": 2.12,
      "learning_rate": 4.203195962849948e-06,
      "loss": 0.4551,
      "step": 1650
    },
    {
      "epoch": 2.12,
      "learning_rate": 4.191904504426397e-06,
      "loss": 0.4494,
      "step": 1651
    },
    {
      "epoch": 2.12,
      "learning_rate": 4.180624209843089e-06,
      "loss": 0.4525,
      "step": 1652
    },
    {
      "epoch": 2.12,
      "learning_rate": 4.169355100782074e-06,
      "loss": 0.4584,
      "step": 1653
    },
    {
      "epoch": 2.12,
      "learning_rate": 4.158097198903903e-06,
      "loss": 0.4611,
      "step": 1654
    },
    {
      "epoch": 2.12,
      "learning_rate": 4.1468505258475785e-06,
      "loss": 0.438,
      "step": 1655
    },
    {
      "epoch": 2.13,
      "learning_rate": 4.13561510323053e-06,
      "loss": 0.4574,
      "step": 1656
    },
    {
      "epoch": 2.13,
      "learning_rate": 4.1243909526485495e-06,
      "loss": 0.4392,
      "step": 1657
    },
    {
      "epoch": 2.13,
      "learning_rate": 4.113178095675777e-06,
      "loss": 0.4539,
      "step": 1658
    },
    {
      "epoch": 2.13,
      "learning_rate": 4.101976553864631e-06,
      "loss": 0.4389,
      "step": 1659
    },
    {
      "epoch": 2.13,
      "learning_rate": 4.0907863487457895e-06,
      "loss": 0.4592,
      "step": 1660
    },
    {
      "epoch": 2.13,
      "learning_rate": 4.079607501828146e-06,
      "loss": 0.4481,
      "step": 1661
    },
    {
      "epoch": 2.13,
      "learning_rate": 4.068440034598742e-06,
      "loss": 0.4479,
      "step": 1662
    },
    {
      "epoch": 2.13,
      "learning_rate": 4.057283968522768e-06,
      "loss": 0.4493,
      "step": 1663
    },
    {
      "epoch": 2.14,
      "learning_rate": 4.0461393250434845e-06,
      "loss": 0.4328,
      "step": 1664
    },
    {
      "epoch": 2.14,
      "learning_rate": 4.035006125582207e-06,
      "loss": 0.4379,
      "step": 1665
    },
    {
      "epoch": 2.14,
      "learning_rate": 4.023884391538244e-06,
      "loss": 0.451,
      "step": 1666
    },
    {
      "epoch": 2.14,
      "learning_rate": 4.01277414428888e-06,
      "loss": 0.4634,
      "step": 1667
    },
    {
      "epoch": 2.14,
      "learning_rate": 4.001675405189302e-06,
      "loss": 0.4416,
      "step": 1668
    },
    {
      "epoch": 2.14,
      "learning_rate": 3.990588195572598e-06,
      "loss": 0.4428,
      "step": 1669
    },
    {
      "epoch": 2.14,
      "learning_rate": 3.979512536749675e-06,
      "loss": 0.4485,
      "step": 1670
    },
    {
      "epoch": 2.15,
      "learning_rate": 3.9684484500092515e-06,
      "loss": 0.4503,
      "step": 1671
    },
    {
      "epoch": 2.15,
      "learning_rate": 3.957395956617802e-06,
      "loss": 0.4493,
      "step": 1672
    },
    {
      "epoch": 2.15,
      "learning_rate": 3.946355077819508e-06,
      "loss": 0.4523,
      "step": 1673
    },
    {
      "epoch": 2.15,
      "learning_rate": 3.935325834836239e-06,
      "loss": 0.4422,
      "step": 1674
    },
    {
      "epoch": 2.15,
      "learning_rate": 3.924308248867485e-06,
      "loss": 0.4512,
      "step": 1675
    },
    {
      "epoch": 2.15,
      "learning_rate": 3.913302341090345e-06,
      "loss": 0.448,
      "step": 1676
    },
    {
      "epoch": 2.15,
      "learning_rate": 3.902308132659457e-06,
      "loss": 0.4295,
      "step": 1677
    },
    {
      "epoch": 2.15,
      "learning_rate": 3.891325644706986e-06,
      "loss": 0.4456,
      "step": 1678
    },
    {
      "epoch": 2.16,
      "learning_rate": 3.880354898342551e-06,
      "loss": 0.43,
      "step": 1679
    },
    {
      "epoch": 2.16,
      "learning_rate": 3.8693959146532225e-06,
      "loss": 0.4545,
      "step": 1680
    },
    {
      "epoch": 2.16,
      "learning_rate": 3.858448714703442e-06,
      "loss": 0.4471,
      "step": 1681
    },
    {
      "epoch": 2.16,
      "learning_rate": 3.847513319535015e-06,
      "loss": 0.4473,
      "step": 1682
    },
    {
      "epoch": 2.16,
      "learning_rate": 3.836589750167059e-06,
      "loss": 0.4477,
      "step": 1683
    },
    {
      "epoch": 2.16,
      "learning_rate": 3.825678027595944e-06,
      "loss": 0.4625,
      "step": 1684
    },
    {
      "epoch": 2.16,
      "learning_rate": 3.814778172795287e-06,
      "loss": 0.4628,
      "step": 1685
    },
    {
      "epoch": 2.16,
      "learning_rate": 3.80389020671588e-06,
      "loss": 0.4445,
      "step": 1686
    },
    {
      "epoch": 2.17,
      "learning_rate": 3.7930141502856778e-06,
      "loss": 0.4341,
      "step": 1687
    },
    {
      "epoch": 2.17,
      "learning_rate": 3.7821500244097276e-06,
      "loss": 0.4505,
      "step": 1688
    },
    {
      "epoch": 2.17,
      "learning_rate": 3.7712978499701593e-06,
      "loss": 0.4593,
      "step": 1689
    },
    {
      "epoch": 2.17,
      "learning_rate": 3.760457647826118e-06,
      "loss": 0.4585,
      "step": 1690
    },
    {
      "epoch": 2.17,
      "learning_rate": 3.7496294388137487e-06,
      "loss": 0.4294,
      "step": 1691
    },
    {
      "epoch": 2.17,
      "learning_rate": 3.7388132437461322e-06,
      "loss": 0.4479,
      "step": 1692
    },
    {
      "epoch": 2.17,
      "learning_rate": 3.7280090834132654e-06,
      "loss": 0.4398,
      "step": 1693
    },
    {
      "epoch": 2.17,
      "learning_rate": 3.7172169785820143e-06,
      "loss": 0.4379,
      "step": 1694
    },
    {
      "epoch": 2.18,
      "learning_rate": 3.706436949996064e-06,
      "loss": 0.4484,
      "step": 1695
    },
    {
      "epoch": 2.18,
      "learning_rate": 3.695669018375898e-06,
      "loss": 0.4407,
      "step": 1696
    },
    {
      "epoch": 2.18,
      "learning_rate": 3.6849132044187364e-06,
      "loss": 0.4509,
      "step": 1697
    },
    {
      "epoch": 2.18,
      "learning_rate": 3.674169528798521e-06,
      "loss": 0.4362,
      "step": 1698
    },
    {
      "epoch": 2.18,
      "learning_rate": 3.6634380121658484e-06,
      "loss": 0.4455,
      "step": 1699
    },
    {
      "epoch": 2.18,
      "learning_rate": 3.652718675147959e-06,
      "loss": 0.444,
      "step": 1700
    },
    {
      "epoch": 2.18,
      "learning_rate": 3.6420115383486677e-06,
      "loss": 0.4378,
      "step": 1701
    },
    {
      "epoch": 2.18,
      "learning_rate": 3.631316622348349e-06,
      "loss": 0.4496,
      "step": 1702
    },
    {
      "epoch": 2.19,
      "learning_rate": 3.6206339477038887e-06,
      "loss": 0.4624,
      "step": 1703
    },
    {
      "epoch": 2.19,
      "learning_rate": 3.6099635349486327e-06,
      "loss": 0.4374,
      "step": 1704
    },
    {
      "epoch": 2.19,
      "learning_rate": 3.5993054045923726e-06,
      "loss": 0.431,
      "step": 1705
    },
    {
      "epoch": 2.19,
      "learning_rate": 3.5886595771212763e-06,
      "loss": 0.4493,
      "step": 1706
    },
    {
      "epoch": 2.19,
      "learning_rate": 3.5780260729978777e-06,
      "loss": 0.4504,
      "step": 1707
    },
    {
      "epoch": 2.19,
      "learning_rate": 3.5674049126610135e-06,
      "loss": 0.4375,
      "step": 1708
    },
    {
      "epoch": 2.19,
      "learning_rate": 3.5567961165258036e-06,
      "loss": 0.4298,
      "step": 1709
    },
    {
      "epoch": 2.2,
      "learning_rate": 3.546199704983592e-06,
      "loss": 0.4474,
      "step": 1710
    },
    {
      "epoch": 2.2,
      "learning_rate": 3.5356156984019286e-06,
      "loss": 0.4404,
      "step": 1711
    },
    {
      "epoch": 2.2,
      "learning_rate": 3.5250441171245087e-06,
      "loss": 0.444,
      "step": 1712
    },
    {
      "epoch": 2.2,
      "learning_rate": 3.5144849814711545e-06,
      "loss": 0.4285,
      "step": 1713
    },
    {
      "epoch": 2.2,
      "learning_rate": 3.5039383117377655e-06,
      "loss": 0.4356,
      "step": 1714
    },
    {
      "epoch": 2.2,
      "learning_rate": 3.4934041281962694e-06,
      "loss": 0.4573,
      "step": 1715
    },
    {
      "epoch": 2.2,
      "learning_rate": 3.482882451094608e-06,
      "loss": 0.4424,
      "step": 1716
    },
    {
      "epoch": 2.2,
      "learning_rate": 3.472373300656673e-06,
      "loss": 0.442,
      "step": 1717
    },
    {
      "epoch": 2.21,
      "learning_rate": 3.4618766970822883e-06,
      "loss": 0.4456,
      "step": 1718
    },
    {
      "epoch": 2.21,
      "learning_rate": 3.4513926605471504e-06,
      "loss": 0.4442,
      "step": 1719
    },
    {
      "epoch": 2.21,
      "learning_rate": 3.4409212112028114e-06,
      "loss": 0.449,
      "step": 1720
    },
    {
      "epoch": 2.21,
      "learning_rate": 3.4304623691766193e-06,
      "loss": 0.443,
      "step": 1721
    },
    {
      "epoch": 2.21,
      "learning_rate": 3.4200161545717005e-06,
      "loss": 0.4519,
      "step": 1722
    },
    {
      "epoch": 2.21,
      "learning_rate": 3.409582587466895e-06,
      "loss": 0.4528,
      "step": 1723
    },
    {
      "epoch": 2.21,
      "learning_rate": 3.399161687916749e-06,
      "loss": 0.4522,
      "step": 1724
    },
    {
      "epoch": 2.21,
      "learning_rate": 3.3887534759514517e-06,
      "loss": 0.4652,
      "step": 1725
    },
    {
      "epoch": 2.22,
      "learning_rate": 3.378357971576802e-06,
      "loss": 0.4498,
      "step": 1726
    },
    {
      "epoch": 2.22,
      "learning_rate": 3.3679751947741858e-06,
      "loss": 0.4553,
      "step": 1727
    },
    {
      "epoch": 2.22,
      "learning_rate": 3.357605165500507e-06,
      "loss": 0.4394,
      "step": 1728
    },
    {
      "epoch": 2.22,
      "learning_rate": 3.3472479036881856e-06,
      "loss": 0.4527,
      "step": 1729
    },
    {
      "epoch": 2.22,
      "learning_rate": 3.3369034292450854e-06,
      "loss": 0.4542,
      "step": 1730
    },
    {
      "epoch": 2.22,
      "learning_rate": 3.326571762054507e-06,
      "loss": 0.4543,
      "step": 1731
    },
    {
      "epoch": 2.22,
      "learning_rate": 3.316252921975116e-06,
      "loss": 0.4439,
      "step": 1732
    },
    {
      "epoch": 2.22,
      "learning_rate": 3.305946928840942e-06,
      "loss": 0.4355,
      "step": 1733
    },
    {
      "epoch": 2.23,
      "learning_rate": 3.2956538024613026e-06,
      "loss": 0.4495,
      "step": 1734
    },
    {
      "epoch": 2.23,
      "learning_rate": 3.2853735626207984e-06,
      "loss": 0.4386,
      "step": 1735
    },
    {
      "epoch": 2.23,
      "learning_rate": 3.2751062290792567e-06,
      "loss": 0.4372,
      "step": 1736
    },
    {
      "epoch": 2.23,
      "learning_rate": 3.264851821571691e-06,
      "loss": 0.4234,
      "step": 1737
    },
    {
      "epoch": 2.23,
      "learning_rate": 3.25461035980828e-06,
      "loss": 0.4389,
      "step": 1738
    },
    {
      "epoch": 2.23,
      "learning_rate": 3.2443818634743064e-06,
      "loss": 0.4469,
      "step": 1739
    },
    {
      "epoch": 2.23,
      "learning_rate": 3.234166352230147e-06,
      "loss": 0.4589,
      "step": 1740
    },
    {
      "epoch": 2.23,
      "learning_rate": 3.223963845711203e-06,
      "loss": 0.4466,
      "step": 1741
    },
    {
      "epoch": 2.24,
      "learning_rate": 3.2137743635278962e-06,
      "loss": 0.4536,
      "step": 1742
    },
    {
      "epoch": 2.24,
      "learning_rate": 3.203597925265598e-06,
      "loss": 0.4328,
      "step": 1743
    },
    {
      "epoch": 2.24,
      "learning_rate": 3.1934345504846222e-06,
      "loss": 0.4351,
      "step": 1744
    },
    {
      "epoch": 2.24,
      "learning_rate": 3.1832842587201605e-06,
      "loss": 0.4303,
      "step": 1745
    },
    {
      "epoch": 2.24,
      "learning_rate": 3.1731470694822643e-06,
      "loss": 0.4439,
      "step": 1746
    },
    {
      "epoch": 2.24,
      "learning_rate": 3.163023002255805e-06,
      "loss": 0.4482,
      "step": 1747
    },
    {
      "epoch": 2.24,
      "learning_rate": 3.1529120765004183e-06,
      "loss": 0.4563,
      "step": 1748
    },
    {
      "epoch": 2.25,
      "learning_rate": 3.142814311650496e-06,
      "loss": 0.4603,
      "step": 1749
    },
    {
      "epoch": 2.25,
      "learning_rate": 3.132729727115119e-06,
      "loss": 0.4571,
      "step": 1750
    },
    {
      "epoch": 2.25,
      "learning_rate": 3.1226583422780467e-06,
      "loss": 0.4245,
      "step": 1751
    },
    {
      "epoch": 2.25,
      "learning_rate": 3.112600176497654e-06,
      "loss": 0.4464,
      "step": 1752
    },
    {
      "epoch": 2.25,
      "learning_rate": 3.102555249106922e-06,
      "loss": 0.4501,
      "step": 1753
    },
    {
      "epoch": 2.25,
      "learning_rate": 3.0925235794133725e-06,
      "loss": 0.4416,
      "step": 1754
    },
    {
      "epoch": 2.25,
      "learning_rate": 3.0825051866990517e-06,
      "loss": 0.4487,
      "step": 1755
    },
    {
      "epoch": 2.25,
      "learning_rate": 3.072500090220488e-06,
      "loss": 0.4547,
      "step": 1756
    },
    {
      "epoch": 2.26,
      "learning_rate": 3.062508309208645e-06,
      "loss": 0.4324,
      "step": 1757
    },
    {
      "epoch": 2.26,
      "learning_rate": 3.0525298628689013e-06,
      "loss": 0.4362,
      "step": 1758
    },
    {
      "epoch": 2.26,
      "learning_rate": 3.0425647703809948e-06,
      "loss": 0.4283,
      "step": 1759
    },
    {
      "epoch": 2.26,
      "learning_rate": 3.032613050899007e-06,
      "loss": 0.4344,
      "step": 1760
    },
    {
      "epoch": 2.26,
      "learning_rate": 3.022674723551303e-06,
      "loss": 0.4579,
      "step": 1761
    },
    {
      "epoch": 2.26,
      "learning_rate": 3.012749807440516e-06,
      "loss": 0.4452,
      "step": 1762
    },
    {
      "epoch": 2.26,
      "learning_rate": 3.0028383216434997e-06,
      "loss": 0.4531,
      "step": 1763
    },
    {
      "epoch": 2.26,
      "learning_rate": 2.992940285211288e-06,
      "loss": 0.4472,
      "step": 1764
    },
    {
      "epoch": 2.27,
      "learning_rate": 2.98305571716907e-06,
      "loss": 0.4587,
      "step": 1765
    },
    {
      "epoch": 2.27,
      "learning_rate": 2.97318463651614e-06,
      "loss": 0.4377,
      "step": 1766
    },
    {
      "epoch": 2.27,
      "learning_rate": 2.963327062225878e-06,
      "loss": 0.4356,
      "step": 1767
    },
    {
      "epoch": 2.27,
      "learning_rate": 2.9534830132456894e-06,
      "loss": 0.4597,
      "step": 1768
    },
    {
      "epoch": 2.27,
      "learning_rate": 2.943652508496995e-06,
      "loss": 0.4309,
      "step": 1769
    },
    {
      "epoch": 2.27,
      "learning_rate": 2.933835566875177e-06,
      "loss": 0.4548,
      "step": 1770
    },
    {
      "epoch": 2.27,
      "learning_rate": 2.924032207249545e-06,
      "loss": 0.457,
      "step": 1771
    },
    {
      "epoch": 2.27,
      "learning_rate": 2.9142424484633116e-06,
      "loss": 0.4356,
      "step": 1772
    },
    {
      "epoch": 2.28,
      "learning_rate": 2.904466309333531e-06,
      "loss": 0.4437,
      "step": 1773
    },
    {
      "epoch": 2.28,
      "learning_rate": 2.8947038086510937e-06,
      "loss": 0.4427,
      "step": 1774
    },
    {
      "epoch": 2.28,
      "learning_rate": 2.884954965180672e-06,
      "loss": 0.4438,
      "step": 1775
    },
    {
      "epoch": 2.28,
      "learning_rate": 2.875219797660681e-06,
      "loss": 0.4306,
      "step": 1776
    },
    {
      "epoch": 2.28,
      "learning_rate": 2.8654983248032585e-06,
      "loss": 0.4526,
      "step": 1777
    },
    {
      "epoch": 2.28,
      "learning_rate": 2.85579056529421e-06,
      "loss": 0.4734,
      "step": 1778
    },
    {
      "epoch": 2.28,
      "learning_rate": 2.8460965377929916e-06,
      "loss": 0.4377,
      "step": 1779
    },
    {
      "epoch": 2.28,
      "learning_rate": 2.836416260932655e-06,
      "loss": 0.4455,
      "step": 1780
    },
    {
      "epoch": 2.29,
      "learning_rate": 2.8267497533198294e-06,
      "loss": 0.4428,
      "step": 1781
    },
    {
      "epoch": 2.29,
      "learning_rate": 2.817097033534678e-06,
      "loss": 0.459,
      "step": 1782
    },
    {
      "epoch": 2.29,
      "learning_rate": 2.8074581201308547e-06,
      "loss": 0.4445,
      "step": 1783
    },
    {
      "epoch": 2.29,
      "learning_rate": 2.7978330316354862e-06,
      "loss": 0.4501,
      "step": 1784
    },
    {
      "epoch": 2.29,
      "learning_rate": 2.7882217865491144e-06,
      "loss": 0.4357,
      "step": 1785
    },
    {
      "epoch": 2.29,
      "learning_rate": 2.7786244033456857e-06,
      "loss": 0.4363,
      "step": 1786
    },
    {
      "epoch": 2.29,
      "learning_rate": 2.7690409004724883e-06,
      "loss": 0.4434,
      "step": 1787
    },
    {
      "epoch": 2.3,
      "learning_rate": 2.7594712963501415e-06,
      "loss": 0.4262,
      "step": 1788
    },
    {
      "epoch": 2.3,
      "learning_rate": 2.7499156093725474e-06,
      "loss": 0.4622,
      "step": 1789
    },
    {
      "epoch": 2.3,
      "learning_rate": 2.740373857906853e-06,
      "loss": 0.4561,
      "step": 1790
    },
    {
      "epoch": 2.3,
      "learning_rate": 2.7308460602934274e-06,
      "loss": 0.4356,
      "step": 1791
    },
    {
      "epoch": 2.3,
      "learning_rate": 2.721332234845808e-06,
      "loss": 0.446,
      "step": 1792
    },
    {
      "epoch": 2.3,
      "learning_rate": 2.711832399850689e-06,
      "loss": 0.4513,
      "step": 1793
    },
    {
      "epoch": 2.3,
      "learning_rate": 2.70234657356786e-06,
      "loss": 0.447,
      "step": 1794
    },
    {
      "epoch": 2.3,
      "learning_rate": 2.6928747742301976e-06,
      "loss": 0.4475,
      "step": 1795
    },
    {
      "epoch": 2.31,
      "learning_rate": 2.683417020043604e-06,
      "loss": 0.4223,
      "step": 1796
    },
    {
      "epoch": 2.31,
      "learning_rate": 2.6739733291869942e-06,
      "loss": 0.4411,
      "step": 1797
    },
    {
      "epoch": 2.31,
      "learning_rate": 2.6645437198122503e-06,
      "loss": 0.4353,
      "step": 1798
    },
    {
      "epoch": 2.31,
      "learning_rate": 2.655128210044183e-06,
      "loss": 0.4222,
      "step": 1799
    },
    {
      "epoch": 2.31,
      "learning_rate": 2.6457268179805106e-06,
      "loss": 0.4498,
      "step": 1800
    },
    {
      "epoch": 2.31,
      "learning_rate": 2.6363395616918043e-06,
      "loss": 0.4521,
      "step": 1801
    },
    {
      "epoch": 2.31,
      "learning_rate": 2.6269664592214762e-06,
      "loss": 0.4497,
      "step": 1802
    },
    {
      "epoch": 2.31,
      "learning_rate": 2.617607528585724e-06,
      "loss": 0.4611,
      "step": 1803
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.6082627877735125e-06,
      "loss": 0.443,
      "step": 1804
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.5989322547465246e-06,
      "loss": 0.4609,
      "step": 1805
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.5896159474391435e-06,
      "loss": 0.4476,
      "step": 1806
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.5803138837583987e-06,
      "loss": 0.4568,
      "step": 1807
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.5710260815839484e-06,
      "loss": 0.452,
      "step": 1808
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.56175255876804e-06,
      "loss": 0.46,
      "step": 1809
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.5524933331354664e-06,
      "loss": 0.4328,
      "step": 1810
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.5432484224835497e-06,
      "loss": 0.4339,
      "step": 1811
    },
    {
      "epoch": 2.33,
      "learning_rate": 2.534017844582085e-06,
      "loss": 0.428,
      "step": 1812
    },
    {
      "epoch": 2.33,
      "learning_rate": 2.5248016171733324e-06,
      "loss": 0.4417,
      "step": 1813
    },
    {
      "epoch": 2.33,
      "learning_rate": 2.515599757971955e-06,
      "loss": 0.449,
      "step": 1814
    },
    {
      "epoch": 2.33,
      "learning_rate": 2.5064122846650085e-06,
      "loss": 0.436,
      "step": 1815
    },
    {
      "epoch": 2.33,
      "learning_rate": 2.4972392149118896e-06,
      "loss": 0.4489,
      "step": 1816
    },
    {
      "epoch": 2.33,
      "learning_rate": 2.4880805663443176e-06,
      "loss": 0.4392,
      "step": 1817
    },
    {
      "epoch": 2.33,
      "learning_rate": 2.478936356566285e-06,
      "loss": 0.4412,
      "step": 1818
    },
    {
      "epoch": 2.34,
      "learning_rate": 2.4698066031540346e-06,
      "loss": 0.4359,
      "step": 1819
    },
    {
      "epoch": 2.34,
      "learning_rate": 2.4606913236560283e-06,
      "loss": 0.451,
      "step": 1820
    },
    {
      "epoch": 2.34,
      "learning_rate": 2.451590535592894e-06,
      "loss": 0.4438,
      "step": 1821
    },
    {
      "epoch": 2.34,
      "learning_rate": 2.4425042564574186e-06,
      "loss": 0.4547,
      "step": 1822
    },
    {
      "epoch": 2.34,
      "learning_rate": 2.43343250371449e-06,
      "loss": 0.4548,
      "step": 1823
    },
    {
      "epoch": 2.34,
      "learning_rate": 2.424375294801087e-06,
      "loss": 0.4381,
      "step": 1824
    },
    {
      "epoch": 2.34,
      "learning_rate": 2.4153326471262197e-06,
      "loss": 0.4463,
      "step": 1825
    },
    {
      "epoch": 2.34,
      "learning_rate": 2.4063045780709225e-06,
      "loss": 0.4468,
      "step": 1826
    },
    {
      "epoch": 2.35,
      "learning_rate": 2.3972911049881976e-06,
      "loss": 0.4499,
      "step": 1827
    },
    {
      "epoch": 2.35,
      "learning_rate": 2.388292245203001e-06,
      "loss": 0.4572,
      "step": 1828
    },
    {
      "epoch": 2.35,
      "learning_rate": 2.379308016012192e-06,
      "loss": 0.4549,
      "step": 1829
    },
    {
      "epoch": 2.35,
      "learning_rate": 2.3703384346845113e-06,
      "loss": 0.4432,
      "step": 1830
    },
    {
      "epoch": 2.35,
      "learning_rate": 2.3613835184605527e-06,
      "loss": 0.457,
      "step": 1831
    },
    {
      "epoch": 2.35,
      "learning_rate": 2.3524432845527055e-06,
      "loss": 0.446,
      "step": 1832
    },
    {
      "epoch": 2.35,
      "learning_rate": 2.3435177501451547e-06,
      "loss": 0.4321,
      "step": 1833
    },
    {
      "epoch": 2.35,
      "learning_rate": 2.334606932393818e-06,
      "loss": 0.4438,
      "step": 1834
    },
    {
      "epoch": 2.36,
      "learning_rate": 2.325710848426336e-06,
      "loss": 0.4346,
      "step": 1835
    },
    {
      "epoch": 2.36,
      "learning_rate": 2.3168295153420184e-06,
      "loss": 0.4429,
      "step": 1836
    },
    {
      "epoch": 2.36,
      "learning_rate": 2.307962950211836e-06,
      "loss": 0.4354,
      "step": 1837
    },
    {
      "epoch": 2.36,
      "learning_rate": 2.2991111700783584e-06,
      "loss": 0.4289,
      "step": 1838
    },
    {
      "epoch": 2.36,
      "learning_rate": 2.2902741919557526e-06,
      "loss": 0.4431,
      "step": 1839
    },
    {
      "epoch": 2.36,
      "learning_rate": 2.281452032829717e-06,
      "loss": 0.436,
      "step": 1840
    },
    {
      "epoch": 2.36,
      "learning_rate": 2.272644709657482e-06,
      "loss": 0.4491,
      "step": 1841
    },
    {
      "epoch": 2.36,
      "learning_rate": 2.2638522393677564e-06,
      "loss": 0.4553,
      "step": 1842
    },
    {
      "epoch": 2.37,
      "learning_rate": 2.2550746388606913e-06,
      "loss": 0.4509,
      "step": 1843
    },
    {
      "epoch": 2.37,
      "learning_rate": 2.2463119250078714e-06,
      "loss": 0.4577,
      "step": 1844
    },
    {
      "epoch": 2.37,
      "learning_rate": 2.237564114652253e-06,
      "loss": 0.442,
      "step": 1845
    },
    {
      "epoch": 2.37,
      "learning_rate": 2.228831224608159e-06,
      "loss": 0.4462,
      "step": 1846
    },
    {
      "epoch": 2.37,
      "learning_rate": 2.2201132716612207e-06,
      "loss": 0.449,
      "step": 1847
    },
    {
      "epoch": 2.37,
      "learning_rate": 2.2114102725683728e-06,
      "loss": 0.463,
      "step": 1848
    },
    {
      "epoch": 2.37,
      "learning_rate": 2.202722244057792e-06,
      "loss": 0.4798,
      "step": 1849
    },
    {
      "epoch": 2.37,
      "learning_rate": 2.194049202828893e-06,
      "loss": 0.4513,
      "step": 1850
    },
    {
      "epoch": 2.38,
      "learning_rate": 2.1853911655522777e-06,
      "loss": 0.4561,
      "step": 1851
    },
    {
      "epoch": 2.38,
      "learning_rate": 2.176748148869703e-06,
      "loss": 0.4346,
      "step": 1852
    },
    {
      "epoch": 2.38,
      "learning_rate": 2.1681201693940667e-06,
      "loss": 0.4469,
      "step": 1853
    },
    {
      "epoch": 2.38,
      "learning_rate": 2.1595072437093502e-06,
      "loss": 0.428,
      "step": 1854
    },
    {
      "epoch": 2.38,
      "learning_rate": 2.1509093883706123e-06,
      "loss": 0.4449,
      "step": 1855
    },
    {
      "epoch": 2.38,
      "learning_rate": 2.1423266199039314e-06,
      "loss": 0.4291,
      "step": 1856
    },
    {
      "epoch": 2.38,
      "learning_rate": 2.133758954806403e-06,
      "loss": 0.4478,
      "step": 1857
    },
    {
      "epoch": 2.39,
      "learning_rate": 2.1252064095460756e-06,
      "loss": 0.4365,
      "step": 1858
    },
    {
      "epoch": 2.39,
      "learning_rate": 2.1166690005619494e-06,
      "loss": 0.4183,
      "step": 1859
    },
    {
      "epoch": 2.39,
      "learning_rate": 2.1081467442639193e-06,
      "loss": 0.4465,
      "step": 1860
    },
    {
      "epoch": 2.39,
      "learning_rate": 2.099639657032765e-06,
      "loss": 0.4427,
      "step": 1861
    },
    {
      "epoch": 2.39,
      "learning_rate": 2.0911477552201065e-06,
      "loss": 0.4659,
      "step": 1862
    },
    {
      "epoch": 2.39,
      "learning_rate": 2.0826710551483685e-06,
      "loss": 0.4416,
      "step": 1863
    },
    {
      "epoch": 2.39,
      "learning_rate": 2.0742095731107693e-06,
      "loss": 0.4443,
      "step": 1864
    },
    {
      "epoch": 2.39,
      "learning_rate": 2.0657633253712618e-06,
      "loss": 0.4497,
      "step": 1865
    },
    {
      "epoch": 2.4,
      "learning_rate": 2.0573323281645295e-06,
      "loss": 0.4654,
      "step": 1866
    },
    {
      "epoch": 2.4,
      "learning_rate": 2.0489165976959336e-06,
      "loss": 0.4414,
      "step": 1867
    },
    {
      "epoch": 2.4,
      "learning_rate": 2.0405161501414983e-06,
      "loss": 0.4373,
      "step": 1868
    },
    {
      "epoch": 2.4,
      "learning_rate": 2.0321310016478626e-06,
      "loss": 0.45,
      "step": 1869
    },
    {
      "epoch": 2.4,
      "learning_rate": 2.0237611683322713e-06,
      "loss": 0.4487,
      "step": 1870
    },
    {
      "epoch": 2.4,
      "learning_rate": 2.015406666282519e-06,
      "loss": 0.4439,
      "step": 1871
    },
    {
      "epoch": 2.4,
      "learning_rate": 2.007067511556939e-06,
      "loss": 0.4491,
      "step": 1872
    },
    {
      "epoch": 2.4,
      "learning_rate": 1.9987437201843696e-06,
      "loss": 0.4393,
      "step": 1873
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.990435308164106e-06,
      "loss": 0.4401,
      "step": 1874
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.982142291465896e-06,
      "loss": 0.4425,
      "step": 1875
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.9738646860298828e-06,
      "loss": 0.4469,
      "step": 1876
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.965602507766602e-06,
      "loss": 0.4447,
      "step": 1877
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.9573557725569214e-06,
      "loss": 0.4651,
      "step": 1878
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.9491244962520385e-06,
      "loss": 0.435,
      "step": 1879
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.9409086946734246e-06,
      "loss": 0.4421,
      "step": 1880
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.93270838361282e-06,
      "loss": 0.4475,
      "step": 1881
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.924523578832179e-06,
      "loss": 0.4402,
      "step": 1882
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.916354296063656e-06,
      "loss": 0.4468,
      "step": 1883
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.9082005510095746e-06,
      "loss": 0.4408,
      "step": 1884
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.9000623593423817e-06,
      "loss": 0.4339,
      "step": 1885
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.891939736704641e-06,
      "loss": 0.422,
      "step": 1886
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.8838326987089807e-06,
      "loss": 0.4367,
      "step": 1887
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.875741260938082e-06,
      "loss": 0.4523,
      "step": 1888
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.8676654389446324e-06,
      "loss": 0.4364,
      "step": 1889
    },
    {
      "epoch": 2.43,
      "learning_rate": 1.8596052482513106e-06,
      "loss": 0.4506,
      "step": 1890
    },
    {
      "epoch": 2.43,
      "learning_rate": 1.851560704350751e-06,
      "loss": 0.4521,
      "step": 1891
    },
    {
      "epoch": 2.43,
      "learning_rate": 1.8435318227055033e-06,
      "loss": 0.4459,
      "step": 1892
    },
    {
      "epoch": 2.43,
      "learning_rate": 1.8355186187480246e-06,
      "loss": 0.4447,
      "step": 1893
    },
    {
      "epoch": 2.43,
      "learning_rate": 1.8275211078806276e-06,
      "loss": 0.4458,
      "step": 1894
    },
    {
      "epoch": 2.43,
      "learning_rate": 1.8195393054754661e-06,
      "loss": 0.4437,
      "step": 1895
    },
    {
      "epoch": 2.43,
      "learning_rate": 1.8115732268745056e-06,
      "loss": 0.4509,
      "step": 1896
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.8036228873894745e-06,
      "loss": 0.4379,
      "step": 1897
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.7956883023018645e-06,
      "loss": 0.4633,
      "step": 1898
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.7877694868628715e-06,
      "loss": 0.4332,
      "step": 1899
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.779866456293392e-06,
      "loss": 0.4455,
      "step": 1900
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.7719792257839729e-06,
      "loss": 0.441,
      "step": 1901
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.7641078104947972e-06,
      "loss": 0.4634,
      "step": 1902
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.7562522255556503e-06,
      "loss": 0.4495,
      "step": 1903
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.7484124860658825e-06,
      "loss": 0.4439,
      "step": 1904
    },
    {
      "epoch": 2.45,
      "learning_rate": 1.7405886070943967e-06,
      "loss": 0.4533,
      "step": 1905
    },
    {
      "epoch": 2.45,
      "learning_rate": 1.7327806036796002e-06,
      "loss": 0.4581,
      "step": 1906
    },
    {
      "epoch": 2.45,
      "learning_rate": 1.7249884908293935e-06,
      "loss": 0.4503,
      "step": 1907
    },
    {
      "epoch": 2.45,
      "learning_rate": 1.7172122835211337e-06,
      "loss": 0.4463,
      "step": 1908
    },
    {
      "epoch": 2.45,
      "learning_rate": 1.7094519967015955e-06,
      "loss": 0.4552,
      "step": 1909
    },
    {
      "epoch": 2.45,
      "learning_rate": 1.7017076452869663e-06,
      "loss": 0.4388,
      "step": 1910
    },
    {
      "epoch": 2.45,
      "learning_rate": 1.6939792441627911e-06,
      "loss": 0.4635,
      "step": 1911
    },
    {
      "epoch": 2.45,
      "learning_rate": 1.6862668081839696e-06,
      "loss": 0.4566,
      "step": 1912
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.678570352174701e-06,
      "loss": 0.4444,
      "step": 1913
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.6708898909284787e-06,
      "loss": 0.435,
      "step": 1914
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.6632254392080515e-06,
      "loss": 0.4402,
      "step": 1915
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.6555770117453896e-06,
      "loss": 0.4441,
      "step": 1916
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.6479446232416707e-06,
      "loss": 0.4477,
      "step": 1917
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.6403282883672368e-06,
      "loss": 0.4542,
      "step": 1918
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.6327280217615793e-06,
      "loss": 0.468,
      "step": 1919
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.6251438380332985e-06,
      "loss": 0.4419,
      "step": 1920
    },
    {
      "epoch": 2.47,
      "learning_rate": 1.6175757517600876e-06,
      "loss": 0.4339,
      "step": 1921
    },
    {
      "epoch": 2.47,
      "learning_rate": 1.6100237774886906e-06,
      "loss": 0.4501,
      "step": 1922
    },
    {
      "epoch": 2.47,
      "learning_rate": 1.6024879297348928e-06,
      "loss": 0.4413,
      "step": 1923
    },
    {
      "epoch": 2.47,
      "learning_rate": 1.5949682229834719e-06,
      "loss": 0.4439,
      "step": 1924
    },
    {
      "epoch": 2.47,
      "learning_rate": 1.587464671688187e-06,
      "loss": 0.4643,
      "step": 1925
    },
    {
      "epoch": 2.47,
      "learning_rate": 1.579977290271747e-06,
      "loss": 0.4657,
      "step": 1926
    },
    {
      "epoch": 2.47,
      "learning_rate": 1.5725060931257697e-06,
      "loss": 0.4613,
      "step": 1927
    },
    {
      "epoch": 2.47,
      "learning_rate": 1.5650510946107788e-06,
      "loss": 0.443,
      "step": 1928
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.557612309056148e-06,
      "loss": 0.4412,
      "step": 1929
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.5501897507601016e-06,
      "loss": 0.4508,
      "step": 1930
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.5427834339896608e-06,
      "loss": 0.4323,
      "step": 1931
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.535393372980639e-06,
      "loss": 0.4619,
      "step": 1932
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.5280195819375964e-06,
      "loss": 0.445,
      "step": 1933
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.5206620750338263e-06,
      "loss": 0.4347,
      "step": 1934
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.5133208664113163e-06,
      "loss": 0.4362,
      "step": 1935
    },
    {
      "epoch": 2.49,
      "learning_rate": 1.5059959701807315e-06,
      "loss": 0.4469,
      "step": 1936
    },
    {
      "epoch": 2.49,
      "learning_rate": 1.4986874004213813e-06,
      "loss": 0.4287,
      "step": 1937
    },
    {
      "epoch": 2.49,
      "learning_rate": 1.4913951711811913e-06,
      "loss": 0.4614,
      "step": 1938
    },
    {
      "epoch": 2.49,
      "learning_rate": 1.4841192964766847e-06,
      "loss": 0.4402,
      "step": 1939
    },
    {
      "epoch": 2.49,
      "learning_rate": 1.4768597902929415e-06,
      "loss": 0.4595,
      "step": 1940
    },
    {
      "epoch": 2.49,
      "learning_rate": 1.4696166665835853e-06,
      "loss": 0.4568,
      "step": 1941
    },
    {
      "epoch": 2.49,
      "learning_rate": 1.4623899392707475e-06,
      "loss": 0.4574,
      "step": 1942
    },
    {
      "epoch": 2.49,
      "learning_rate": 1.4551796222450465e-06,
      "loss": 0.4467,
      "step": 1943
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.4479857293655542e-06,
      "loss": 0.4313,
      "step": 1944
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.4408082744597807e-06,
      "loss": 0.4435,
      "step": 1945
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.4336472713236282e-06,
      "loss": 0.4537,
      "step": 1946
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.4265027337213899e-06,
      "loss": 0.4426,
      "step": 1947
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.4193746753857041e-06,
      "loss": 0.4541,
      "step": 1948
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.41226311001753e-06,
      "loss": 0.4272,
      "step": 1949
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.4051680512861355e-06,
      "loss": 0.4531,
      "step": 1950
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.3980895128290495e-06,
      "loss": 0.4297,
      "step": 1951
    },
    {
      "epoch": 2.51,
      "learning_rate": 1.3910275082520575e-06,
      "loss": 0.4458,
      "step": 1952
    },
    {
      "epoch": 2.51,
      "learning_rate": 1.3839820511291545e-06,
      "loss": 0.461,
      "step": 1953
    },
    {
      "epoch": 2.51,
      "learning_rate": 1.3769531550025406e-06,
      "loss": 0.4379,
      "step": 1954
    },
    {
      "epoch": 2.51,
      "learning_rate": 1.3699408333825737e-06,
      "loss": 0.4435,
      "step": 1955
    },
    {
      "epoch": 2.51,
      "learning_rate": 1.3629450997477578e-06,
      "loss": 0.4641,
      "step": 1956
    },
    {
      "epoch": 2.51,
      "learning_rate": 1.355965967544718e-06,
      "loss": 0.4508,
      "step": 1957
    },
    {
      "epoch": 2.51,
      "learning_rate": 1.3490034501881577e-06,
      "loss": 0.4448,
      "step": 1958
    },
    {
      "epoch": 2.51,
      "learning_rate": 1.3420575610608554e-06,
      "loss": 0.4484,
      "step": 1959
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.3351283135136218e-06,
      "loss": 0.4442,
      "step": 1960
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.3282157208652858e-06,
      "loss": 0.4446,
      "step": 1961
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.321319796402657e-06,
      "loss": 0.4616,
      "step": 1962
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.3144405533805138e-06,
      "loss": 0.4423,
      "step": 1963
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.3075780050215637e-06,
      "loss": 0.4601,
      "step": 1964
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.300732164516433e-06,
      "loss": 0.4386,
      "step": 1965
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.2939030450236245e-06,
      "loss": 0.4402,
      "step": 1966
    },
    {
      "epoch": 2.53,
      "learning_rate": 1.28709065966951e-06,
      "loss": 0.4466,
      "step": 1967
    },
    {
      "epoch": 2.53,
      "learning_rate": 1.2802950215482945e-06,
      "loss": 0.4647,
      "step": 1968
    },
    {
      "epoch": 2.53,
      "learning_rate": 1.2735161437219857e-06,
      "loss": 0.4596,
      "step": 1969
    },
    {
      "epoch": 2.53,
      "learning_rate": 1.2667540392203858e-06,
      "loss": 0.4542,
      "step": 1970
    },
    {
      "epoch": 2.53,
      "learning_rate": 1.2600087210410472e-06,
      "loss": 0.4523,
      "step": 1971
    },
    {
      "epoch": 2.53,
      "learning_rate": 1.2532802021492685e-06,
      "loss": 0.4544,
      "step": 1972
    },
    {
      "epoch": 2.53,
      "learning_rate": 1.2465684954780444e-06,
      "loss": 0.4498,
      "step": 1973
    },
    {
      "epoch": 2.53,
      "learning_rate": 1.2398736139280687e-06,
      "loss": 0.4531,
      "step": 1974
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.2331955703676823e-06,
      "loss": 0.4546,
      "step": 1975
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.226534377632872e-06,
      "loss": 0.4611,
      "step": 1976
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.219890048527228e-06,
      "loss": 0.4557,
      "step": 1977
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.2132625958219301e-06,
      "loss": 0.4412,
      "step": 1978
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.2066520322557219e-06,
      "loss": 0.4363,
      "step": 1979
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.2000583705348767e-06,
      "loss": 0.4437,
      "step": 1980
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.1934816233331904e-06,
      "loss": 0.4389,
      "step": 1981
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.1869218032919371e-06,
      "loss": 0.4382,
      "step": 1982
    },
    {
      "epoch": 2.55,
      "learning_rate": 1.1803789230198636e-06,
      "loss": 0.4564,
      "step": 1983
    },
    {
      "epoch": 2.55,
      "learning_rate": 1.1738529950931477e-06,
      "loss": 0.4331,
      "step": 1984
    },
    {
      "epoch": 2.55,
      "learning_rate": 1.1673440320553941e-06,
      "loss": 0.4587,
      "step": 1985
    },
    {
      "epoch": 2.55,
      "learning_rate": 1.1608520464175865e-06,
      "loss": 0.4521,
      "step": 1986
    },
    {
      "epoch": 2.55,
      "learning_rate": 1.1543770506580875e-06,
      "loss": 0.4413,
      "step": 1987
    },
    {
      "epoch": 2.55,
      "learning_rate": 1.1479190572225929e-06,
      "loss": 0.4398,
      "step": 1988
    },
    {
      "epoch": 2.55,
      "learning_rate": 1.1414780785241252e-06,
      "loss": 0.4583,
      "step": 1989
    },
    {
      "epoch": 2.55,
      "learning_rate": 1.1350541269430015e-06,
      "loss": 0.4443,
      "step": 1990
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.128647214826808e-06,
      "loss": 0.4582,
      "step": 1991
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.1222573544903824e-06,
      "loss": 0.4605,
      "step": 1992
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.1158845582157817e-06,
      "loss": 0.4497,
      "step": 1993
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.1095288382522717e-06,
      "loss": 0.4537,
      "step": 1994
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.103190206816287e-06,
      "loss": 0.442,
      "step": 1995
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.0968686760914248e-06,
      "loss": 0.4518,
      "step": 1996
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.0905642582284015e-06,
      "loss": 0.4402,
      "step": 1997
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.0842769653450536e-06,
      "loss": 0.4422,
      "step": 1998
    },
    {
      "epoch": 2.57,
      "learning_rate": 1.0780068095262896e-06,
      "loss": 0.4519,
      "step": 1999
    },
    {
      "epoch": 2.57,
      "learning_rate": 1.071753802824087e-06,
      "loss": 0.4541,
      "step": 2000
    },
    {
      "epoch": 2.57,
      "learning_rate": 1.065517957257458e-06,
      "loss": 0.4345,
      "step": 2001
    },
    {
      "epoch": 2.57,
      "learning_rate": 1.0592992848124263e-06,
      "loss": 0.4651,
      "step": 2002
    },
    {
      "epoch": 2.57,
      "learning_rate": 1.0530977974420109e-06,
      "loss": 0.4425,
      "step": 2003
    },
    {
      "epoch": 2.57,
      "learning_rate": 1.0469135070661961e-06,
      "loss": 0.4475,
      "step": 2004
    },
    {
      "epoch": 2.57,
      "learning_rate": 1.0407464255719145e-06,
      "loss": 0.4585,
      "step": 2005
    },
    {
      "epoch": 2.58,
      "learning_rate": 1.0345965648130174e-06,
      "loss": 0.4469,
      "step": 2006
    },
    {
      "epoch": 2.58,
      "learning_rate": 1.02846393661026e-06,
      "loss": 0.4456,
      "step": 2007
    },
    {
      "epoch": 2.58,
      "learning_rate": 1.02234855275127e-06,
      "loss": 0.4524,
      "step": 2008
    },
    {
      "epoch": 2.58,
      "learning_rate": 1.0162504249905325e-06,
      "loss": 0.4506,
      "step": 2009
    },
    {
      "epoch": 2.58,
      "learning_rate": 1.010169565049367e-06,
      "loss": 0.4558,
      "step": 2010
    },
    {
      "epoch": 2.58,
      "learning_rate": 1.0041059846158952e-06,
      "loss": 0.4478,
      "step": 2011
    },
    {
      "epoch": 2.58,
      "learning_rate": 9.980596953450317e-07,
      "loss": 0.4663,
      "step": 2012
    },
    {
      "epoch": 2.58,
      "learning_rate": 9.920307088584503e-07,
      "loss": 0.4519,
      "step": 2013
    },
    {
      "epoch": 2.59,
      "learning_rate": 9.860190367445733e-07,
      "loss": 0.4412,
      "step": 2014
    },
    {
      "epoch": 2.59,
      "learning_rate": 9.800246905585354e-07,
      "loss": 0.4346,
      "step": 2015
    },
    {
      "epoch": 2.59,
      "learning_rate": 9.740476818221733e-07,
      "loss": 0.4594,
      "step": 2016
    },
    {
      "epoch": 2.59,
      "learning_rate": 9.680880220240018e-07,
      "loss": 0.433,
      "step": 2017
    },
    {
      "epoch": 2.59,
      "learning_rate": 9.62145722619182e-07,
      "loss": 0.455,
      "step": 2018
    },
    {
      "epoch": 2.59,
      "learning_rate": 9.56220795029511e-07,
      "loss": 0.4522,
      "step": 2019
    },
    {
      "epoch": 2.59,
      "learning_rate": 9.503132506433932e-07,
      "loss": 0.4343,
      "step": 2020
    },
    {
      "epoch": 2.59,
      "learning_rate": 9.444231008158211e-07,
      "loss": 0.4371,
      "step": 2021
    },
    {
      "epoch": 2.6,
      "learning_rate": 9.385503568683551e-07,
      "loss": 0.4279,
      "step": 2022
    },
    {
      "epoch": 2.6,
      "learning_rate": 9.326950300890947e-07,
      "loss": 0.4607,
      "step": 2023
    },
    {
      "epoch": 2.6,
      "learning_rate": 9.26857131732668e-07,
      "loss": 0.4679,
      "step": 2024
    },
    {
      "epoch": 2.6,
      "learning_rate": 9.210366730201947e-07,
      "loss": 0.4415,
      "step": 2025
    },
    {
      "epoch": 2.6,
      "learning_rate": 9.152336651392824e-07,
      "loss": 0.449,
      "step": 2026
    },
    {
      "epoch": 2.6,
      "learning_rate": 9.094481192439896e-07,
      "loss": 0.4499,
      "step": 2027
    },
    {
      "epoch": 2.6,
      "learning_rate": 9.036800464548157e-07,
      "loss": 0.4505,
      "step": 2028
    },
    {
      "epoch": 2.6,
      "learning_rate": 8.979294578586739e-07,
      "loss": 0.4594,
      "step": 2029
    },
    {
      "epoch": 2.61,
      "learning_rate": 8.921963645088649e-07,
      "loss": 0.4383,
      "step": 2030
    },
    {
      "epoch": 2.61,
      "learning_rate": 8.864807774250717e-07,
      "loss": 0.4453,
      "step": 2031
    },
    {
      "epoch": 2.61,
      "learning_rate": 8.807827075933161e-07,
      "loss": 0.443,
      "step": 2032
    },
    {
      "epoch": 2.61,
      "learning_rate": 8.751021659659608e-07,
      "loss": 0.4479,
      "step": 2033
    },
    {
      "epoch": 2.61,
      "learning_rate": 8.694391634616728e-07,
      "loss": 0.4422,
      "step": 2034
    },
    {
      "epoch": 2.61,
      "learning_rate": 8.637937109654027e-07,
      "loss": 0.4497,
      "step": 2035
    },
    {
      "epoch": 2.61,
      "learning_rate": 8.581658193283771e-07,
      "loss": 0.4632,
      "step": 2036
    },
    {
      "epoch": 2.61,
      "learning_rate": 8.525554993680585e-07,
      "loss": 0.4522,
      "step": 2037
    },
    {
      "epoch": 2.62,
      "learning_rate": 8.46962761868142e-07,
      "loss": 0.4487,
      "step": 2038
    },
    {
      "epoch": 2.62,
      "learning_rate": 8.41387617578523e-07,
      "loss": 0.4458,
      "step": 2039
    },
    {
      "epoch": 2.62,
      "learning_rate": 8.35830077215285e-07,
      "loss": 0.4711,
      "step": 2040
    },
    {
      "epoch": 2.62,
      "learning_rate": 8.302901514606687e-07,
      "loss": 0.4456,
      "step": 2041
    },
    {
      "epoch": 2.62,
      "learning_rate": 8.247678509630608e-07,
      "loss": 0.449,
      "step": 2042
    },
    {
      "epoch": 2.62,
      "learning_rate": 8.192631863369737e-07,
      "loss": 0.4504,
      "step": 2043
    },
    {
      "epoch": 2.62,
      "learning_rate": 8.137761681630141e-07,
      "loss": 0.4246,
      "step": 2044
    },
    {
      "epoch": 2.63,
      "learning_rate": 8.083068069878775e-07,
      "loss": 0.4631,
      "step": 2045
    },
    {
      "epoch": 2.63,
      "learning_rate": 8.028551133243123e-07,
      "loss": 0.4338,
      "step": 2046
    },
    {
      "epoch": 2.63,
      "learning_rate": 7.974210976511177e-07,
      "loss": 0.4423,
      "step": 2047
    },
    {
      "epoch": 2.63,
      "learning_rate": 7.920047704131039e-07,
      "loss": 0.4412,
      "step": 2048
    },
    {
      "epoch": 2.63,
      "learning_rate": 7.866061420210913e-07,
      "loss": 0.4404,
      "step": 2049
    },
    {
      "epoch": 2.63,
      "learning_rate": 7.812252228518724e-07,
      "loss": 0.4494,
      "step": 2050
    },
    {
      "epoch": 2.63,
      "learning_rate": 7.758620232482083e-07,
      "loss": 0.4428,
      "step": 2051
    },
    {
      "epoch": 2.63,
      "learning_rate": 7.70516553518793e-07,
      "loss": 0.4461,
      "step": 2052
    },
    {
      "epoch": 2.64,
      "learning_rate": 7.651888239382477e-07,
      "loss": 0.4673,
      "step": 2053
    },
    {
      "epoch": 2.64,
      "learning_rate": 7.598788447470961e-07,
      "loss": 0.443,
      "step": 2054
    },
    {
      "epoch": 2.64,
      "learning_rate": 7.545866261517354e-07,
      "loss": 0.439,
      "step": 2055
    },
    {
      "epoch": 2.64,
      "learning_rate": 7.493121783244339e-07,
      "loss": 0.4472,
      "step": 2056
    },
    {
      "epoch": 2.64,
      "learning_rate": 7.440555114032954e-07,
      "loss": 0.4463,
      "step": 2057
    },
    {
      "epoch": 2.64,
      "learning_rate": 7.388166354922532e-07,
      "loss": 0.4447,
      "step": 2058
    },
    {
      "epoch": 2.64,
      "learning_rate": 7.335955606610367e-07,
      "loss": 0.447,
      "step": 2059
    },
    {
      "epoch": 2.64,
      "learning_rate": 7.283922969451673e-07,
      "loss": 0.4388,
      "step": 2060
    },
    {
      "epoch": 2.65,
      "learning_rate": 7.232068543459258e-07,
      "loss": 0.4393,
      "step": 2061
    },
    {
      "epoch": 2.65,
      "learning_rate": 7.180392428303395e-07,
      "loss": 0.4598,
      "step": 2062
    },
    {
      "epoch": 2.65,
      "learning_rate": 7.128894723311675e-07,
      "loss": 0.4519,
      "step": 2063
    },
    {
      "epoch": 2.65,
      "learning_rate": 7.077575527468683e-07,
      "loss": 0.4523,
      "step": 2064
    },
    {
      "epoch": 2.65,
      "learning_rate": 7.026434939415949e-07,
      "loss": 0.4313,
      "step": 2065
    },
    {
      "epoch": 2.65,
      "learning_rate": 6.975473057451653e-07,
      "loss": 0.4533,
      "step": 2066
    },
    {
      "epoch": 2.65,
      "learning_rate": 6.924689979530552e-07,
      "loss": 0.4502,
      "step": 2067
    },
    {
      "epoch": 2.65,
      "learning_rate": 6.874085803263608e-07,
      "loss": 0.4503,
      "step": 2068
    },
    {
      "epoch": 2.66,
      "learning_rate": 6.823660625918039e-07,
      "loss": 0.4313,
      "step": 2069
    },
    {
      "epoch": 2.66,
      "learning_rate": 6.773414544416901e-07,
      "loss": 0.4365,
      "step": 2070
    },
    {
      "epoch": 2.66,
      "learning_rate": 6.723347655339085e-07,
      "loss": 0.4589,
      "step": 2071
    },
    {
      "epoch": 2.66,
      "learning_rate": 6.67346005491899e-07,
      "loss": 0.4432,
      "step": 2072
    },
    {
      "epoch": 2.66,
      "learning_rate": 6.623751839046455e-07,
      "loss": 0.437,
      "step": 2073
    },
    {
      "epoch": 2.66,
      "learning_rate": 6.574223103266486e-07,
      "loss": 0.4408,
      "step": 2074
    },
    {
      "epoch": 2.66,
      "learning_rate": 6.524873942779119e-07,
      "loss": 0.4407,
      "step": 2075
    },
    {
      "epoch": 2.66,
      "learning_rate": 6.475704452439224e-07,
      "loss": 0.4559,
      "step": 2076
    },
    {
      "epoch": 2.67,
      "learning_rate": 6.426714726756322e-07,
      "loss": 0.4614,
      "step": 2077
    },
    {
      "epoch": 2.67,
      "learning_rate": 6.377904859894423e-07,
      "loss": 0.4589,
      "step": 2078
    },
    {
      "epoch": 2.67,
      "learning_rate": 6.329274945671781e-07,
      "loss": 0.4551,
      "step": 2079
    },
    {
      "epoch": 2.67,
      "learning_rate": 6.280825077560814e-07,
      "loss": 0.4735,
      "step": 2080
    },
    {
      "epoch": 2.67,
      "learning_rate": 6.232555348687841e-07,
      "loss": 0.4509,
      "step": 2081
    },
    {
      "epoch": 2.67,
      "learning_rate": 6.184465851832944e-07,
      "loss": 0.4291,
      "step": 2082
    },
    {
      "epoch": 2.67,
      "learning_rate": 6.136556679429751e-07,
      "loss": 0.4649,
      "step": 2083
    },
    {
      "epoch": 2.68,
      "learning_rate": 6.088827923565321e-07,
      "loss": 0.4502,
      "step": 2084
    },
    {
      "epoch": 2.68,
      "learning_rate": 6.041279675979927e-07,
      "loss": 0.4299,
      "step": 2085
    },
    {
      "epoch": 2.68,
      "learning_rate": 5.99391202806685e-07,
      "loss": 0.4471,
      "step": 2086
    },
    {
      "epoch": 2.68,
      "learning_rate": 5.946725070872295e-07,
      "loss": 0.4525,
      "step": 2087
    },
    {
      "epoch": 2.68,
      "learning_rate": 5.899718895095086e-07,
      "loss": 0.4534,
      "step": 2088
    },
    {
      "epoch": 2.68,
      "learning_rate": 5.852893591086628e-07,
      "loss": 0.4398,
      "step": 2089
    },
    {
      "epoch": 2.68,
      "learning_rate": 5.806249248850626e-07,
      "loss": 0.4404,
      "step": 2090
    },
    {
      "epoch": 2.68,
      "learning_rate": 5.759785958042985e-07,
      "loss": 0.4425,
      "step": 2091
    },
    {
      "epoch": 2.69,
      "learning_rate": 5.713503807971587e-07,
      "loss": 0.4424,
      "step": 2092
    },
    {
      "epoch": 2.69,
      "learning_rate": 5.667402887596152e-07,
      "loss": 0.4485,
      "step": 2093
    },
    {
      "epoch": 2.69,
      "learning_rate": 5.621483285528051e-07,
      "loss": 0.4405,
      "step": 2094
    },
    {
      "epoch": 2.69,
      "learning_rate": 5.575745090030138e-07,
      "loss": 0.44,
      "step": 2095
    },
    {
      "epoch": 2.69,
      "learning_rate": 5.5301883890166e-07,
      "loss": 0.4536,
      "step": 2096
    },
    {
      "epoch": 2.69,
      "learning_rate": 5.484813270052736e-07,
      "loss": 0.4206,
      "step": 2097
    },
    {
      "epoch": 2.69,
      "learning_rate": 5.439619820354858e-07,
      "loss": 0.452,
      "step": 2098
    },
    {
      "epoch": 2.69,
      "learning_rate": 5.394608126790058e-07,
      "loss": 0.4523,
      "step": 2099
    },
    {
      "epoch": 2.7,
      "learning_rate": 5.349778275876105e-07,
      "loss": 0.4542,
      "step": 2100
    },
    {
      "epoch": 2.7,
      "learning_rate": 5.305130353781207e-07,
      "loss": 0.4447,
      "step": 2101
    },
    {
      "epoch": 2.7,
      "learning_rate": 5.260664446323926e-07,
      "loss": 0.4409,
      "step": 2102
    },
    {
      "epoch": 2.7,
      "learning_rate": 5.216380638972918e-07,
      "loss": 0.442,
      "step": 2103
    },
    {
      "epoch": 2.7,
      "learning_rate": 5.172279016846882e-07,
      "loss": 0.4383,
      "step": 2104
    },
    {
      "epoch": 2.7,
      "learning_rate": 5.128359664714267e-07,
      "loss": 0.424,
      "step": 2105
    },
    {
      "epoch": 2.7,
      "learning_rate": 5.084622666993244e-07,
      "loss": 0.4324,
      "step": 2106
    },
    {
      "epoch": 2.7,
      "learning_rate": 5.041068107751445e-07,
      "loss": 0.4339,
      "step": 2107
    },
    {
      "epoch": 2.71,
      "learning_rate": 4.997696070705837e-07,
      "loss": 0.4367,
      "step": 2108
    },
    {
      "epoch": 2.71,
      "learning_rate": 4.954506639222556e-07,
      "loss": 0.4538,
      "step": 2109
    },
    {
      "epoch": 2.71,
      "learning_rate": 4.911499896316741e-07,
      "loss": 0.4402,
      "step": 2110
    },
    {
      "epoch": 2.71,
      "learning_rate": 4.86867592465241e-07,
      "loss": 0.4384,
      "step": 2111
    },
    {
      "epoch": 2.71,
      "learning_rate": 4.826034806542234e-07,
      "loss": 0.4586,
      "step": 2112
    },
    {
      "epoch": 2.71,
      "learning_rate": 4.783576623947472e-07,
      "loss": 0.4343,
      "step": 2113
    },
    {
      "epoch": 2.71,
      "learning_rate": 4.741301458477687e-07,
      "loss": 0.4411,
      "step": 2114
    },
    {
      "epoch": 2.72,
      "learning_rate": 4.699209391390735e-07,
      "loss": 0.4342,
      "step": 2115
    },
    {
      "epoch": 2.72,
      "learning_rate": 4.657300503592488e-07,
      "loss": 0.4484,
      "step": 2116
    },
    {
      "epoch": 2.72,
      "learning_rate": 4.61557487563673e-07,
      "loss": 0.4463,
      "step": 2117
    },
    {
      "epoch": 2.72,
      "learning_rate": 4.574032587725041e-07,
      "loss": 0.4413,
      "step": 2118
    },
    {
      "epoch": 2.72,
      "learning_rate": 4.532673719706526e-07,
      "loss": 0.4375,
      "step": 2119
    },
    {
      "epoch": 2.72,
      "learning_rate": 4.4914983510778055e-07,
      "loss": 0.4659,
      "step": 2120
    },
    {
      "epoch": 2.72,
      "learning_rate": 4.450506560982748e-07,
      "loss": 0.4616,
      "step": 2121
    },
    {
      "epoch": 2.72,
      "learning_rate": 4.4096984282123944e-07,
      "loss": 0.4217,
      "step": 2122
    },
    {
      "epoch": 2.73,
      "learning_rate": 4.369074031204734e-07,
      "loss": 0.4409,
      "step": 2123
    },
    {
      "epoch": 2.73,
      "learning_rate": 4.32863344804465e-07,
      "loss": 0.4345,
      "step": 2124
    },
    {
      "epoch": 2.73,
      "learning_rate": 4.2883767564636523e-07,
      "loss": 0.4325,
      "step": 2125
    },
    {
      "epoch": 2.73,
      "learning_rate": 4.248304033839834e-07,
      "loss": 0.4467,
      "step": 2126
    },
    {
      "epoch": 2.73,
      "learning_rate": 4.2084153571976705e-07,
      "loss": 0.4475,
      "step": 2127
    },
    {
      "epoch": 2.73,
      "learning_rate": 4.168710803207865e-07,
      "loss": 0.4479,
      "step": 2128
    },
    {
      "epoch": 2.73,
      "learning_rate": 4.1291904481872256e-07,
      "loss": 0.4525,
      "step": 2129
    },
    {
      "epoch": 2.73,
      "learning_rate": 4.0898543680985114e-07,
      "loss": 0.4493,
      "step": 2130
    },
    {
      "epoch": 2.74,
      "learning_rate": 4.0507026385502747e-07,
      "loss": 0.4367,
      "step": 2131
    },
    {
      "epoch": 2.74,
      "learning_rate": 4.011735334796718e-07,
      "loss": 0.4505,
      "step": 2132
    },
    {
      "epoch": 2.74,
      "learning_rate": 3.972952531737584e-07,
      "loss": 0.4397,
      "step": 2133
    },
    {
      "epoch": 2.74,
      "learning_rate": 3.934354303917953e-07,
      "loss": 0.4446,
      "step": 2134
    },
    {
      "epoch": 2.74,
      "learning_rate": 3.8959407255281466e-07,
      "loss": 0.455,
      "step": 2135
    },
    {
      "epoch": 2.74,
      "learning_rate": 3.857711870403558e-07,
      "loss": 0.4458,
      "step": 2136
    },
    {
      "epoch": 2.74,
      "learning_rate": 3.819667812024541e-07,
      "loss": 0.4528,
      "step": 2137
    },
    {
      "epoch": 2.74,
      "learning_rate": 3.7818086235162256e-07,
      "loss": 0.4458,
      "step": 2138
    },
    {
      "epoch": 2.75,
      "learning_rate": 3.7441343776484116e-07,
      "loss": 0.4484,
      "step": 2139
    },
    {
      "epoch": 2.75,
      "learning_rate": 3.706645146835419e-07,
      "loss": 0.4419,
      "step": 2140
    },
    {
      "epoch": 2.75,
      "learning_rate": 3.669341003135929e-07,
      "loss": 0.4586,
      "step": 2141
    },
    {
      "epoch": 2.75,
      "learning_rate": 3.6322220182528843e-07,
      "loss": 0.4549,
      "step": 2142
    },
    {
      "epoch": 2.75,
      "learning_rate": 3.595288263533336e-07,
      "loss": 0.4238,
      "step": 2143
    },
    {
      "epoch": 2.75,
      "learning_rate": 3.558539809968264e-07,
      "loss": 0.4729,
      "step": 2144
    },
    {
      "epoch": 2.75,
      "learning_rate": 3.521976728192544e-07,
      "loss": 0.4407,
      "step": 2145
    },
    {
      "epoch": 2.75,
      "learning_rate": 3.485599088484659e-07,
      "loss": 0.4502,
      "step": 2146
    },
    {
      "epoch": 2.76,
      "learning_rate": 3.4494069607667326e-07,
      "loss": 0.4298,
      "step": 2147
    },
    {
      "epoch": 2.76,
      "learning_rate": 3.41340041460424e-07,
      "loss": 0.449,
      "step": 2148
    },
    {
      "epoch": 2.76,
      "learning_rate": 3.377579519206009e-07,
      "loss": 0.4595,
      "step": 2149
    },
    {
      "epoch": 2.76,
      "learning_rate": 3.3419443434240083e-07,
      "loss": 0.457,
      "step": 2150
    },
    {
      "epoch": 2.76,
      "learning_rate": 3.306494955753181e-07,
      "loss": 0.4441,
      "step": 2151
    },
    {
      "epoch": 2.76,
      "learning_rate": 3.271231424331456e-07,
      "loss": 0.4512,
      "step": 2152
    },
    {
      "epoch": 2.76,
      "learning_rate": 3.2361538169394244e-07,
      "loss": 0.4421,
      "step": 2153
    },
    {
      "epoch": 2.77,
      "learning_rate": 3.201262201000388e-07,
      "loss": 0.4526,
      "step": 2154
    },
    {
      "epoch": 2.77,
      "learning_rate": 3.166556643580121e-07,
      "loss": 0.451,
      "step": 2155
    },
    {
      "epoch": 2.77,
      "learning_rate": 3.1320372113867626e-07,
      "loss": 0.4402,
      "step": 2156
    },
    {
      "epoch": 2.77,
      "learning_rate": 3.097703970770716e-07,
      "loss": 0.4269,
      "step": 2157
    },
    {
      "epoch": 2.77,
      "learning_rate": 3.063556987724481e-07,
      "loss": 0.4487,
      "step": 2158
    },
    {
      "epoch": 2.77,
      "learning_rate": 3.029596327882578e-07,
      "loss": 0.4588,
      "step": 2159
    },
    {
      "epoch": 2.77,
      "learning_rate": 2.995822056521358e-07,
      "loss": 0.4525,
      "step": 2160
    },
    {
      "epoch": 2.77,
      "learning_rate": 2.9622342385589256e-07,
      "loss": 0.4457,
      "step": 2161
    },
    {
      "epoch": 2.78,
      "learning_rate": 2.9288329385550375e-07,
      "loss": 0.4379,
      "step": 2162
    },
    {
      "epoch": 2.78,
      "learning_rate": 2.895618220710872e-07,
      "loss": 0.4723,
      "step": 2163
    },
    {
      "epoch": 2.78,
      "learning_rate": 2.862590148869027e-07,
      "loss": 0.4455,
      "step": 2164
    },
    {
      "epoch": 2.78,
      "learning_rate": 2.82974878651332e-07,
      "loss": 0.4659,
      "step": 2165
    },
    {
      "epoch": 2.78,
      "learning_rate": 2.7970941967687013e-07,
      "loss": 0.4312,
      "step": 2166
    },
    {
      "epoch": 2.78,
      "learning_rate": 2.764626442401119e-07,
      "loss": 0.4421,
      "step": 2167
    },
    {
      "epoch": 2.78,
      "learning_rate": 2.732345585817398e-07,
      "loss": 0.4413,
      "step": 2168
    },
    {
      "epoch": 2.78,
      "learning_rate": 2.7002516890651365e-07,
      "loss": 0.4537,
      "step": 2169
    },
    {
      "epoch": 2.79,
      "learning_rate": 2.6683448138325574e-07,
      "loss": 0.4502,
      "step": 2170
    },
    {
      "epoch": 2.79,
      "learning_rate": 2.6366250214484247e-07,
      "loss": 0.4565,
      "step": 2171
    },
    {
      "epoch": 2.79,
      "learning_rate": 2.605092372881879e-07,
      "loss": 0.4405,
      "step": 2172
    },
    {
      "epoch": 2.79,
      "learning_rate": 2.573746928742382e-07,
      "loss": 0.4332,
      "step": 2173
    },
    {
      "epoch": 2.79,
      "learning_rate": 2.542588749279551e-07,
      "loss": 0.4245,
      "step": 2174
    },
    {
      "epoch": 2.79,
      "learning_rate": 2.5116178943830563e-07,
      "loss": 0.4443,
      "step": 2175
    },
    {
      "epoch": 2.79,
      "learning_rate": 2.48083442358249e-07,
      "loss": 0.4538,
      "step": 2176
    },
    {
      "epoch": 2.79,
      "learning_rate": 2.450238396047333e-07,
      "loss": 0.4261,
      "step": 2177
    },
    {
      "epoch": 2.8,
      "learning_rate": 2.419829870586698e-07,
      "loss": 0.4468,
      "step": 2178
    },
    {
      "epoch": 2.8,
      "learning_rate": 2.389608905649343e-07,
      "loss": 0.4633,
      "step": 2179
    },
    {
      "epoch": 2.8,
      "learning_rate": 2.3595755593235235e-07,
      "loss": 0.4661,
      "step": 2180
    },
    {
      "epoch": 2.8,
      "learning_rate": 2.3297298893368292e-07,
      "loss": 0.4531,
      "step": 2181
    },
    {
      "epoch": 2.8,
      "learning_rate": 2.3000719530561488e-07,
      "loss": 0.4453,
      "step": 2182
    },
    {
      "epoch": 2.8,
      "learning_rate": 2.2706018074875046e-07,
      "loss": 0.4345,
      "step": 2183
    },
    {
      "epoch": 2.8,
      "learning_rate": 2.2413195092759853e-07,
      "loss": 0.442,
      "step": 2184
    },
    {
      "epoch": 2.8,
      "learning_rate": 2.2122251147055684e-07,
      "loss": 0.4351,
      "step": 2185
    },
    {
      "epoch": 2.81,
      "learning_rate": 2.1833186796991312e-07,
      "loss": 0.439,
      "step": 2186
    },
    {
      "epoch": 2.81,
      "learning_rate": 2.1546002598181848e-07,
      "loss": 0.451,
      "step": 2187
    },
    {
      "epoch": 2.81,
      "learning_rate": 2.12606991026294e-07,
      "loss": 0.4417,
      "step": 2188
    },
    {
      "epoch": 2.81,
      "learning_rate": 2.097727685872042e-07,
      "loss": 0.4335,
      "step": 2189
    },
    {
      "epoch": 2.81,
      "learning_rate": 2.0695736411225798e-07,
      "loss": 0.4436,
      "step": 2190
    },
    {
      "epoch": 2.81,
      "learning_rate": 2.0416078301299325e-07,
      "loss": 0.4443,
      "step": 2191
    },
    {
      "epoch": 2.81,
      "learning_rate": 2.0138303066476572e-07,
      "loss": 0.4624,
      "step": 2192
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.9862411240674117e-07,
      "loss": 0.445,
      "step": 2193
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.9588403354188324e-07,
      "loss": 0.439,
      "step": 2194
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.931627993369467e-07,
      "loss": 0.4396,
      "step": 2195
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.9046041502245982e-07,
      "loss": 0.457,
      "step": 2196
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.8777688579272536e-07,
      "loss": 0.4441,
      "step": 2197
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.8511221680579728e-07,
      "loss": 0.4312,
      "step": 2198
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.8246641318348412e-07,
      "loss": 0.4453,
      "step": 2199
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.79839480011329e-07,
      "loss": 0.4346,
      "step": 2200
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.7723142233860624e-07,
      "loss": 0.4673,
      "step": 2201
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.746422451783103e-07,
      "loss": 0.4521,
      "step": 2202
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.7207195350713914e-07,
      "loss": 0.4401,
      "step": 2203
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.6952055226549746e-07,
      "loss": 0.4375,
      "step": 2204
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.669880463574758e-07,
      "loss": 0.4279,
      "step": 2205
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.6447444065084916e-07,
      "loss": 0.4373,
      "step": 2206
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.6197973997705952e-07,
      "loss": 0.4452,
      "step": 2207
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.5950394913121781e-07,
      "loss": 0.4495,
      "step": 2208
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.5704707287208076e-07,
      "loss": 0.4558,
      "step": 2209
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.5460911592205307e-07,
      "loss": 0.4668,
      "step": 2210
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.521900829671763e-07,
      "loss": 0.4437,
      "step": 2211
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.497899786571122e-07,
      "loss": 0.4439,
      "step": 2212
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.4740880760514388e-07,
      "loss": 0.4484,
      "step": 2213
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.4504657438816127e-07,
      "loss": 0.4622,
      "step": 2214
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.4270328354665352e-07,
      "loss": 0.4535,
      "step": 2215
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.4037893958469994e-07,
      "loss": 0.4358,
      "step": 2216
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.3807354696996233e-07,
      "loss": 0.4349,
      "step": 2217
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.3578711013367384e-07,
      "loss": 0.4833,
      "step": 2218
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.335196334706379e-07,
      "loss": 0.462,
      "step": 2219
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.3127112133920594e-07,
      "loss": 0.4534,
      "step": 2220
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.2904157806128413e-07,
      "loss": 0.4639,
      "step": 2221
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.2683100792231563e-07,
      "loss": 0.4667,
      "step": 2222
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.2463941517127597e-07,
      "loss": 0.4592,
      "step": 2223
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.2246680402066224e-07,
      "loss": 0.4504,
      "step": 2224
    },
    {
      "epoch": 2.86,
      "learning_rate": 1.203131786464873e-07,
      "loss": 0.4628,
      "step": 2225
    },
    {
      "epoch": 2.86,
      "learning_rate": 1.1817854318827426e-07,
      "loss": 0.4337,
      "step": 2226
    },
    {
      "epoch": 2.86,
      "learning_rate": 1.160629017490389e-07,
      "loss": 0.4536,
      "step": 2227
    },
    {
      "epoch": 2.86,
      "learning_rate": 1.1396625839529496e-07,
      "loss": 0.4407,
      "step": 2228
    },
    {
      "epoch": 2.86,
      "learning_rate": 1.1188861715703437e-07,
      "loss": 0.4442,
      "step": 2229
    },
    {
      "epoch": 2.86,
      "learning_rate": 1.0982998202772932e-07,
      "loss": 0.4367,
      "step": 2230
    },
    {
      "epoch": 2.86,
      "learning_rate": 1.0779035696431572e-07,
      "loss": 0.4446,
      "step": 2231
    },
    {
      "epoch": 2.87,
      "learning_rate": 1.0576974588719314e-07,
      "loss": 0.4524,
      "step": 2232
    },
    {
      "epoch": 2.87,
      "learning_rate": 1.0376815268021367e-07,
      "loss": 0.4492,
      "step": 2233
    },
    {
      "epoch": 2.87,
      "learning_rate": 1.0178558119067316e-07,
      "loss": 0.4421,
      "step": 2234
    },
    {
      "epoch": 2.87,
      "learning_rate": 9.982203522930556e-08,
      "loss": 0.4524,
      "step": 2235
    },
    {
      "epoch": 2.87,
      "learning_rate": 9.787751857027738e-08,
      "loss": 0.443,
      "step": 2236
    },
    {
      "epoch": 2.87,
      "learning_rate": 9.595203495117778e-08,
      "loss": 0.4524,
      "step": 2237
    },
    {
      "epoch": 2.87,
      "learning_rate": 9.404558807301067e-08,
      "loss": 0.4482,
      "step": 2238
    },
    {
      "epoch": 2.87,
      "learning_rate": 9.215818160019152e-08,
      "loss": 0.438,
      "step": 2239
    },
    {
      "epoch": 2.88,
      "learning_rate": 9.028981916053503e-08,
      "loss": 0.451,
      "step": 2240
    },
    {
      "epoch": 2.88,
      "learning_rate": 8.844050434525631e-08,
      "loss": 0.4249,
      "step": 2241
    },
    {
      "epoch": 2.88,
      "learning_rate": 8.661024070895197e-08,
      "loss": 0.4566,
      "step": 2242
    },
    {
      "epoch": 2.88,
      "learning_rate": 8.479903176960347e-08,
      "loss": 0.4389,
      "step": 2243
    },
    {
      "epoch": 2.88,
      "learning_rate": 8.300688100856824e-08,
      "loss": 0.4425,
      "step": 2244
    },
    {
      "epoch": 2.88,
      "learning_rate": 8.123379187056968e-08,
      "loss": 0.4497,
      "step": 2245
    },
    {
      "epoch": 2.88,
      "learning_rate": 7.94797677636916e-08,
      "loss": 0.4331,
      "step": 2246
    },
    {
      "epoch": 2.88,
      "learning_rate": 7.77448120593749e-08,
      "loss": 0.4212,
      "step": 2247
    },
    {
      "epoch": 2.89,
      "learning_rate": 7.602892809240869e-08,
      "loss": 0.4351,
      "step": 2248
    },
    {
      "epoch": 2.89,
      "learning_rate": 7.433211916092143e-08,
      "loss": 0.4499,
      "step": 2249
    },
    {
      "epoch": 2.89,
      "learning_rate": 7.265438852637973e-08,
      "loss": 0.444,
      "step": 2250
    },
    {
      "epoch": 2.89,
      "learning_rate": 7.09957394135774e-08,
      "loss": 0.4528,
      "step": 2251
    },
    {
      "epoch": 2.89,
      "learning_rate": 6.935617501063418e-08,
      "loss": 0.4453,
      "step": 2252
    },
    {
      "epoch": 2.89,
      "learning_rate": 6.773569846898254e-08,
      "loss": 0.4348,
      "step": 2253
    },
    {
      "epoch": 2.89,
      "learning_rate": 6.613431290337092e-08,
      "loss": 0.4583,
      "step": 2254
    },
    {
      "epoch": 2.89,
      "learning_rate": 6.455202139184825e-08,
      "loss": 0.4382,
      "step": 2255
    },
    {
      "epoch": 2.9,
      "learning_rate": 6.298882697576503e-08,
      "loss": 0.4486,
      "step": 2256
    },
    {
      "epoch": 2.9,
      "learning_rate": 6.144473265976558e-08,
      "loss": 0.4488,
      "step": 2257
    },
    {
      "epoch": 2.9,
      "learning_rate": 5.991974141177692e-08,
      "loss": 0.4528,
      "step": 2258
    },
    {
      "epoch": 2.9,
      "learning_rate": 5.841385616301321e-08,
      "loss": 0.4409,
      "step": 2259
    },
    {
      "epoch": 2.9,
      "learning_rate": 5.69270798079613e-08,
      "loss": 0.4412,
      "step": 2260
    },
    {
      "epoch": 2.9,
      "learning_rate": 5.545941520438081e-08,
      "loss": 0.4599,
      "step": 2261
    },
    {
      "epoch": 2.9,
      "learning_rate": 5.40108651732929e-08,
      "loss": 0.4467,
      "step": 2262
    },
    {
      "epoch": 2.91,
      "learning_rate": 5.258143249898373e-08,
      "loss": 0.4512,
      "step": 2263
    },
    {
      "epoch": 2.91,
      "learning_rate": 5.117111992898771e-08,
      "loss": 0.4283,
      "step": 2264
    },
    {
      "epoch": 2.91,
      "learning_rate": 4.9779930174091996e-08,
      "loss": 0.4421,
      "step": 2265
    },
    {
      "epoch": 2.91,
      "learning_rate": 4.840786590832647e-08,
      "loss": 0.4326,
      "step": 2266
    },
    {
      "epoch": 2.91,
      "learning_rate": 4.7054929768959314e-08,
      "loss": 0.4529,
      "step": 2267
    },
    {
      "epoch": 2.91,
      "learning_rate": 4.5721124356491454e-08,
      "loss": 0.4514,
      "step": 2268
    },
    {
      "epoch": 2.91,
      "learning_rate": 4.440645223465545e-08,
      "loss": 0.4475,
      "step": 2269
    },
    {
      "epoch": 2.91,
      "learning_rate": 4.3110915930402176e-08,
      "loss": 0.4255,
      "step": 2270
    },
    {
      "epoch": 2.92,
      "learning_rate": 4.183451793390747e-08,
      "loss": 0.4686,
      "step": 2271
    },
    {
      "epoch": 2.92,
      "learning_rate": 4.05772606985555e-08,
      "loss": 0.4288,
      "step": 2272
    },
    {
      "epoch": 2.92,
      "learning_rate": 3.9339146640942075e-08,
      "loss": 0.4446,
      "step": 2273
    },
    {
      "epoch": 2.92,
      "learning_rate": 3.81201781408691e-08,
      "loss": 0.4539,
      "step": 2274
    },
    {
      "epoch": 2.92,
      "learning_rate": 3.692035754133461e-08,
      "loss": 0.4405,
      "step": 2275
    },
    {
      "epoch": 2.92,
      "learning_rate": 3.573968714853715e-08,
      "loss": 0.4536,
      "step": 2276
    },
    {
      "epoch": 2.92,
      "learning_rate": 3.457816923186142e-08,
      "loss": 0.4527,
      "step": 2277
    },
    {
      "epoch": 2.92,
      "learning_rate": 3.343580602388263e-08,
      "loss": 0.4481,
      "step": 2278
    },
    {
      "epoch": 2.93,
      "learning_rate": 3.23125997203555e-08,
      "loss": 0.4426,
      "step": 2279
    },
    {
      "epoch": 2.93,
      "learning_rate": 3.120855248021415e-08,
      "loss": 0.4374,
      "step": 2280
    },
    {
      "epoch": 2.93,
      "learning_rate": 3.012366642556774e-08,
      "loss": 0.4524,
      "step": 2281
    },
    {
      "epoch": 2.93,
      "learning_rate": 2.9057943641693787e-08,
      "loss": 0.4536,
      "step": 2282
    },
    {
      "epoch": 2.93,
      "learning_rate": 2.8011386177037025e-08,
      "loss": 0.4535,
      "step": 2283
    },
    {
      "epoch": 2.93,
      "learning_rate": 2.6983996043201675e-08,
      "loss": 0.4628,
      "step": 2284
    },
    {
      "epoch": 2.93,
      "learning_rate": 2.597577521495476e-08,
      "loss": 0.4657,
      "step": 2285
    },
    {
      "epoch": 2.93,
      "learning_rate": 2.498672563021276e-08,
      "loss": 0.4595,
      "step": 2286
    },
    {
      "epoch": 2.94,
      "learning_rate": 2.4016849190044988e-08,
      "loss": 0.4515,
      "step": 2287
    },
    {
      "epoch": 2.94,
      "learning_rate": 2.306614775866911e-08,
      "loss": 0.4422,
      "step": 2288
    },
    {
      "epoch": 2.94,
      "learning_rate": 2.2134623163443393e-08,
      "loss": 0.4452,
      "step": 2289
    },
    {
      "epoch": 2.94,
      "learning_rate": 2.1222277194867803e-08,
      "loss": 0.4306,
      "step": 2290
    },
    {
      "epoch": 2.94,
      "learning_rate": 2.0329111606577355e-08,
      "loss": 0.4326,
      "step": 2291
    },
    {
      "epoch": 2.94,
      "learning_rate": 1.9455128115343225e-08,
      "loss": 0.4447,
      "step": 2292
    },
    {
      "epoch": 2.94,
      "learning_rate": 1.860032840106163e-08,
      "loss": 0.4356,
      "step": 2293
    },
    {
      "epoch": 2.94,
      "learning_rate": 1.7764714106759396e-08,
      "loss": 0.4594,
      "step": 2294
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.694828683858396e-08,
      "loss": 0.4402,
      "step": 2295
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.6151048165804485e-08,
      "loss": 0.4397,
      "step": 2296
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.5372999620808514e-08,
      "loss": 0.4433,
      "step": 2297
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.4614142699094224e-08,
      "loss": 0.4426,
      "step": 2298
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.3874478859275952e-08,
      "loss": 0.4319,
      "step": 2299
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.3154009523071998e-08,
      "loss": 0.4309,
      "step": 2300
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.2452736075311279e-08,
      "loss": 0.449,
      "step": 2301
    },
    {
      "epoch": 2.96,
      "learning_rate": 1.1770659863921119e-08,
      "loss": 0.4389,
      "step": 2302
    },
    {
      "epoch": 2.96,
      "learning_rate": 1.1107782199933914e-08,
      "loss": 0.4508,
      "step": 2303
    },
    {
      "epoch": 2.96,
      "learning_rate": 1.0464104357477133e-08,
      "loss": 0.4544,
      "step": 2304
    },
    {
      "epoch": 2.96,
      "learning_rate": 9.839627573775545e-09,
      "loss": 0.4505,
      "step": 2305
    },
    {
      "epoch": 2.96,
      "learning_rate": 9.23435304914566e-09,
      "loss": 0.4536,
      "step": 2306
    },
    {
      "epoch": 2.96,
      "learning_rate": 8.64828194699685e-09,
      "loss": 0.4465,
      "step": 2307
    },
    {
      "epoch": 2.96,
      "learning_rate": 8.081415393826896e-09,
      "loss": 0.4501,
      "step": 2308
    },
    {
      "epoch": 2.96,
      "learning_rate": 7.53375447921978e-09,
      "loss": 0.4412,
      "step": 2309
    },
    {
      "epoch": 2.97,
      "learning_rate": 7.00530025584345e-09,
      "loss": 0.4298,
      "step": 2310
    },
    {
      "epoch": 2.97,
      "learning_rate": 6.496053739447616e-09,
      "loss": 0.4253,
      "step": 2311
    },
    {
      "epoch": 2.97,
      "learning_rate": 6.006015908865959e-09,
      "loss": 0.4396,
      "step": 2312
    },
    {
      "epoch": 2.97,
      "learning_rate": 5.53518770600836e-09,
      "loss": 0.4452,
      "step": 2313
    },
    {
      "epoch": 2.97,
      "learning_rate": 5.083570035859797e-09,
      "loss": 0.4557,
      "step": 2314
    },
    {
      "epoch": 2.97,
      "learning_rate": 4.651163766484779e-09,
      "loss": 0.4414,
      "step": 2315
    },
    {
      "epoch": 2.97,
      "learning_rate": 4.237969729017355e-09,
      "loss": 0.4471,
      "step": 2316
    },
    {
      "epoch": 2.97,
      "learning_rate": 3.843988717665559e-09,
      "loss": 0.4452,
      "step": 2317
    },
    {
      "epoch": 2.98,
      "learning_rate": 3.469221489705854e-09,
      "loss": 0.4334,
      "step": 2318
    },
    {
      "epoch": 2.98,
      "learning_rate": 3.113668765486466e-09,
      "loss": 0.4396,
      "step": 2319
    },
    {
      "epoch": 2.98,
      "learning_rate": 2.777331228420721e-09,
      "loss": 0.4591,
      "step": 2320
    },
    {
      "epoch": 2.98,
      "learning_rate": 2.4602095249892657e-09,
      "loss": 0.4434,
      "step": 2321
    },
    {
      "epoch": 2.98,
      "learning_rate": 2.162304264735626e-09,
      "loss": 0.462,
      "step": 2322
    },
    {
      "epoch": 2.98,
      "learning_rate": 1.8836160202706512e-09,
      "loss": 0.4575,
      "step": 2323
    },
    {
      "epoch": 2.98,
      "learning_rate": 1.6241453272636265e-09,
      "loss": 0.4213,
      "step": 2324
    },
    {
      "epoch": 2.98,
      "learning_rate": 1.38389268445005e-09,
      "loss": 0.4484,
      "step": 2325
    },
    {
      "epoch": 2.99,
      "learning_rate": 1.1628585536216374e-09,
      "loss": 0.4331,
      "step": 2326
    },
    {
      "epoch": 2.99,
      "learning_rate": 9.610433596329848e-10,
      "loss": 0.4506,
      "step": 2327
    },
    {
      "epoch": 2.99,
      "learning_rate": 7.784474903960171e-10,
      "loss": 0.4527,
      "step": 2328
    },
    {
      "epoch": 2.99,
      "learning_rate": 6.150712968822081e-10,
      "loss": 0.4413,
      "step": 2329
    },
    {
      "epoch": 2.99,
      "learning_rate": 4.709150931192507e-10,
      "loss": 0.4657,
      "step": 2330
    },
    {
      "epoch": 2.99,
      "learning_rate": 3.4597915619105637e-10,
      "loss": 0.4355,
      "step": 2331
    },
    {
      "epoch": 2.99,
      "learning_rate": 2.402637262410856e-10,
      "loss": 0.4526,
      "step": 2332
    },
    {
      "epoch": 2.99,
      "learning_rate": 1.5376900646568716e-10,
      "loss": 0.4495,
      "step": 2333
    },
    {
      "epoch": 3.0,
      "learning_rate": 8.649516311853845e-11,
      "loss": 0.4562,
      "step": 2334
    },
    {
      "epoch": 3.0,
      "learning_rate": 3.844232550731519e-11,
      "loss": 0.4407,
      "step": 2335
    },
    {
      "epoch": 3.0,
      "learning_rate": 9.610585994801469e-12,
      "loss": 0.4484,
      "step": 2336
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0,
      "loss": 0.4553,
      "step": 2337
    },
    {
      "epoch": 3.0,
      "step": 2337,
      "total_flos": 1.6743668791933665e+18,
      "train_loss": 0.47801864417536827,
      "train_runtime": 27964.7816,
      "train_samples_per_second": 10.69,
      "train_steps_per_second": 0.084
    }
  ],
  "max_steps": 2337,
  "num_train_epochs": 3,
  "total_flos": 1.6743668791933665e+18,
  "trial_name": null,
  "trial_params": null
}
