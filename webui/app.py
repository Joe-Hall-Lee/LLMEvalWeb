from __future__ import annotations
import os
import sys
import gc
import gradio as gr
from gradio.components import Dropdown
from transformers import AutoTokenizer
import requests
import pandas as pd
import json

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from config import FINETUNED_JUDGE_MODELS, PROPRIETARY_MODELS
from utils import (
    update_batch_calibration_mode, clear_model,
    update_calibration_mode, update_model_choices, load_model_based_on_type,
    manual_evaluate, enable_evaluate_button, batch_evaluation, update_model_type, update_eval_mode
)
from helpers import (
    show_batch_calibration_mode, show_calibration_mode
)
from webui.theme import Seafoam, css
from visualization import analyze_results, update_report_list

# åœ¨ gr.Tabs å¤–éƒ¨å®šä¹‰å¯è§†åŒ–ç»„ä»¶
stats_html = gr.HTML(visible=True)
comp_plot = gr.Plot(label="æ¨¡å‹å¯¹æ¯”åˆ†æ", visible=True)

with gr.Blocks(theme=Seafoam(), css=css) as demo:
    gr.Markdown(
        """
        # ğŸŒŸ LLM Evaluation Web Application
        ### åŸºäº LLM-as-a-Judge çš„å¤§æ¨¡å‹è¯„ä¼°ç½‘é¡µåº”ç”¨
        """
    )
    
    state = gr.State({
        "tokenizer": None,
        "model_type": "å¾®è°ƒè£åˆ¤æ¨¡å‹",
        "eval_mode": "å•æ¨¡å‹è¯„ä¼°",
        "confidence_threshold": 0.5,
        "finetuned_model_name": list(FINETUNED_JUDGE_MODELS.keys())[0],
        "proprietary_model_name": list(PROPRIETARY_MODELS.keys())[0]
    })

    with gr.Row():
        with gr.Column(scale=1):
            with gr.Group():
                gr.Markdown("### ğŸ“‹ æ¨¡å‹è®¾ç½®")
                eval_mode_selector = gr.Radio(
                    label="è¯„ä¼°æ¨¡å¼",
                    choices=["å•æ¨¡å‹è¯„ä¼°", "çº§è”è¯„ä¼°"],
                    value="å•æ¨¡å‹è¯„ä¼°",
                    interactive=True,
                    elem_classes=["radio-group"]
                )
                model_type_selector = gr.Radio(
                    label="é€‰æ‹©æ¨¡å‹ç±»å‹",
                    choices=["å¾®è°ƒè£åˆ¤æ¨¡å‹", "ä¸“æœ‰æ¨¡å‹"],
                    value="å¾®è°ƒè£åˆ¤æ¨¡å‹",
                    interactive=True,
                    elem_classes=["radio-group"]
                )
                model_selector = gr.Dropdown(
                    label="é€‰æ‹©å¾®è°ƒè£åˆ¤æ¨¡å‹",
                    choices=list(FINETUNED_JUDGE_MODELS.keys()),
                    value=list(FINETUNED_JUDGE_MODELS.keys())[0],
                    interactive=True,
                    elem_classes=["dropdown"]
                )
                proprietary_model_selector = gr.Dropdown(
                    label="é€‰æ‹©ä¸“æœ‰æ¨¡å‹",
                    choices=list(PROPRIETARY_MODELS.keys()),
                    value=list(PROPRIETARY_MODELS.keys())[0],
                    interactive=True,
                    visible=False,
                    elem_classes=["dropdown"]
                )
                threshold_input = gr.Slider(
                    label="ç½®ä¿¡åº¦é˜ˆå€¼",
                    value=0.5,
                    minimum=0.0,
                    maximum=1.0,
                    step=0.01,
                    interactive=True,
                    visible=False,
                    elem_classes=["slider"]
                )
                with gr.Row():
                    load_model_btn = gr.Button("åŠ è½½æ¨¡å‹", variant="primary", elem_classes=["primary-button"])
                    unload_model_btn = gr.Button("å¸è½½æ¨¡å‹", variant="secondary", elem_classes=["secondary-button"])
                model_load_output = gr.Textbox(
                    label="æ¨¡å‹çŠ¶æ€",
                    interactive=False,
                    elem_classes=["textbox"]
                )

    with gr.Tabs() as tabs:
        with gr.TabItem("ğŸ“ æ‰‹åŠ¨è¯„ä¼°"):
            with gr.Row():
                with gr.Column(scale=1):
                    instruction_input = gr.Textbox(
                        label="æŒ‡ä»¤",
                        placeholder="è¯·è¾“å…¥è¯„ä¼°æŒ‡ä»¤â€¦â€¦",
                        lines=3
                    )
            with gr.Row():
                with gr.Column(scale=1):
                    answer1_input = gr.Textbox(
                        label="å¤§æ¨¡å‹ 1 å›ç­”",
                        placeholder="è¯·è¾“å…¥ç¬¬ä¸€ä¸ªå›ç­”â€¦â€¦",
                        lines=3
                    )
                with gr.Column(scale=1):
                    answer2_input = gr.Textbox(
                        label="å¤§æ¨¡å‹ 2 å›ç­”", 
                        placeholder="è¯·è¾“å…¥ç¬¬äºŒä¸ªå›ç­”â€¦â€¦",
                        lines=3
                    )
            with gr.Column():
                evaluation_mode_selector = gr.Radio(
                    choices=["ç›´æ¥è¯„ä¼°", "æ€ç»´é“¾"],
                    label="æ¨ç†ç­–ç•¥",
                    value="ç›´æ¥è¯„ä¼°",
                    visible=False
                )
                calibration_mode = gr.Checkbox(
                    label="å¯ç”¨æ ¡å‡†",
                    value=False,
                    visible=False
                )
            model_type_selector.change(
                fn=show_calibration_mode,
                inputs=[model_type_selector, eval_mode_selector],
                outputs=[evaluation_mode_selector, calibration_mode]
            )
            model_type_selector.change(
                fn=update_model_type,
                inputs=[model_type_selector, state],
                outputs=[state]
            ).then(
                fn=update_model_choices,
                inputs=[model_type_selector],
                outputs=[model_selector, proprietary_model_selector]
            ).then(
                fn=update_calibration_mode,
                inputs=[model_type_selector],
                outputs=[state]
            )
            evaluate_btn = gr.Button("å¼€å§‹è¯„ä¼°", interactive=False)
            model_load_output.change(enable_evaluate_button, inputs=model_load_output, outputs=evaluate_btn)

            with gr.Group():
                result_output = gr.Textbox(label="è¯„ä¼°ç»“æœ", interactive=False)
                details_button = gr.Button("æ˜¾ç¤ºè¯¦æƒ…", elem_classes=["details-button"])

                # é®ç½©å±‚å’Œå¼¹çª—
                modal_overlay = gr.HTML('<div class="modal-overlay" style="display: none;"></div>', visible=False)
                details_panel = gr.Group(visible=False, elem_classes=["modal-container"])
                with details_panel:
                    close_button = gr.Button("", elem_classes=["close-button"])
                    details_output = gr.HTML(label="è¯„ä¼°è¯¦æƒ…", elem_classes=["modal-content", "pretty-scroll"])

            def show_details(verdict, details):
                return verdict, details, gr.update(visible=True), gr.update(visible=True)

            def hide_details():
                return gr.update(visible=False), gr.update(visible=False)

            evaluate_btn.click(
                fn=manual_evaluate,
                inputs=[instruction_input, answer1_input, answer2_input, evaluation_mode_selector, state, calibration_mode],
                outputs=[result_output, details_output]
            )
            details_button.click(
                fn=lambda verdict, details: show_details(verdict, details),
                inputs=[result_output, details_output],
                outputs=[result_output, details_output, modal_overlay, details_panel]
            )
            close_button.click(
                fn=hide_details,
                outputs=[modal_overlay, details_panel]
            )

        with gr.TabItem("ğŸ“Š æ‰¹é‡è¯„ä¼°"):
            file_input = gr.File(label="ä¸Šä¼ æ•°æ®æ–‡ä»¶ (CSV/JSON)")
            with gr.Column():
                batch_mode_selector = gr.Radio(
                    choices=["ç›´æ¥è¯„ä¼°", "æ€ç»´é“¾"],
                    label="æ¨ç†ç­–ç•¥",
                    value="ç›´æ¥è¯„ä¼°",
                    visible=False
                )
                batch_calibration_mode = gr.Checkbox(label="å¯ç”¨æ ¡å‡†", value=False, visible=False)
            batch_evaluate_btn = gr.Button("å¼€å§‹æ‰¹é‡è¯„ä¼°", interactive=False)
            batch_result_output = gr.Textbox(label="æ‰¹é‡è¯„ä¼°ç»“æœ", interactive=False)
            report_download = gr.File(label="è¯„ä¼°æŠ¥å‘Šä¸‹è½½", visible=False, interactive=False) 
            gr.Markdown(
                """
                #### ğŸ“‹ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
                - CSV æ–‡ä»¶: åŒ…å« instruction, answer1, answer2 åˆ—
                - JSON æ–‡ä»¶: åŒ…å«ç›¸åº”å­—æ®µçš„æ•°ç»„
                """
            )

            eval_mode_selector.change(
                fn=update_eval_mode,
                inputs=[eval_mode_selector, state],
                outputs=[
                    model_type_selector, proprietary_model_selector, threshold_input,
                    model_type_selector, evaluation_mode_selector, calibration_mode,
                    batch_mode_selector, batch_calibration_mode
                ]
            )

            model_type_selector.change(
                fn=show_batch_calibration_mode,
                inputs=[model_type_selector, eval_mode_selector],
                outputs=[batch_mode_selector, batch_calibration_mode]
            ).then(
                fn=update_batch_calibration_mode,
                inputs=[model_type_selector],
                outputs=[state]
            )

            batch_evaluate_btn.click(
                fn=batch_evaluation,
                inputs=[file_input, batch_mode_selector, state, batch_calibration_mode],
                outputs=[batch_result_output, report_download]
            ).then(
                fn=lambda: gr.update(visible=True),
                outputs=report_download
            ).then(
                fn=analyze_results,
                inputs=report_download,
                outputs=[stats_html, comp_plot]
            )
            model_load_output.change(enable_evaluate_button, inputs=model_load_output, outputs=batch_evaluate_btn)
        with gr.TabItem("ğŸ“ˆ ç»“æœå¯è§†åŒ–", id="visualization_tab"):
            with gr.Row():
                with gr.Column(scale=1):
                    report_selector = gr.Dropdown(
                        label="é€‰æ‹©è¯„ä¼°æŠ¥å‘Š",
                        interactive=True,
                        visible=True
                    )
                    refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æŠ¥å‘Šåˆ—è¡¨", size="sm")
                                            
            with gr.Row():
                with gr.Column(scale=1):
                    stats_html = gr.HTML(label="ç»Ÿè®¡æ‘˜è¦", visible=True, elem_id="stats_html")
                with gr.Column(scale=2):
                    comp_plot = gr.Plot(label="æ¨¡å‹å¯¹æ¯”åˆ†æ", visible=True, elem_id="comp_plot")

            # åˆ·æ–°æŠ¥å‘Šåˆ—è¡¨
            refresh_btn.click(
                fn=update_report_list,
                outputs=report_selector
            )

            # é€‰æ‹©æŠ¥å‘Šååˆ†æç»“æœ
            report_selector.change(
                fn=analyze_results,
                inputs=report_selector,
                outputs=[stats_html, comp_plot]
            )
    gr.Markdown(
        """
        <div class="footer">
            <p>Designed by Hongli Zhou</p>
        </div>
        """,
        elem_classes="footer"
    )

    model_type_selector.change(
        fn=lambda model_type: [
            gr.update(visible=model_type == "å¾®è°ƒè£åˆ¤æ¨¡å‹"),
            gr.update(visible=model_type == "ä¸“æœ‰æ¨¡å‹"),
        ],
        inputs=[model_type_selector],
        outputs=[model_selector, proprietary_model_selector]
    )

    model_selector.change(
        fn=lambda selected_model, s: {**s, "finetuned_model_name": selected_model},
        inputs=[model_selector, state],
        outputs=[state]
    )
    proprietary_model_selector.change(
        fn=lambda prop_model, s: {**s, "proprietary_model_name": prop_model},
        inputs=[proprietary_model_selector, state],
        outputs=[state]
    )

    load_model_btn.click(
        fn=load_model_based_on_type,
        inputs=[model_type_selector, model_selector, proprietary_model_selector, eval_mode_selector, state],
        outputs=[model_load_output, load_model_btn]
    )

    unload_model_btn.click(
        fn=clear_model,
        inputs=[state],
        outputs=[model_load_output]
    )

    threshold_input.change(
        fn=lambda threshold, s: {**s, "confidence_threshold": threshold},
        inputs=[threshold_input, state],
        outputs=state
    )

if __name__ == "__main__":
    demo.launch()